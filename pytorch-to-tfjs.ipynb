{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Export model so I can load it in JavaScript"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">**Note**<br><br>\n",
    "This is not a guide on how to transfer Pytorch models to Tensorflow.js models. \n",
    "<br><br>\n",
    ">I use nobuco __No Bullshit Converter__ [GitHub](https://github.com/AlexanderLutsenko/nobuco) made by Alexander Lutsenko."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Sequential: 1-1                             [-1, 960, 1, 1]           --\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    └─Sequential: 2-1                        [-1, 960, 7, 7]           --\n",
      "├─Sequential: 1                               []                        --\n",
      "|    └─Sequential: 2-2                        [-1, 960, 7, 7]           (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─Conv2dNormActivation: 3-1         [-1, 16, 112, 112]        (464)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─Conv2dNormActivation: 3-2         [-1, 16, 112, 112]        (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-3             [-1, 16, 112, 112]        (464)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-4             [-1, 16, 112, 112]        (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-5             [-1, 24, 56, 56]          (3,440)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-6             [-1, 24, 56, 56]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-7             [-1, 24, 56, 56]          (4,440)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-8             [-1, 24, 56, 56]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-9             [-1, 40, 28, 28]          (10,328)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-10            [-1, 40, 28, 28]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-11            [-1, 40, 28, 28]          (20,992)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-12            [-1, 40, 28, 28]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-13            [-1, 40, 28, 28]          (20,992)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-14            [-1, 40, 28, 28]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-15            [-1, 80, 14, 14]          (32,080)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-16            [-1, 80, 14, 14]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-17            [-1, 80, 14, 14]          (34,760)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-18            [-1, 80, 14, 14]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-19            [-1, 80, 14, 14]          (31,992)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-20            [-1, 80, 14, 14]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-21            [-1, 80, 14, 14]          (31,992)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-22            [-1, 80, 14, 14]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-23            [-1, 112, 14, 14]         (214,424)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-24            [-1, 112, 14, 14]         (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-25            [-1, 112, 14, 14]         (386,120)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-26            [-1, 112, 14, 14]         (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-27            [-1, 160, 7, 7]           (429,224)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-28            [-1, 160, 7, 7]           (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-29            [-1, 160, 7, 7]           (797,360)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-30            [-1, 160, 7, 7]           (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-31            [-1, 160, 7, 7]           (797,360)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-32            [-1, 160, 7, 7]           (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─Conv2dNormActivation: 3-33        [-1, 960, 7, 7]           155,520\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─Conv2dNormActivation: 3-34        [-1, 960, 7, 7]           (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    └─AdaptiveAvgPool2d: 2-3                 [-1, 960, 1, 1]           --\n",
      "├─Sequential: 1                               []                        --\n",
      "|    └─AdaptiveAvgPool2d: 2-4                 [-1, 960, 1, 1]           --\n",
      "├─Sequential: 1-2                             [-1, 5]                   --\n",
      "|    └─AdaptiveAvgPool2d: 2-5                 [-1, 960, 1, 1]           --\n",
      "|    └─Flatten: 2-6                           [-1, 960]                 --\n",
      "|    └─Linear: 2-7                            [-1, 1024]                984,064\n",
      "|    └─ReLU: 2-8                              [-1, 1024]                --\n",
      "|    └─Linear: 2-9                            [-1, 512]                 524,800\n",
      "|    └─ReLU: 2-10                             [-1, 512]                 --\n",
      "|    └─Linear: 2-11                           [-1, 5]                   2,565\n",
      "|    └─Softmax: 2-12                          [-1, 5]                   --\n",
      "===============================================================================================\n",
      "Total params: 4,483,381\n",
      "Trainable params: 1,666,949\n",
      "Non-trainable params: 2,816,432\n",
      "Total mult-adds (M): 49.29\n",
      "===============================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 3.79\n",
      "Params size (MB): 17.10\n",
      "Estimated Total Size (MB): 21.47\n",
      "===============================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "├─Sequential: 1-1                             [-1, 960, 1, 1]           --\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    └─Sequential: 2-1                        [-1, 960, 7, 7]           --\n",
       "├─Sequential: 1                               []                        --\n",
       "|    └─Sequential: 2-2                        [-1, 960, 7, 7]           (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─Conv2dNormActivation: 3-1         [-1, 16, 112, 112]        (464)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─Conv2dNormActivation: 3-2         [-1, 16, 112, 112]        (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-3             [-1, 16, 112, 112]        (464)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-4             [-1, 16, 112, 112]        (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-5             [-1, 24, 56, 56]          (3,440)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-6             [-1, 24, 56, 56]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-7             [-1, 24, 56, 56]          (4,440)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-8             [-1, 24, 56, 56]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-9             [-1, 40, 28, 28]          (10,328)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-10            [-1, 40, 28, 28]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-11            [-1, 40, 28, 28]          (20,992)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-12            [-1, 40, 28, 28]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-13            [-1, 40, 28, 28]          (20,992)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-14            [-1, 40, 28, 28]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-15            [-1, 80, 14, 14]          (32,080)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-16            [-1, 80, 14, 14]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-17            [-1, 80, 14, 14]          (34,760)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-18            [-1, 80, 14, 14]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-19            [-1, 80, 14, 14]          (31,992)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-20            [-1, 80, 14, 14]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-21            [-1, 80, 14, 14]          (31,992)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-22            [-1, 80, 14, 14]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-23            [-1, 112, 14, 14]         (214,424)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-24            [-1, 112, 14, 14]         (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-25            [-1, 112, 14, 14]         (386,120)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-26            [-1, 112, 14, 14]         (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-27            [-1, 160, 7, 7]           (429,224)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-28            [-1, 160, 7, 7]           (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-29            [-1, 160, 7, 7]           (797,360)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-30            [-1, 160, 7, 7]           (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-31            [-1, 160, 7, 7]           (797,360)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-32            [-1, 160, 7, 7]           (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─Conv2dNormActivation: 3-33        [-1, 960, 7, 7]           155,520\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─Conv2dNormActivation: 3-34        [-1, 960, 7, 7]           (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    └─AdaptiveAvgPool2d: 2-3                 [-1, 960, 1, 1]           --\n",
       "├─Sequential: 1                               []                        --\n",
       "|    └─AdaptiveAvgPool2d: 2-4                 [-1, 960, 1, 1]           --\n",
       "├─Sequential: 1-2                             [-1, 5]                   --\n",
       "|    └─AdaptiveAvgPool2d: 2-5                 [-1, 960, 1, 1]           --\n",
       "|    └─Flatten: 2-6                           [-1, 960]                 --\n",
       "|    └─Linear: 2-7                            [-1, 1024]                984,064\n",
       "|    └─ReLU: 2-8                              [-1, 1024]                --\n",
       "|    └─Linear: 2-9                            [-1, 512]                 524,800\n",
       "|    └─ReLU: 2-10                             [-1, 512]                 --\n",
       "|    └─Linear: 2-11                           [-1, 5]                   2,565\n",
       "|    └─Softmax: 2-12                          [-1, 5]                   --\n",
       "===============================================================================================\n",
       "Total params: 4,483,381\n",
       "Trainable params: 1,666,949\n",
       "Non-trainable params: 2,816,432\n",
       "Total mult-adds (M): 49.29\n",
       "===============================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 3.79\n",
       "Params size (MB): 17.10\n",
       "Estimated Total Size (MB): 21.47\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# model:\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "from torchvision.models import mobilenet_v3_large, MobileNet_V3_Large_Weights\n",
    "import torch.nn as nn \n",
    "from torchvision.datasets import ImageFolder\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.transforms import v2\n",
    "from torchvision.transforms import InterpolationMode\n",
    "import matplotlib.pyplot as plt \n",
    "%matplotlib inline\n",
    "\n",
    "# Path directory\n",
    "dir_path = \"dataset/data-splited 3\"\n",
    "\n",
    "# Data augmentation transformations (only train set)\n",
    "train_transform = v2.Compose([\n",
    "    v2.ToImage(),  # Convert to tensor\n",
    "    #v2.RandomPerspective(distortion_scale=0.6, p=1.0),\n",
    "    v2.Resize((224, 224), interpolation=InterpolationMode.BICUBIC),  # Bicubic Interpolation for Better Quality\n",
    "    v2.RandomRotation(20),   # Random rotation\n",
    "    #v2.RandomAffine(degrees=0, translate=(0.2, 0.1), shear=20),\n",
    "    #v2.RandomHorizontalFlip(p=0.5),  # Random horizontal flip\n",
    "    # Add more transformations if needed\n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    # Normalize using Imagenet pretrianed model with its own mean and std is recommended.\n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),  \n",
    "])\n",
    "\n",
    "# Data augmentation transformations for val and test sets\n",
    "transform = v2.Compose([\n",
    "    v2.ToImage(), \n",
    "    v2.ToDtype(torch.float32, scale=True),\n",
    "    v2.Resize((224, 224), interpolation=InterpolationMode.BICUBIC), \n",
    "    v2.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "\n",
    "])\n",
    "\n",
    "# Load dataset\n",
    "train_set = ImageFolder(os.path.join(dir_path, \"train\"), transform=train_transform)\n",
    "val_set = ImageFolder(os.path.join(dir_path, \"val\"), transform=transform)\n",
    "test_set = ImageFolder(os.path.join(dir_path, \"test\"), transform=transform)\n",
    "\n",
    "# Create DataLoaders\n",
    "train_loader = DataLoader(train_set, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_set, batch_size=16, shuffle=False)\n",
    "test_loader = DataLoader(test_set, batch_size=16, shuffle=False)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NeuralNetwork(nn.Module):\n",
    "    def __init__(self, num_classes=len(train_set.classes)):\n",
    "        super(NeuralNetwork, self).__init__()\n",
    "        # Where we define all the parts of the model\n",
    "        self.base_model = mobilenet_v3_large(weights=MobileNet_V3_Large_Weights.IMAGENET1K_V2)\n",
    "        self.features = nn.Sequential(*list(self.base_model.children())[:-1])\n",
    "        \n",
    "        # Code the of the base model\n",
    "        #for param in self.base_model.parameters():\n",
    "        #    param.requires_grad = False  # Freeze all layers initially\n",
    "        self.fine_tune_at = 165\n",
    "\n",
    "        # Iterate through parameters, not layers directly\n",
    "        for i, param in enumerate(self.base_model.parameters()):\n",
    "            if i >= self.fine_tune_at: \n",
    "                param.requires_grad = True  # Unfreeze parameters\n",
    "            else:\n",
    "                param.requires_grad = False\n",
    "\n",
    "      \n",
    "        # Make a classifier\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d(1),  # More flexible than GlobalAveragePooling\n",
    "            nn.Flatten(),\n",
    "            nn.Linear(960, 1024),  # Adjust input features\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(1024, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, num_classes),\n",
    "            nn.Softmax(dim=1) \n",
    "        )\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Connect these parts and return the output\n",
    "        x = self.features(x)\n",
    "        output = self.classifier(x)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "    \n",
    "model = NeuralNetwork(len(train_set.classes))\n",
    "\n",
    "summary(model.cuda(), (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================================================================\n",
      "Layer (type:depth-idx)                        Output Shape              Param #\n",
      "===============================================================================================\n",
      "├─Sequential: 1-1                             [-1, 960, 1, 1]           --\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    └─Sequential: 2-1                        [-1, 960, 7, 7]           --\n",
      "├─Sequential: 1                               []                        --\n",
      "|    └─Sequential: 2-2                        [-1, 960, 7, 7]           (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─Conv2dNormActivation: 3-1         [-1, 16, 112, 112]        (464)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─Conv2dNormActivation: 3-2         [-1, 16, 112, 112]        (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-3             [-1, 16, 112, 112]        (464)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-4             [-1, 16, 112, 112]        (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-5             [-1, 24, 56, 56]          (3,440)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-6             [-1, 24, 56, 56]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-7             [-1, 24, 56, 56]          (4,440)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-8             [-1, 24, 56, 56]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-9             [-1, 40, 28, 28]          (10,328)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-10            [-1, 40, 28, 28]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-11            [-1, 40, 28, 28]          (20,992)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-12            [-1, 40, 28, 28]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-13            [-1, 40, 28, 28]          (20,992)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-14            [-1, 40, 28, 28]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-15            [-1, 80, 14, 14]          (32,080)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-16            [-1, 80, 14, 14]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-17            [-1, 80, 14, 14]          (34,760)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-18            [-1, 80, 14, 14]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-19            [-1, 80, 14, 14]          (31,992)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-20            [-1, 80, 14, 14]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-21            [-1, 80, 14, 14]          (31,992)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-22            [-1, 80, 14, 14]          (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-23            [-1, 112, 14, 14]         (214,424)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-24            [-1, 112, 14, 14]         (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-25            [-1, 112, 14, 14]         (386,120)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-26            [-1, 112, 14, 14]         (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-27            [-1, 160, 7, 7]           (429,224)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-28            [-1, 160, 7, 7]           (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-29            [-1, 160, 7, 7]           (797,360)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-30            [-1, 160, 7, 7]           (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─InvertedResidual: 3-31            [-1, 160, 7, 7]           (797,360)\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─InvertedResidual: 3-32            [-1, 160, 7, 7]           (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    |    └─Conv2dNormActivation: 3-33        [-1, 960, 7, 7]           155,520\n",
      "├─Sequential: 1                               []                        --\n",
      "|    |    └─Conv2dNormActivation: 3-34        [-1, 960, 7, 7]           (recursive)\n",
      "├─MobileNetV3: 1                              []                        --\n",
      "|    └─AdaptiveAvgPool2d: 2-3                 [-1, 960, 1, 1]           --\n",
      "├─Sequential: 1                               []                        --\n",
      "|    └─AdaptiveAvgPool2d: 2-4                 [-1, 960, 1, 1]           --\n",
      "├─Sequential: 1-2                             [-1, 5]                   --\n",
      "|    └─AdaptiveAvgPool2d: 2-5                 [-1, 960, 1, 1]           --\n",
      "|    └─Flatten: 2-6                           [-1, 960]                 --\n",
      "|    └─Linear: 2-7                            [-1, 1024]                984,064\n",
      "|    └─ReLU: 2-8                              [-1, 1024]                --\n",
      "|    └─Linear: 2-9                            [-1, 512]                 524,800\n",
      "|    └─ReLU: 2-10                             [-1, 512]                 --\n",
      "|    └─Linear: 2-11                           [-1, 5]                   2,565\n",
      "|    └─Softmax: 2-12                          [-1, 5]                   --\n",
      "===============================================================================================\n",
      "Total params: 4,483,381\n",
      "Trainable params: 1,666,949\n",
      "Non-trainable params: 2,816,432\n",
      "Total mult-adds (M): 49.29\n",
      "===============================================================================================\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 3.79\n",
      "Params size (MB): 17.10\n",
      "Estimated Total Size (MB): 21.47\n",
      "===============================================================================================\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "===============================================================================================\n",
       "Layer (type:depth-idx)                        Output Shape              Param #\n",
       "===============================================================================================\n",
       "├─Sequential: 1-1                             [-1, 960, 1, 1]           --\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    └─Sequential: 2-1                        [-1, 960, 7, 7]           --\n",
       "├─Sequential: 1                               []                        --\n",
       "|    └─Sequential: 2-2                        [-1, 960, 7, 7]           (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─Conv2dNormActivation: 3-1         [-1, 16, 112, 112]        (464)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─Conv2dNormActivation: 3-2         [-1, 16, 112, 112]        (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-3             [-1, 16, 112, 112]        (464)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-4             [-1, 16, 112, 112]        (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-5             [-1, 24, 56, 56]          (3,440)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-6             [-1, 24, 56, 56]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-7             [-1, 24, 56, 56]          (4,440)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-8             [-1, 24, 56, 56]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-9             [-1, 40, 28, 28]          (10,328)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-10            [-1, 40, 28, 28]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-11            [-1, 40, 28, 28]          (20,992)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-12            [-1, 40, 28, 28]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-13            [-1, 40, 28, 28]          (20,992)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-14            [-1, 40, 28, 28]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-15            [-1, 80, 14, 14]          (32,080)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-16            [-1, 80, 14, 14]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-17            [-1, 80, 14, 14]          (34,760)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-18            [-1, 80, 14, 14]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-19            [-1, 80, 14, 14]          (31,992)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-20            [-1, 80, 14, 14]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-21            [-1, 80, 14, 14]          (31,992)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-22            [-1, 80, 14, 14]          (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-23            [-1, 112, 14, 14]         (214,424)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-24            [-1, 112, 14, 14]         (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-25            [-1, 112, 14, 14]         (386,120)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-26            [-1, 112, 14, 14]         (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-27            [-1, 160, 7, 7]           (429,224)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-28            [-1, 160, 7, 7]           (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-29            [-1, 160, 7, 7]           (797,360)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-30            [-1, 160, 7, 7]           (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─InvertedResidual: 3-31            [-1, 160, 7, 7]           (797,360)\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─InvertedResidual: 3-32            [-1, 160, 7, 7]           (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    |    └─Conv2dNormActivation: 3-33        [-1, 960, 7, 7]           155,520\n",
       "├─Sequential: 1                               []                        --\n",
       "|    |    └─Conv2dNormActivation: 3-34        [-1, 960, 7, 7]           (recursive)\n",
       "├─MobileNetV3: 1                              []                        --\n",
       "|    └─AdaptiveAvgPool2d: 2-3                 [-1, 960, 1, 1]           --\n",
       "├─Sequential: 1                               []                        --\n",
       "|    └─AdaptiveAvgPool2d: 2-4                 [-1, 960, 1, 1]           --\n",
       "├─Sequential: 1-2                             [-1, 5]                   --\n",
       "|    └─AdaptiveAvgPool2d: 2-5                 [-1, 960, 1, 1]           --\n",
       "|    └─Flatten: 2-6                           [-1, 960]                 --\n",
       "|    └─Linear: 2-7                            [-1, 1024]                984,064\n",
       "|    └─ReLU: 2-8                              [-1, 1024]                --\n",
       "|    └─Linear: 2-9                            [-1, 512]                 524,800\n",
       "|    └─ReLU: 2-10                             [-1, 512]                 --\n",
       "|    └─Linear: 2-11                           [-1, 5]                   2,565\n",
       "|    └─Softmax: 2-12                          [-1, 5]                   --\n",
       "===============================================================================================\n",
       "Total params: 4,483,381\n",
       "Trainable params: 1,666,949\n",
       "Non-trainable params: 2,816,432\n",
       "Total mult-adds (M): 49.29\n",
       "===============================================================================================\n",
       "Input size (MB): 0.57\n",
       "Forward/backward pass size (MB): 3.79\n",
       "Params size (MB): 17.10\n",
       "Estimated Total Size (MB): 21.47\n",
       "==============================================================================================="
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1. Load your trained PyTorch model\n",
    "saved_model = torch.load('pytorch-model-CPU.pt')\n",
    "\n",
    "summary(saved_model, (3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Hardswish.__init__() got an unexpected keyword argument 'training'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 29\u001b[0m\n\u001b[0;32m     26\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     27\u001b[0m        \u001b[38;5;28;01mreturn\u001b[39;00m module  \u001b[38;5;66;03m# No changes needed\u001b[39;00m\n\u001b[1;32m---> 29\u001b[0m my_pytorch_model \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_inplace_warning\u001b[49m\u001b[43m(\u001b[49m\u001b[43msaved_model\u001b[49m\u001b[43m)\u001b[49m \n",
      "Cell \u001b[1;32mIn[4], line 7\u001b[0m, in \u001b[0;36mresolve_inplace_warning\u001b[1;34m(model)\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m name, module \u001b[38;5;129;01min\u001b[39;00m model\u001b[38;5;241m.\u001b[39mnamed_modules():\n\u001b[0;32m      6\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mforward\u001b[39m\u001b[38;5;124m'\u001b[39m):  \u001b[38;5;66;03m# Check if it's a module with a forward pass\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m         new_module \u001b[38;5;241m=\u001b[39m \u001b[43mresolve_inplace_module\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m \n\u001b[0;32m      8\u001b[0m         \u001b[38;5;28msetattr\u001b[39m(model, name, new_module) \n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model\n",
      "Cell \u001b[1;32mIn[4], line 22\u001b[0m, in \u001b[0;36mresolve_inplace_module\u001b[1;34m(module)\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Example: Common in-place operation replacement pattern.\u001b[39;00m\n\u001b[0;32m     21\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(module, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124minplace\u001b[39m\u001b[38;5;124m'\u001b[39m): \n\u001b[1;32m---> 22\u001b[0m     new_module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmodule\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__dict__\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# Reconstruct the module\u001b[39;00m\n\u001b[0;32m     23\u001b[0m     new_module\u001b[38;5;241m.\u001b[39minplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;66;03m# Disable in-place operations\u001b[39;00m\n\u001b[0;32m     24\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m new_module\n",
      "\u001b[1;31mTypeError\u001b[0m: Hardswish.__init__() got an unexpected keyword argument 'training'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "def resolve_inplace_warning(model):\n",
    "    \"\"\"Iterates through model modules to replace in-place operations\"\"\"\n",
    "    for name, module in model.named_modules():\n",
    "        if hasattr(module, 'forward'):  # Check if it's a module with a forward pass\n",
    "            new_module = resolve_inplace_module(module) \n",
    "            setattr(model, name, new_module) \n",
    "    return model\n",
    "\n",
    "def resolve_inplace_module(module):\n",
    "    \"\"\"Replaces in-place operations with out-of-place versions in a module\"\"\"\n",
    "    # You'll need to customize the logic here based on the specific\n",
    "    # in-place operations detected in your model.\n",
    "\n",
    "    # Example: Assuming an in-place ReLU\n",
    "    if isinstance(module, torch.nn.ReLU):\n",
    "        return torch.nn.ReLU(inplace=False) \n",
    "\n",
    "    # Example: Common in-place operation replacement pattern.\n",
    "    elif hasattr(module, 'inplace'): \n",
    "        new_module = type(module)(**module.__dict__) # Reconstruct the module\n",
    "        new_module.inplace = False # Disable in-place operations\n",
    "        return new_module\n",
    "\n",
    "    else:\n",
    "       return module  # No changes needed\n",
    "\n",
    "my_pytorch_model = resolve_inplace_warning(saved_model) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From c:\\Users\\louis\\anaconda3\\envs\\nobuco\\Lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import Nobuco dependencies\n",
    "from nobuco import pytorch_to_keras, ChannelOrder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NeuralNetwork(\n",
       "  (base_model): MobileNetV3(\n",
       "    (features): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "            (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv2dNormActivation(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "    )\n",
       "    (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "    (classifier): Sequential(\n",
       "      (0): Linear(in_features=960, out_features=1280, bias=True)\n",
       "      (1): Hardswish()\n",
       "      (2): Dropout(p=0.2, inplace=True)\n",
       "      (3): Linear(in_features=1280, out_features=1000, bias=True)\n",
       "    )\n",
       "  )\n",
       "  (features): Sequential(\n",
       "    (0): Sequential(\n",
       "      (0): Conv2dNormActivation(\n",
       "        (0): Conv2d(3, 16, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "      (1): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=16, bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 16, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(16, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (2): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=64, bias=False)\n",
       "            (1): BatchNorm2d(64, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(64, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (3): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(24, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (4): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 72, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=72, bias=False)\n",
       "            (1): BatchNorm2d(72, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(72, 24, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(24, 72, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(72, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (5): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (6): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 120, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 120, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=120, bias=False)\n",
       "            (1): BatchNorm2d(120, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): ReLU(inplace=True)\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(120, 32, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(32, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(120, 40, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(40, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (7): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(40, 240, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 240, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), groups=240, bias=False)\n",
       "            (1): BatchNorm2d(240, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(240, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (8): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 200, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(200, 200, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=200, bias=False)\n",
       "            (1): BatchNorm2d(200, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(200, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (9): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (10): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 184, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(184, 184, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=184, bias=False)\n",
       "            (1): BatchNorm2d(184, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): Conv2dNormActivation(\n",
       "            (0): Conv2d(184, 80, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(80, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (11): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(80, 480, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 480, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=480, bias=False)\n",
       "            (1): BatchNorm2d(480, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(480, 120, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(120, 480, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(480, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (12): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 112, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(112, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (13): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(112, 672, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 672, kernel_size=(5, 5), stride=(2, 2), padding=(2, 2), groups=672, bias=False)\n",
       "            (1): BatchNorm2d(672, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(672, 168, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(168, 672, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(672, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (14): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (15): InvertedResidual(\n",
       "        (block): Sequential(\n",
       "          (0): Conv2dNormActivation(\n",
       "            (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (1): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 960, kernel_size=(5, 5), stride=(1, 1), padding=(2, 2), groups=960, bias=False)\n",
       "            (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "            (2): Hardswish()\n",
       "          )\n",
       "          (2): SqueezeExcitation(\n",
       "            (avgpool): AdaptiveAvgPool2d(output_size=1)\n",
       "            (fc1): Conv2d(960, 240, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (fc2): Conv2d(240, 960, kernel_size=(1, 1), stride=(1, 1))\n",
       "            (activation): ReLU()\n",
       "            (scale_activation): Hardsigmoid()\n",
       "          )\n",
       "          (3): Conv2dNormActivation(\n",
       "            (0): Conv2d(960, 160, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "            (1): BatchNorm2d(160, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "      (16): Conv2dNormActivation(\n",
       "        (0): Conv2d(160, 960, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "        (1): BatchNorm2d(960, eps=0.001, momentum=0.01, affine=True, track_running_stats=True)\n",
       "        (2): Hardswish()\n",
       "      )\n",
       "    )\n",
       "    (1): AdaptiveAvgPool2d(output_size=1)\n",
       "  )\n",
       "  (classifier): Sequential(\n",
       "    (0): AdaptiveAvgPool2d(output_size=1)\n",
       "    (1): Flatten(start_dim=1, end_dim=-1)\n",
       "    (2): Linear(in_features=960, out_features=1024, bias=True)\n",
       "    (3): ReLU()\n",
       "    (4): Linear(in_features=1024, out_features=512, bias=True)\n",
       "    (5): ReLU()\n",
       "    (6): Linear(in_features=512, out_features=5, bias=True)\n",
       "    (7): Softmax(dim=1)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "saved_model.to(\"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# nobuco is not working correctly for now  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nobuco\n",
    "from nobuco import ChannelOrder, ChannelOrderingStrategy\n",
    "from nobuco.layers.weight import WeightLayer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the model to evaluation mode\n",
    "saved_model.eval()\n",
    "\n",
    "# Input_tensor = torch.randn(1, 224, 224, 3)\n",
    "input_tensor = torch.randn(1, 3, 224, 224).to(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\louis\\anaconda3\\envs\\nobuco\\Lib\\site-packages\\nobuco\\converters\\validation.py:55: RuntimeWarning: [<class 'torchvision.ops.misc.Conv2dNormActivation'>|NeuralNetwork->Sequential->Sequential->InvertedResidual->Sequential] conversion procedure might be incorrect: max. discrepancy for output #0 is 0.00014 (0.000%)\n",
      "  warnings.warn(warn_string, category=RuntimeWarning)\n",
      "c:\\Users\\louis\\anaconda3\\envs\\nobuco\\Lib\\site-packages\\nobuco\\converters\\validation.py:55: RuntimeWarning: [<class 'torch.nn.modules.container.Sequential'>|NeuralNetwork->Sequential->Sequential->InvertedResidual] conversion procedure might be incorrect: max. discrepancy for output #0 is 0.00013 (0.000%)\n",
      "  warnings.warn(warn_string, category=RuntimeWarning)\n",
      "c:\\Users\\louis\\anaconda3\\envs\\nobuco\\Lib\\site-packages\\nobuco\\converters\\validation.py:55: RuntimeWarning: [<class 'torchvision.models.mobilenetv3.InvertedResidual'>|NeuralNetwork->Sequential->Sequential] conversion procedure might be incorrect: max. discrepancy for output #0 is 0.00013 (0.000%)\n",
      "  warnings.warn(warn_string, category=RuntimeWarning)\n",
      "c:\\Users\\louis\\anaconda3\\envs\\nobuco\\Lib\\site-packages\\nobuco\\converters\\validation.py:55: RuntimeWarning: [<class 'torch.nn.modules.container.Sequential'>|NeuralNetwork->Sequential] conversion procedure might be incorrect: max. discrepancy for output #0 is 0.00055 (0.021%)\n",
      "  warnings.warn(warn_string, category=RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend:\n",
      "    \u001b[32mGreen\u001b[0m — conversion successful\n",
      "    \u001b[33mYellow\u001b[0m — conversion imprecise\n",
      "    \u001b[31mRed\u001b[0m — conversion failed\n",
      "    \u001b[31m\u001b[7mRed\u001b[0m — no converter found\n",
      "    \u001b[0m\u001b[1mBold\u001b[0m — conversion applied directly\n",
      "    * — subgraph reused\n",
      "    \u001b[7mTensor\u001b[0m — this output is not dependent on any of subgraph's input tensors\n",
      "    \u001b[4mTensor\u001b[0m — this input is a parameter / constant\n",
      "    \u001b[90mTensor\u001b[0m — this tensor is useless\n",
      "\n",
      "\u001b[32mNeuralNetwork[__main__]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_361<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_347<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m\u001b[7m (!) Max diff 0.00055 (0.021%) \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"C:\\Users\\louis\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py\", line 217\u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"C:/Users/louis/AppData/Roaming/Python/Python311/site-packages/torch/nn/modules/container.py\", line 43 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33mSequential[torch.nn.modules.container]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_2<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_0<1,3,224,224>\u001b[0m, float32_1<16,3,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_2<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_2<1,16,112,112>\u001b[0m) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_2<1,16,112,112>\u001b[0m, float32_3<16>\u001b[0m, float32_3<16>\u001b[0m, float32_4<16>\u001b[0m, float32_3<16>\u001b[0m, False, 0.01, 0.001) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_2<1,16,112,112>\u001b[0m, float32_4<16>\u001b[0m, float32_3<16>\u001b[0m, float32_3<16>\u001b[0m, float32_3<16>\u001b[0m, False, 0.01, 0.001, True) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_5<1,16,112,112>\u001b[0m, True) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_7<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_5<1,16,112,112>\u001b[0m, float32_6<16,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 16) -> float32_7<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_7<1,16,112,112>\u001b[0m) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_7<1,16,112,112>\u001b[0m, float32_8<16>\u001b[0m, float32_9<16>\u001b[0m, float32_10<16>\u001b[0m, float32_11<16>\u001b[0m, False, 0.01, 0.001) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_7<1,16,112,112>\u001b[0m, float32_10<16>\u001b[0m, float32_11<16>\u001b[0m, float32_8<16>\u001b[0m, float32_9<16>\u001b[0m, False, 0.01, 0.001, True) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_12<1,16,112,112>\u001b[0m) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_12<1,16,112,112>\u001b[0m, inplace=True) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_12<1,16,112,112>\u001b[0m) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_12<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_12<1,16,112,112>\u001b[0m) -> float32_14<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_12<1,16,112,112>\u001b[0m, float32_13<16,16,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_14<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_14<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_14<1,16,112,112>\u001b[0m, float32_15<16>\u001b[0m, float32_16<16>\u001b[0m, float32_16<16>\u001b[0m, float32_17<16>\u001b[0m, False, 0.01, 0.001) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_14<1,16,112,112>\u001b[0m, float32_16<16>\u001b[0m, float32_17<16>\u001b[0m, float32_15<16>\u001b[0m, float32_16<16>\u001b[0m, False, 0.01, 0.001, True) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_18<1,16,112,112>\u001b[0m, float32_5<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_18<1,16,112,112>\u001b[0m, float32_5<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_18<1,16,112,112>\u001b[0m) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_18<1,16,112,112>\u001b[0m) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_18<1,16,112,112>\u001b[0m) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_18<1,16,112,112>\u001b[0m) -> float32_20<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_18<1,16,112,112>\u001b[0m, float32_19<64,16,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_20<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_20<1,64,112,112>\u001b[0m) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_20<1,64,112,112>\u001b[0m, float32_21<64>\u001b[0m, float32_22<64>\u001b[0m, float32_22<64>\u001b[0m, float32_22<64>\u001b[0m, False, 0.01, 0.001) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_20<1,64,112,112>\u001b[0m, float32_22<64>\u001b[0m, float32_22<64>\u001b[0m, float32_21<64>\u001b[0m, float32_22<64>\u001b[0m, False, 0.01, 0.001, True) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_23<1,64,112,112>\u001b[0m) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_23<1,64,112,112>\u001b[0m, inplace=True) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_23<1,64,112,112>\u001b[0m) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_23<1,64,112,112>\u001b[0m) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_23<1,64,112,112>\u001b[0m) -> float32_25<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_23<1,64,112,112>\u001b[0m, float32_24<64,1,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 64) -> float32_25<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_25<1,64,56,56>\u001b[0m) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_25<1,64,56,56>\u001b[0m, float32_26<64>\u001b[0m, float32_27<64>\u001b[0m, float32_28<64>\u001b[0m, float32_29<64>\u001b[0m, False, 0.01, 0.001) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_25<1,64,56,56>\u001b[0m, float32_28<64>\u001b[0m, float32_29<64>\u001b[0m, float32_26<64>\u001b[0m, float32_27<64>\u001b[0m, False, 0.01, 0.001, True) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_30<1,64,56,56>\u001b[0m) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_30<1,64,56,56>\u001b[0m, inplace=True) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_30<1,64,56,56>\u001b[0m) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_30<1,64,56,56>\u001b[0m) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_30<1,64,56,56>\u001b[0m) -> float32_32<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_30<1,64,56,56>\u001b[0m, float32_31<24,64,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_32<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_32<1,24,56,56>\u001b[0m) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_32<1,24,56,56>\u001b[0m, float32_33<24>\u001b[0m, float32_33<24>\u001b[0m, float32_34<24>\u001b[0m, float32_33<24>\u001b[0m, False, 0.01, 0.001) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_32<1,24,56,56>\u001b[0m, float32_34<24>\u001b[0m, float32_33<24>\u001b[0m, float32_33<24>\u001b[0m, float32_33<24>\u001b[0m, False, 0.01, 0.001, True) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_35<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_35<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_35<1,24,56,56>\u001b[0m) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_35<1,24,56,56>\u001b[0m) -> float32_37<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_35<1,24,56,56>\u001b[0m, float32_36<72,24,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_37<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_37<1,72,56,56>\u001b[0m) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_37<1,72,56,56>\u001b[0m, float32_38<72>\u001b[0m, float32_39<72>\u001b[0m, float32_40<72>\u001b[0m, float32_41<72>\u001b[0m, False, 0.01, 0.001) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_37<1,72,56,56>\u001b[0m, float32_40<72>\u001b[0m, float32_41<72>\u001b[0m, float32_38<72>\u001b[0m, float32_39<72>\u001b[0m, False, 0.01, 0.001, True) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_42<1,72,56,56>\u001b[0m) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_42<1,72,56,56>\u001b[0m, inplace=True) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_42<1,72,56,56>\u001b[0m) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_42<1,72,56,56>\u001b[0m) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_42<1,72,56,56>\u001b[0m) -> float32_44<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_42<1,72,56,56>\u001b[0m, float32_43<72,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 72) -> float32_44<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_44<1,72,56,56>\u001b[0m) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_44<1,72,56,56>\u001b[0m, float32_45<72>\u001b[0m, float32_46<72>\u001b[0m, float32_47<72>\u001b[0m, float32_47<72>\u001b[0m, False, 0.01, 0.001) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_44<1,72,56,56>\u001b[0m, float32_47<72>\u001b[0m, float32_47<72>\u001b[0m, float32_45<72>\u001b[0m, float32_46<72>\u001b[0m, False, 0.01, 0.001, True) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_48<1,72,56,56>\u001b[0m) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_48<1,72,56,56>\u001b[0m, inplace=True) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_48<1,72,56,56>\u001b[0m) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_48<1,72,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_48<1,72,56,56>\u001b[0m) -> float32_50<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_48<1,72,56,56>\u001b[0m, float32_49<24,72,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_50<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_50<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_50<1,24,56,56>\u001b[0m, float32_51<24>\u001b[0m, float32_52<24>\u001b[0m, float32_53<24>\u001b[0m, float32_52<24>\u001b[0m, False, 0.01, 0.001) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_50<1,24,56,56>\u001b[0m, float32_53<24>\u001b[0m, float32_52<24>\u001b[0m, float32_51<24>\u001b[0m, float32_52<24>\u001b[0m, False, 0.01, 0.001, True) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_54<1,24,56,56>\u001b[0m, float32_35<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_54<1,24,56,56>\u001b[0m, float32_35<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_54<1,24,56,56>\u001b[0m) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_54<1,24,56,56>\u001b[0m) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_54<1,24,56,56>\u001b[0m) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_54<1,24,56,56>\u001b[0m) -> float32_56<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_54<1,24,56,56>\u001b[0m, float32_55<72,24,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_56<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_56<1,72,56,56>\u001b[0m) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_56<1,72,56,56>\u001b[0m, float32_57<72>\u001b[0m, float32_57<72>\u001b[0m, float32_58<72>\u001b[0m, float32_59<72>\u001b[0m, False, 0.01, 0.001) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_56<1,72,56,56>\u001b[0m, float32_58<72>\u001b[0m, float32_59<72>\u001b[0m, float32_57<72>\u001b[0m, float32_57<72>\u001b[0m, False, 0.01, 0.001, True) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_60<1,72,56,56>\u001b[0m) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_60<1,72,56,56>\u001b[0m, inplace=True) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_60<1,72,56,56>\u001b[0m) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_60<1,72,56,56>\u001b[0m) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_60<1,72,56,56>\u001b[0m) -> float32_62<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_60<1,72,56,56>\u001b[0m, float32_61<72,1,5,5>\u001b[0m, None, (2, 2), (2, 2), (1, 1), 72) -> float32_62<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_62<1,72,28,28>\u001b[0m) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_62<1,72,28,28>\u001b[0m, float32_63<72>\u001b[0m, float32_64<72>\u001b[0m, float32_65<72>\u001b[0m, float32_66<72>\u001b[0m, False, 0.01, 0.001) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_62<1,72,28,28>\u001b[0m, float32_65<72>\u001b[0m, float32_66<72>\u001b[0m, float32_63<72>\u001b[0m, float32_64<72>\u001b[0m, False, 0.01, 0.001, True) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_67<1,72,28,28>\u001b[0m) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_67<1,72,28,28>\u001b[0m, inplace=True) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_67<1,72,28,28>\u001b[0m) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_67<1,72,28,28>\u001b[0m) -> float32_77<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_67<1,72,28,28>\u001b[0m) -> float32_68<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_67<1,72,28,28>\u001b[0m, 1) -> float32_68<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_68<1,72,1,1>\u001b[0m) -> float32_71<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_68<1,72,1,1>\u001b[0m, float32_69<24,72,1,1>\u001b[0m, float32_70<24>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_71<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_71<1,24,1,1>\u001b[0m) -> float32_72<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_71<1,24,1,1>\u001b[0m, inplace=False) -> float32_72<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_71<1,24,1,1>\u001b[0m) -> float32_72<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_72<1,24,1,1>\u001b[0m) -> float32_75<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_72<1,24,1,1>\u001b[0m, float32_73<72,24,1,1>\u001b[0m, float32_74<72>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_75<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_75<1,72,1,1>\u001b[0m) -> float32_76<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_75<1,72,1,1>\u001b[0m, False) -> float32_76<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_76<1,72,1,1>\u001b[0m, float32_67<1,72,28,28>\u001b[0m) -> float32_77<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_76<1,72,1,1>\u001b[0m, float32_67<1,72,28,28>\u001b[0m) -> float32_77<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_77<1,72,28,28>\u001b[0m) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_77<1,72,28,28>\u001b[0m) -> float32_79<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_77<1,72,28,28>\u001b[0m, float32_78<40,72,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_79<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_79<1,40,28,28>\u001b[0m) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_79<1,40,28,28>\u001b[0m, float32_80<40>\u001b[0m, float32_81<40>\u001b[0m, float32_80<40>\u001b[0m, float32_82<40>\u001b[0m, False, 0.01, 0.001) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_79<1,40,28,28>\u001b[0m, float32_80<40>\u001b[0m, float32_82<40>\u001b[0m, float32_80<40>\u001b[0m, float32_81<40>\u001b[0m, False, 0.01, 0.001, True) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_83<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_83<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_83<1,40,28,28>\u001b[0m) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_83<1,40,28,28>\u001b[0m) -> float32_85<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_83<1,40,28,28>\u001b[0m, float32_84<120,40,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_85<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_85<1,120,28,28>\u001b[0m) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_85<1,120,28,28>\u001b[0m, float32_86<120>\u001b[0m, float32_87<120>\u001b[0m, float32_88<120>\u001b[0m, float32_86<120>\u001b[0m, False, 0.01, 0.001) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_85<1,120,28,28>\u001b[0m, float32_88<120>\u001b[0m, float32_86<120>\u001b[0m, float32_86<120>\u001b[0m, float32_87<120>\u001b[0m, False, 0.01, 0.001, True) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_89<1,120,28,28>\u001b[0m) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_89<1,120,28,28>\u001b[0m, inplace=True) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_89<1,120,28,28>\u001b[0m) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_89<1,120,28,28>\u001b[0m) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_89<1,120,28,28>\u001b[0m) -> float32_91<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_89<1,120,28,28>\u001b[0m, float32_90<120,1,5,5>\u001b[0m, None, (1, 1), (2, 2), (1, 1), 120) -> float32_91<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_91<1,120,28,28>\u001b[0m) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_91<1,120,28,28>\u001b[0m, float32_92<120>\u001b[0m, float32_93<120>\u001b[0m, float32_92<120>\u001b[0m, float32_94<120>\u001b[0m, False, 0.01, 0.001) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_91<1,120,28,28>\u001b[0m, float32_92<120>\u001b[0m, float32_94<120>\u001b[0m, float32_92<120>\u001b[0m, float32_93<120>\u001b[0m, False, 0.01, 0.001, True) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_95<1,120,28,28>\u001b[0m) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_95<1,120,28,28>\u001b[0m, inplace=True) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_95<1,120,28,28>\u001b[0m) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_95<1,120,28,28>\u001b[0m) -> float32_104<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_95<1,120,28,28>\u001b[0m) -> float32_96<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_95<1,120,28,28>\u001b[0m, 1) -> float32_96<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_96<1,120,1,1>\u001b[0m) -> float32_99<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_96<1,120,1,1>\u001b[0m, float32_97<32,120,1,1>\u001b[0m, float32_98<32>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_99<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_99<1,32,1,1>\u001b[0m) -> float32_100<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_99<1,32,1,1>\u001b[0m, inplace=False) -> float32_100<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_99<1,32,1,1>\u001b[0m) -> float32_100<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_100<1,32,1,1>\u001b[0m) -> float32_102<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_100<1,32,1,1>\u001b[0m, float32_101<120,32,1,1>\u001b[0m, float32_101<120>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_102<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_102<1,120,1,1>\u001b[0m) -> float32_103<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_102<1,120,1,1>\u001b[0m, False) -> float32_103<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_103<1,120,1,1>\u001b[0m, float32_95<1,120,28,28>\u001b[0m) -> float32_104<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_103<1,120,1,1>\u001b[0m, float32_95<1,120,28,28>\u001b[0m) -> float32_104<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_104<1,120,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_104<1,120,28,28>\u001b[0m) -> float32_106<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_104<1,120,28,28>\u001b[0m, float32_105<40,120,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_106<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_106<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_106<1,40,28,28>\u001b[0m, float32_107<40>\u001b[0m, float32_108<40>\u001b[0m, float32_109<40>\u001b[0m, float32_109<40>\u001b[0m, False, 0.01, 0.001) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_106<1,40,28,28>\u001b[0m, float32_109<40>\u001b[0m, float32_109<40>\u001b[0m, float32_107<40>\u001b[0m, float32_108<40>\u001b[0m, False, 0.01, 0.001, True) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_110<1,40,28,28>\u001b[0m, float32_83<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_110<1,40,28,28>\u001b[0m, float32_83<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_110<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_110<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_110<1,40,28,28>\u001b[0m) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_110<1,40,28,28>\u001b[0m) -> float32_112<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_110<1,40,28,28>\u001b[0m, float32_111<120,40,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_112<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_112<1,120,28,28>\u001b[0m) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_112<1,120,28,28>\u001b[0m, float32_113<120>\u001b[0m, float32_114<120>\u001b[0m, float32_115<120>\u001b[0m, float32_113<120>\u001b[0m, False, 0.01, 0.001) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_112<1,120,28,28>\u001b[0m, float32_115<120>\u001b[0m, float32_113<120>\u001b[0m, float32_113<120>\u001b[0m, float32_114<120>\u001b[0m, False, 0.01, 0.001, True) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_116<1,120,28,28>\u001b[0m) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_116<1,120,28,28>\u001b[0m, inplace=True) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_116<1,120,28,28>\u001b[0m) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_116<1,120,28,28>\u001b[0m) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_116<1,120,28,28>\u001b[0m) -> float32_118<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_116<1,120,28,28>\u001b[0m, float32_117<120,1,5,5>\u001b[0m, None, (1, 1), (2, 2), (1, 1), 120) -> float32_118<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_118<1,120,28,28>\u001b[0m) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_118<1,120,28,28>\u001b[0m, float32_119<120>\u001b[0m, float32_120<120>\u001b[0m, float32_121<120>\u001b[0m, float32_120<120>\u001b[0m, False, 0.01, 0.001) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_118<1,120,28,28>\u001b[0m, float32_121<120>\u001b[0m, float32_120<120>\u001b[0m, float32_119<120>\u001b[0m, float32_120<120>\u001b[0m, False, 0.01, 0.001, True) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_122<1,120,28,28>\u001b[0m) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_122<1,120,28,28>\u001b[0m, inplace=True) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_122<1,120,28,28>\u001b[0m) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_122<1,120,28,28>\u001b[0m) -> float32_131<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_122<1,120,28,28>\u001b[0m) -> float32_123<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_122<1,120,28,28>\u001b[0m, 1) -> float32_123<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_123<1,120,1,1>\u001b[0m) -> float32_125<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_123<1,120,1,1>\u001b[0m, float32_124<32,120,1,1>\u001b[0m, float32_124<32>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_125<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_125<1,32,1,1>\u001b[0m) -> float32_126<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_125<1,32,1,1>\u001b[0m, inplace=False) -> float32_126<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_125<1,32,1,1>\u001b[0m) -> float32_126<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_126<1,32,1,1>\u001b[0m) -> float32_129<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_126<1,32,1,1>\u001b[0m, float32_127<120,32,1,1>\u001b[0m, float32_128<120>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_129<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_129<1,120,1,1>\u001b[0m) -> float32_130<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_129<1,120,1,1>\u001b[0m, False) -> float32_130<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_130<1,120,1,1>\u001b[0m, float32_122<1,120,28,28>\u001b[0m) -> float32_131<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_130<1,120,1,1>\u001b[0m, float32_122<1,120,28,28>\u001b[0m) -> float32_131<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_131<1,120,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_131<1,120,28,28>\u001b[0m) -> float32_133<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_131<1,120,28,28>\u001b[0m, float32_132<40,120,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_133<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_133<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_133<1,40,28,28>\u001b[0m, float32_134<40>\u001b[0m, float32_134<40>\u001b[0m, float32_135<40>\u001b[0m, float32_136<40>\u001b[0m, False, 0.01, 0.001) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_133<1,40,28,28>\u001b[0m, float32_135<40>\u001b[0m, float32_136<40>\u001b[0m, float32_134<40>\u001b[0m, float32_134<40>\u001b[0m, False, 0.01, 0.001, True) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_137<1,40,28,28>\u001b[0m, float32_110<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_137<1,40,28,28>\u001b[0m, float32_110<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_137<1,40,28,28>\u001b[0m) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_137<1,40,28,28>\u001b[0m) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_137<1,40,28,28>\u001b[0m) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_137<1,40,28,28>\u001b[0m) -> float32_139<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_137<1,40,28,28>\u001b[0m, float32_138<240,40,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_139<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_139<1,240,28,28>\u001b[0m) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_139<1,240,28,28>\u001b[0m, float32_140<240>\u001b[0m, float32_141<240>\u001b[0m, float32_141<240>\u001b[0m, float32_140<240>\u001b[0m, False, 0.01, 0.001) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_139<1,240,28,28>\u001b[0m, float32_141<240>\u001b[0m, float32_140<240>\u001b[0m, float32_140<240>\u001b[0m, float32_141<240>\u001b[0m, False, 0.01, 0.001, True) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_142<1,240,28,28>\u001b[0m) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_142<1,240,28,28>\u001b[0m, True) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_142<1,240,28,28>\u001b[0m) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_142<1,240,28,28>\u001b[0m) -> float32_144<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_142<1,240,28,28>\u001b[0m, float32_143<240,1,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 240) -> float32_144<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_144<1,240,14,14>\u001b[0m) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_144<1,240,14,14>\u001b[0m, float32_145<240>\u001b[0m, float32_145<240>\u001b[0m, float32_145<240>\u001b[0m, float32_146<240>\u001b[0m, False, 0.01, 0.001) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_144<1,240,14,14>\u001b[0m, float32_145<240>\u001b[0m, float32_146<240>\u001b[0m, float32_145<240>\u001b[0m, float32_145<240>\u001b[0m, False, 0.01, 0.001, True) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_147<1,240,14,14>\u001b[0m) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_147<1,240,14,14>\u001b[0m, True) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_147<1,240,14,14>\u001b[0m) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_147<1,240,14,14>\u001b[0m) -> float32_149<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_147<1,240,14,14>\u001b[0m, float32_148<80,240,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_149<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_149<1,80,14,14>\u001b[0m) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_149<1,80,14,14>\u001b[0m, float32_150<80>\u001b[0m, float32_150<80>\u001b[0m, float32_150<80>\u001b[0m, float32_151<80>\u001b[0m, False, 0.01, 0.001) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_149<1,80,14,14>\u001b[0m, float32_150<80>\u001b[0m, float32_151<80>\u001b[0m, float32_150<80>\u001b[0m, float32_150<80>\u001b[0m, False, 0.01, 0.001, True) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_152<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_152<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_152<1,80,14,14>\u001b[0m) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_152<1,80,14,14>\u001b[0m) -> float32_154<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_152<1,80,14,14>\u001b[0m, float32_153<200,80,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_154<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_154<1,200,14,14>\u001b[0m) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_154<1,200,14,14>\u001b[0m, float32_155<200>\u001b[0m, float32_155<200>\u001b[0m, float32_156<200>\u001b[0m, float32_157<200>\u001b[0m, False, 0.01, 0.001) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_154<1,200,14,14>\u001b[0m, float32_156<200>\u001b[0m, float32_157<200>\u001b[0m, float32_155<200>\u001b[0m, float32_155<200>\u001b[0m, False, 0.01, 0.001, True) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_158<1,200,14,14>\u001b[0m) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_158<1,200,14,14>\u001b[0m, True) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_158<1,200,14,14>\u001b[0m) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_158<1,200,14,14>\u001b[0m) -> float32_160<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_158<1,200,14,14>\u001b[0m, float32_159<200,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 200) -> float32_160<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_160<1,200,14,14>\u001b[0m) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_160<1,200,14,14>\u001b[0m, float32_161<200>\u001b[0m, float32_162<200>\u001b[0m, float32_161<200>\u001b[0m, float32_162<200>\u001b[0m, False, 0.01, 0.001) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_160<1,200,14,14>\u001b[0m, float32_161<200>\u001b[0m, float32_162<200>\u001b[0m, float32_161<200>\u001b[0m, float32_162<200>\u001b[0m, False, 0.01, 0.001, True) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_163<1,200,14,14>\u001b[0m) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_163<1,200,14,14>\u001b[0m, True) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_163<1,200,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_163<1,200,14,14>\u001b[0m) -> float32_165<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_163<1,200,14,14>\u001b[0m, float32_164<80,200,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_165<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_165<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_165<1,80,14,14>\u001b[0m, float32_166<80>\u001b[0m, float32_167<80>\u001b[0m, float32_167<80>\u001b[0m, float32_167<80>\u001b[0m, False, 0.01, 0.001) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_165<1,80,14,14>\u001b[0m, float32_167<80>\u001b[0m, float32_167<80>\u001b[0m, float32_166<80>\u001b[0m, float32_167<80>\u001b[0m, False, 0.01, 0.001, True) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_168<1,80,14,14>\u001b[0m, float32_152<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_168<1,80,14,14>\u001b[0m, float32_152<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_168<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_168<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_168<1,80,14,14>\u001b[0m) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_168<1,80,14,14>\u001b[0m) -> float32_170<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_168<1,80,14,14>\u001b[0m, float32_169<184,80,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_170<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_170<1,184,14,14>\u001b[0m) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_170<1,184,14,14>\u001b[0m, float32_171<184>\u001b[0m, float32_172<184>\u001b[0m, float32_173<184>\u001b[0m, float32_173<184>\u001b[0m, False, 0.01, 0.001) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_170<1,184,14,14>\u001b[0m, float32_173<184>\u001b[0m, float32_173<184>\u001b[0m, float32_171<184>\u001b[0m, float32_172<184>\u001b[0m, False, 0.01, 0.001, True) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_174<1,184,14,14>\u001b[0m) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_174<1,184,14,14>\u001b[0m, True) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_174<1,184,14,14>\u001b[0m) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_174<1,184,14,14>\u001b[0m) -> float32_176<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_174<1,184,14,14>\u001b[0m, float32_175<184,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 184) -> float32_176<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_176<1,184,14,14>\u001b[0m) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_176<1,184,14,14>\u001b[0m, float32_177<184>\u001b[0m, float32_178<184>\u001b[0m, float32_179<184>\u001b[0m, float32_179<184>\u001b[0m, False, 0.01, 0.001) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_176<1,184,14,14>\u001b[0m, float32_179<184>\u001b[0m, float32_179<184>\u001b[0m, float32_177<184>\u001b[0m, float32_178<184>\u001b[0m, False, 0.01, 0.001, True) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_180<1,184,14,14>\u001b[0m) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_180<1,184,14,14>\u001b[0m, True) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_180<1,184,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_180<1,184,14,14>\u001b[0m) -> float32_182<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_180<1,184,14,14>\u001b[0m, float32_181<80,184,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_182<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_182<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_182<1,80,14,14>\u001b[0m, float32_183<80>\u001b[0m, float32_183<80>\u001b[0m, float32_183<80>\u001b[0m, float32_184<80>\u001b[0m, False, 0.01, 0.001) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_182<1,80,14,14>\u001b[0m, float32_183<80>\u001b[0m, float32_184<80>\u001b[0m, float32_183<80>\u001b[0m, float32_183<80>\u001b[0m, False, 0.01, 0.001, True) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_185<1,80,14,14>\u001b[0m, float32_168<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_185<1,80,14,14>\u001b[0m, float32_168<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_185<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_185<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_185<1,80,14,14>\u001b[0m) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_185<1,80,14,14>\u001b[0m) -> float32_187<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_185<1,80,14,14>\u001b[0m, float32_186<184,80,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_187<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_187<1,184,14,14>\u001b[0m) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_187<1,184,14,14>\u001b[0m, float32_188<184>\u001b[0m, float32_189<184>\u001b[0m, float32_189<184>\u001b[0m, float32_189<184>\u001b[0m, False, 0.01, 0.001) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_187<1,184,14,14>\u001b[0m, float32_189<184>\u001b[0m, float32_189<184>\u001b[0m, float32_188<184>\u001b[0m, float32_189<184>\u001b[0m, False, 0.01, 0.001, True) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_190<1,184,14,14>\u001b[0m) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_190<1,184,14,14>\u001b[0m, True) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_190<1,184,14,14>\u001b[0m) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_190<1,184,14,14>\u001b[0m) -> float32_192<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_190<1,184,14,14>\u001b[0m, float32_191<184,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 184) -> float32_192<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_192<1,184,14,14>\u001b[0m) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_192<1,184,14,14>\u001b[0m, float32_193<184>\u001b[0m, float32_194<184>\u001b[0m, float32_194<184>\u001b[0m, float32_194<184>\u001b[0m, False, 0.01, 0.001) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_192<1,184,14,14>\u001b[0m, float32_194<184>\u001b[0m, float32_194<184>\u001b[0m, float32_193<184>\u001b[0m, float32_194<184>\u001b[0m, False, 0.01, 0.001, True) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_195<1,184,14,14>\u001b[0m) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_195<1,184,14,14>\u001b[0m, True) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_195<1,184,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_195<1,184,14,14>\u001b[0m) -> float32_197<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_195<1,184,14,14>\u001b[0m, float32_196<80,184,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_197<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_197<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_197<1,80,14,14>\u001b[0m, float32_198<80>\u001b[0m, float32_198<80>\u001b[0m, float32_199<80>\u001b[0m, float32_198<80>\u001b[0m, False, 0.01, 0.001) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_197<1,80,14,14>\u001b[0m, float32_199<80>\u001b[0m, float32_198<80>\u001b[0m, float32_198<80>\u001b[0m, float32_198<80>\u001b[0m, False, 0.01, 0.001, True) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_200<1,80,14,14>\u001b[0m, float32_185<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_200<1,80,14,14>\u001b[0m, float32_185<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_200<1,80,14,14>\u001b[0m) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_200<1,80,14,14>\u001b[0m) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_200<1,80,14,14>\u001b[0m) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_200<1,80,14,14>\u001b[0m) -> float32_202<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_200<1,80,14,14>\u001b[0m, float32_201<480,80,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_202<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_202<1,480,14,14>\u001b[0m) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_202<1,480,14,14>\u001b[0m, float32_203<480>\u001b[0m, float32_204<480>\u001b[0m, float32_205<480>\u001b[0m, float32_206<480>\u001b[0m, False, 0.01, 0.001) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_202<1,480,14,14>\u001b[0m, float32_205<480>\u001b[0m, float32_206<480>\u001b[0m, float32_203<480>\u001b[0m, float32_204<480>\u001b[0m, False, 0.01, 0.001, True) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_207<1,480,14,14>\u001b[0m) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_207<1,480,14,14>\u001b[0m, True) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_207<1,480,14,14>\u001b[0m) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_207<1,480,14,14>\u001b[0m) -> float32_209<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_207<1,480,14,14>\u001b[0m, float32_208<480,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 480) -> float32_209<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_209<1,480,14,14>\u001b[0m) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_209<1,480,14,14>\u001b[0m, float32_210<480>\u001b[0m, float32_211<480>\u001b[0m, float32_212<480>\u001b[0m, float32_213<480>\u001b[0m, False, 0.01, 0.001) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_209<1,480,14,14>\u001b[0m, float32_212<480>\u001b[0m, float32_213<480>\u001b[0m, float32_210<480>\u001b[0m, float32_211<480>\u001b[0m, False, 0.01, 0.001, True) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_214<1,480,14,14>\u001b[0m) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_214<1,480,14,14>\u001b[0m, True) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_214<1,480,14,14>\u001b[0m) -> float32_224<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_214<1,480,14,14>\u001b[0m) -> float32_215<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_214<1,480,14,14>\u001b[0m, 1) -> float32_215<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_215<1,480,1,1>\u001b[0m) -> float32_218<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_215<1,480,1,1>\u001b[0m, float32_216<120,480,1,1>\u001b[0m, float32_217<120>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_218<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_218<1,120,1,1>\u001b[0m) -> float32_219<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_218<1,120,1,1>\u001b[0m, inplace=False) -> float32_219<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_218<1,120,1,1>\u001b[0m) -> float32_219<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_219<1,120,1,1>\u001b[0m) -> float32_222<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_219<1,120,1,1>\u001b[0m, float32_220<480,120,1,1>\u001b[0m, float32_221<480>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_222<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_222<1,480,1,1>\u001b[0m) -> float32_223<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_222<1,480,1,1>\u001b[0m, False) -> float32_223<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_223<1,480,1,1>\u001b[0m, float32_214<1,480,14,14>\u001b[0m) -> float32_224<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_223<1,480,1,1>\u001b[0m, float32_214<1,480,14,14>\u001b[0m) -> float32_224<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_224<1,480,14,14>\u001b[0m) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_224<1,480,14,14>\u001b[0m) -> float32_226<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_224<1,480,14,14>\u001b[0m, float32_225<112,480,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_226<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_226<1,112,14,14>\u001b[0m) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_226<1,112,14,14>\u001b[0m, float32_227<112>\u001b[0m, float32_228<112>\u001b[0m, float32_228<112>\u001b[0m, float32_229<112>\u001b[0m, False, 0.01, 0.001) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_226<1,112,14,14>\u001b[0m, float32_228<112>\u001b[0m, float32_229<112>\u001b[0m, float32_227<112>\u001b[0m, float32_228<112>\u001b[0m, False, 0.01, 0.001, True) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_230<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_230<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_230<1,112,14,14>\u001b[0m) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_230<1,112,14,14>\u001b[0m) -> float32_232<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_230<1,112,14,14>\u001b[0m, float32_231<672,112,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_232<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_232<1,672,14,14>\u001b[0m) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_232<1,672,14,14>\u001b[0m, float32_233<672>\u001b[0m, float32_234<672>\u001b[0m, float32_235<672>\u001b[0m, float32_234<672>\u001b[0m, False, 0.01, 0.001) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_232<1,672,14,14>\u001b[0m, float32_235<672>\u001b[0m, float32_234<672>\u001b[0m, float32_233<672>\u001b[0m, float32_234<672>\u001b[0m, False, 0.01, 0.001, True) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_236<1,672,14,14>\u001b[0m) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_236<1,672,14,14>\u001b[0m, True) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_236<1,672,14,14>\u001b[0m) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_236<1,672,14,14>\u001b[0m) -> float32_238<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_236<1,672,14,14>\u001b[0m, float32_237<672,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 672) -> float32_238<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_238<1,672,14,14>\u001b[0m) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_238<1,672,14,14>\u001b[0m, float32_239<672>\u001b[0m, float32_240<672>\u001b[0m, float32_241<672>\u001b[0m, float32_242<672>\u001b[0m, False, 0.01, 0.001) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_238<1,672,14,14>\u001b[0m, float32_241<672>\u001b[0m, float32_242<672>\u001b[0m, float32_239<672>\u001b[0m, float32_240<672>\u001b[0m, False, 0.01, 0.001, True) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_243<1,672,14,14>\u001b[0m) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_243<1,672,14,14>\u001b[0m, True) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_243<1,672,14,14>\u001b[0m) -> float32_252<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_243<1,672,14,14>\u001b[0m) -> float32_244<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_243<1,672,14,14>\u001b[0m, 1) -> float32_244<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_244<1,672,1,1>\u001b[0m) -> float32_247<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_244<1,672,1,1>\u001b[0m, float32_245<168,672,1,1>\u001b[0m, float32_246<168>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_247<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_247<1,168,1,1>\u001b[0m) -> float32_248<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_247<1,168,1,1>\u001b[0m, inplace=False) -> float32_248<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_247<1,168,1,1>\u001b[0m) -> float32_248<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_248<1,168,1,1>\u001b[0m) -> float32_250<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_248<1,168,1,1>\u001b[0m, float32_249<672,168,1,1>\u001b[0m, float32_249<672>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_250<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_250<1,672,1,1>\u001b[0m) -> float32_251<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_250<1,672,1,1>\u001b[0m, False) -> float32_251<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_251<1,672,1,1>\u001b[0m, float32_243<1,672,14,14>\u001b[0m) -> float32_252<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_251<1,672,1,1>\u001b[0m, float32_243<1,672,14,14>\u001b[0m) -> float32_252<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_252<1,672,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_252<1,672,14,14>\u001b[0m) -> float32_254<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_252<1,672,14,14>\u001b[0m, float32_253<112,672,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_254<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_254<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_254<1,112,14,14>\u001b[0m, float32_255<112>\u001b[0m, float32_256<112>\u001b[0m, float32_255<112>\u001b[0m, float32_255<112>\u001b[0m, False, 0.01, 0.001) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_254<1,112,14,14>\u001b[0m, float32_255<112>\u001b[0m, float32_255<112>\u001b[0m, float32_255<112>\u001b[0m, float32_256<112>\u001b[0m, False, 0.01, 0.001, True) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_257<1,112,14,14>\u001b[0m, float32_230<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_257<1,112,14,14>\u001b[0m, float32_230<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_257<1,112,14,14>\u001b[0m) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_257<1,112,14,14>\u001b[0m) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_257<1,112,14,14>\u001b[0m) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_257<1,112,14,14>\u001b[0m) -> float32_259<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_257<1,112,14,14>\u001b[0m, float32_258<672,112,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_259<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_259<1,672,14,14>\u001b[0m) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_259<1,672,14,14>\u001b[0m, float32_260<672>\u001b[0m, float32_261<672>\u001b[0m, float32_260<672>\u001b[0m, float32_262<672>\u001b[0m, False, 0.01, 0.001) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_259<1,672,14,14>\u001b[0m, float32_260<672>\u001b[0m, float32_262<672>\u001b[0m, float32_260<672>\u001b[0m, float32_261<672>\u001b[0m, False, 0.01, 0.001, True) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_263<1,672,14,14>\u001b[0m) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_263<1,672,14,14>\u001b[0m, True) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_263<1,672,14,14>\u001b[0m) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_263<1,672,14,14>\u001b[0m) -> float32_265<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_263<1,672,14,14>\u001b[0m, float32_264<672,1,5,5>\u001b[0m, None, (2, 2), (2, 2), (1, 1), 672) -> float32_265<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_265<1,672,7,7>\u001b[0m) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_265<1,672,7,7>\u001b[0m, float32_266<672>\u001b[0m, float32_267<672>\u001b[0m, float32_268<672>\u001b[0m, float32_268<672>\u001b[0m, False, 0.01, 0.001) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_265<1,672,7,7>\u001b[0m, float32_268<672>\u001b[0m, float32_268<672>\u001b[0m, float32_266<672>\u001b[0m, float32_267<672>\u001b[0m, False, 0.01, 0.001, True) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_269<1,672,7,7>\u001b[0m) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_269<1,672,7,7>\u001b[0m, True) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_269<1,672,7,7>\u001b[0m) -> float32_279<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_269<1,672,7,7>\u001b[0m) -> float32_270<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_269<1,672,7,7>\u001b[0m, 1) -> float32_270<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_270<1,672,1,1>\u001b[0m) -> float32_273<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_270<1,672,1,1>\u001b[0m, float32_271<168,672,1,1>\u001b[0m, float32_272<168>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_273<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_273<1,168,1,1>\u001b[0m) -> float32_274<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_273<1,168,1,1>\u001b[0m, inplace=False) -> float32_274<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_273<1,168,1,1>\u001b[0m) -> float32_274<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_274<1,168,1,1>\u001b[0m) -> float32_277<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_274<1,168,1,1>\u001b[0m, float32_275<672,168,1,1>\u001b[0m, float32_276<672>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_277<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_277<1,672,1,1>\u001b[0m) -> float32_278<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_277<1,672,1,1>\u001b[0m, False) -> float32_278<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_278<1,672,1,1>\u001b[0m, float32_269<1,672,7,7>\u001b[0m) -> float32_279<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_278<1,672,1,1>\u001b[0m, float32_269<1,672,7,7>\u001b[0m) -> float32_279<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_279<1,672,7,7>\u001b[0m) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_279<1,672,7,7>\u001b[0m) -> float32_281<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_279<1,672,7,7>\u001b[0m, float32_280<160,672,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_281<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_281<1,160,7,7>\u001b[0m) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_281<1,160,7,7>\u001b[0m, float32_282<160>\u001b[0m, float32_283<160>\u001b[0m, float32_284<160>\u001b[0m, float32_285<160>\u001b[0m, False, 0.01, 0.001) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_281<1,160,7,7>\u001b[0m, float32_284<160>\u001b[0m, float32_285<160>\u001b[0m, float32_282<160>\u001b[0m, float32_283<160>\u001b[0m, False, 0.01, 0.001, True) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_286<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_286<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_286<1,160,7,7>\u001b[0m) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_286<1,160,7,7>\u001b[0m) -> float32_288<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_286<1,160,7,7>\u001b[0m, float32_287<960,160,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_288<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_288<1,960,7,7>\u001b[0m) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_288<1,960,7,7>\u001b[0m, float32_289<960>\u001b[0m, float32_290<960>\u001b[0m, float32_291<960>\u001b[0m, float32_290<960>\u001b[0m, False, 0.01, 0.001) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_288<1,960,7,7>\u001b[0m, float32_291<960>\u001b[0m, float32_290<960>\u001b[0m, float32_289<960>\u001b[0m, float32_290<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_292<1,960,7,7>\u001b[0m) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_292<1,960,7,7>\u001b[0m, True) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_292<1,960,7,7>\u001b[0m) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_292<1,960,7,7>\u001b[0m) -> float32_294<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_292<1,960,7,7>\u001b[0m, float32_293<960,1,5,5>\u001b[0m, None, (1, 1), (2, 2), (1, 1), 960) -> float32_294<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_294<1,960,7,7>\u001b[0m) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_294<1,960,7,7>\u001b[0m, float32_295<960>\u001b[0m, float32_296<960>\u001b[0m, float32_297<960>\u001b[0m, float32_296<960>\u001b[0m, False, 0.01, 0.001) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_294<1,960,7,7>\u001b[0m, float32_297<960>\u001b[0m, float32_296<960>\u001b[0m, float32_295<960>\u001b[0m, float32_296<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_298<1,960,7,7>\u001b[0m) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_298<1,960,7,7>\u001b[0m, True) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_298<1,960,7,7>\u001b[0m) -> float32_308<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_298<1,960,7,7>\u001b[0m) -> float32_299<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_298<1,960,7,7>\u001b[0m, 1) -> float32_299<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_299<1,960,1,1>\u001b[0m) -> float32_302<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_299<1,960,1,1>\u001b[0m, float32_300<240,960,1,1>\u001b[0m, float32_301<240>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_302<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_302<1,240,1,1>\u001b[0m) -> float32_303<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_302<1,240,1,1>\u001b[0m, inplace=False) -> float32_303<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_302<1,240,1,1>\u001b[0m) -> float32_303<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_303<1,240,1,1>\u001b[0m) -> float32_306<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_303<1,240,1,1>\u001b[0m, float32_304<960,240,1,1>\u001b[0m, float32_305<960>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_306<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_306<1,960,1,1>\u001b[0m) -> float32_307<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_306<1,960,1,1>\u001b[0m, False) -> float32_307<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_307<1,960,1,1>\u001b[0m, float32_298<1,960,7,7>\u001b[0m) -> float32_308<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_307<1,960,1,1>\u001b[0m, float32_298<1,960,7,7>\u001b[0m) -> float32_308<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_308<1,960,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_308<1,960,7,7>\u001b[0m) -> float32_310<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_308<1,960,7,7>\u001b[0m, float32_309<160,960,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_310<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_310<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_310<1,160,7,7>\u001b[0m, float32_311<160>\u001b[0m, float32_312<160>\u001b[0m, float32_311<160>\u001b[0m, float32_313<160>\u001b[0m, False, 0.01, 0.001) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_310<1,160,7,7>\u001b[0m, float32_311<160>\u001b[0m, float32_313<160>\u001b[0m, float32_311<160>\u001b[0m, float32_312<160>\u001b[0m, False, 0.01, 0.001, True) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_314<1,160,7,7>\u001b[0m, float32_286<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_314<1,160,7,7>\u001b[0m, float32_286<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m\u001b[7m (!) Max diff 0.00013 (0.000%) \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"C:\\Users\\louis\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py\", line 217\u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"C:/Users/louis/AppData/Roaming/Python/Python311/site-packages/torchvision/models/mobilenetv3.py\", line 52 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_314<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m\u001b[7m (!) Max diff 0.00013 (0.000%) \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"C:\\Users\\louis\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\mobilenetv3.py\", line 111\u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"C:/Users/louis/AppData/Roaming/Python/Python311/site-packages/torch/nn/modules/container.py\", line 43 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33mSequential[torch.nn.modules.container]\u001b[0m(float32_314<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_314<1,160,7,7>\u001b[0m) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_314<1,160,7,7>\u001b[0m) -> float32_316<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_314<1,160,7,7>\u001b[0m, float32_315<960,160,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_316<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_316<1,960,7,7>\u001b[0m) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_316<1,960,7,7>\u001b[0m, float32_317<960>\u001b[0m, float32_318<960>\u001b[0m, float32_317<960>\u001b[0m, float32_319<960>\u001b[0m, False, 0.01, 0.001) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_316<1,960,7,7>\u001b[0m, float32_317<960>\u001b[0m, float32_319<960>\u001b[0m, float32_317<960>\u001b[0m, float32_318<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_320<1,960,7,7>\u001b[0m) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_320<1,960,7,7>\u001b[0m, True) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_320<1,960,7,7>\u001b[0m) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_320<1,960,7,7>\u001b[0m) -> float32_322<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_320<1,960,7,7>\u001b[0m, float32_321<960,1,5,5>\u001b[0m, None, (1, 1), (2, 2), (1, 1), 960) -> float32_322<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_322<1,960,7,7>\u001b[0m) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_322<1,960,7,7>\u001b[0m, float32_323<960>\u001b[0m, float32_324<960>\u001b[0m, float32_325<960>\u001b[0m, float32_323<960>\u001b[0m, False, 0.01, 0.001) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_322<1,960,7,7>\u001b[0m, float32_325<960>\u001b[0m, float32_323<960>\u001b[0m, float32_323<960>\u001b[0m, float32_324<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_326<1,960,7,7>\u001b[0m) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_326<1,960,7,7>\u001b[0m, True) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_326<1,960,7,7>\u001b[0m) -> float32_336<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_326<1,960,7,7>\u001b[0m) -> float32_327<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_326<1,960,7,7>\u001b[0m, 1) -> float32_327<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_327<1,960,1,1>\u001b[0m) -> float32_330<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_327<1,960,1,1>\u001b[0m, float32_328<240,960,1,1>\u001b[0m, float32_329<240>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_330<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_330<1,240,1,1>\u001b[0m) -> float32_331<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_330<1,240,1,1>\u001b[0m, inplace=False) -> float32_331<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_330<1,240,1,1>\u001b[0m) -> float32_331<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_331<1,240,1,1>\u001b[0m) -> float32_334<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_331<1,240,1,1>\u001b[0m, float32_332<960,240,1,1>\u001b[0m, float32_333<960>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_334<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_334<1,960,1,1>\u001b[0m) -> float32_335<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_334<1,960,1,1>\u001b[0m, False) -> float32_335<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_335<1,960,1,1>\u001b[0m, float32_326<1,960,7,7>\u001b[0m) -> float32_336<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_335<1,960,1,1>\u001b[0m, float32_326<1,960,7,7>\u001b[0m) -> float32_336<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m\u001b[7m (!) Max diff 0.00014 (0.000%) \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"C:\\Users\\louis\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py\", line 217\u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"C:/Users/louis/AppData/Roaming/Python/Python311/site-packages/torchvision/ops/misc.py\", line 125 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m ├·\u001b[0m \u001b[33mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_336<1,960,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_336<1,960,7,7>\u001b[0m) -> float32_338<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_336<1,960,7,7>\u001b[0m, float32_337<160,960,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_338<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_338<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_338<1,160,7,7>\u001b[0m, float32_339<160>\u001b[0m, float32_340<160>\u001b[0m, float32_339<160>\u001b[0m, float32_339<160>\u001b[0m, False, 0.01, 0.001) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m └ \u001b[0m \u001b[33m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_338<1,160,7,7>\u001b[0m, float32_339<160>\u001b[0m, float32_339<160>\u001b[0m, float32_339<160>\u001b[0m, float32_340<160>\u001b[0m, False, 0.01, 0.001, True) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_341<1,160,7,7>\u001b[0m, float32_314<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_341<1,160,7,7>\u001b[0m, float32_314<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_341<1,160,7,7>\u001b[0m) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_341<1,160,7,7>\u001b[0m) -> float32_343<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_341<1,160,7,7>\u001b[0m, float32_342<960,160,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_343<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_343<1,960,7,7>\u001b[0m) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_343<1,960,7,7>\u001b[0m, float32_344<960>\u001b[0m, float32_344<960>\u001b[0m, float32_345<960>\u001b[0m, float32_345<960>\u001b[0m, False, 0.01, 0.001) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_343<1,960,7,7>\u001b[0m, float32_345<960>\u001b[0m, float32_345<960>\u001b[0m, float32_344<960>\u001b[0m, float32_344<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_346<1,960,7,7>\u001b[0m) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_346<1,960,7,7>\u001b[0m, True) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_346<1,960,7,7>\u001b[0m) -> float32_347<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_346<1,960,7,7>\u001b[0m, 1) -> float32_347<1,960,1,1>\u001b[0m\n",
      "\u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_347<1,960,1,1>\u001b[0m) -> float32_361<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_347<1,960,1,1>\u001b[0m) -> float32_348<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_347<1,960,1,1>\u001b[0m, 1) -> float32_348<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mFlatten[torch.nn.modules.flatten]\u001b[0m(float32_348<1,960,1,1>\u001b[0m) -> float32_349<1,960>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mflatten[torch.Tensor]\u001b[0m(float32_348<1,960,1,1>\u001b[0m, 1, -1) -> float32_349<1,960>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_349<1,960>\u001b[0m) -> float32_352<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_349<1,960>\u001b[0m, float32_350<1024,960>\u001b[0m, float32_351<1024>\u001b[0m) -> float32_352<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_352<1,1024>\u001b[0m) -> float32_353<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_352<1,1024>\u001b[0m, inplace=False) -> float32_353<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_352<1,1024>\u001b[0m) -> float32_353<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_353<1,1024>\u001b[0m) -> float32_356<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_353<1,1024>\u001b[0m, float32_354<512,1024>\u001b[0m, float32_355<512>\u001b[0m) -> float32_356<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_356<1,512>\u001b[0m) -> float32_357<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_356<1,512>\u001b[0m, inplace=False) -> float32_357<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_356<1,512>\u001b[0m) -> float32_357<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_357<1,512>\u001b[0m) -> float32_360<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_357<1,512>\u001b[0m, float32_358<5,512>\u001b[0m, float32_359<5>\u001b[0m) -> float32_360<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSoftmax[torch.nn.modules.activation]\u001b[0m(float32_360<1,5>\u001b[0m) -> float32_361<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_360<1,5>\u001b[0m, 1, _stacklevel=5) -> float32_361<1,5>\u001b[0m\n",
      "\u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_360<1,5>\u001b[0m, 1) -> float32_361<1,5>\u001b[0m\n",
      "\n",
      "Conversion complete. Elapsed time: 8.57 sec.\n"
     ]
    }
   ],
   "source": [
    "keras_model = keras_model = nobuco.pytorch_to_keras(saved_model, [input_tensor], inputs_channel_order=ChannelOrder.TENSORFLOW)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\louis\\anaconda3\\envs\\nobuco\\Lib\\site-packages\\nobuco\\converters\\validation.py:55: RuntimeWarning: [<class 'torchvision.ops.misc.Conv2dNormActivation'>|NeuralNetwork->Sequential->Sequential->InvertedResidual->Sequential] conversion procedure might be incorrect: max. discrepancy for output #0 is 0.00014 (0.000%)\n",
      "  warnings.warn(warn_string, category=RuntimeWarning)\n",
      "c:\\Users\\louis\\anaconda3\\envs\\nobuco\\Lib\\site-packages\\nobuco\\converters\\validation.py:55: RuntimeWarning: [<class 'torch.nn.modules.container.Sequential'>|NeuralNetwork->Sequential->Sequential->InvertedResidual] conversion procedure might be incorrect: max. discrepancy for output #0 is 0.00013 (0.000%)\n",
      "  warnings.warn(warn_string, category=RuntimeWarning)\n",
      "c:\\Users\\louis\\anaconda3\\envs\\nobuco\\Lib\\site-packages\\nobuco\\converters\\validation.py:55: RuntimeWarning: [<class 'torchvision.models.mobilenetv3.InvertedResidual'>|NeuralNetwork->Sequential->Sequential] conversion procedure might be incorrect: max. discrepancy for output #0 is 0.00013 (0.000%)\n",
      "  warnings.warn(warn_string, category=RuntimeWarning)\n",
      "c:\\Users\\louis\\anaconda3\\envs\\nobuco\\Lib\\site-packages\\nobuco\\converters\\validation.py:55: RuntimeWarning: [<class 'torch.nn.modules.container.Sequential'>|NeuralNetwork->Sequential] conversion procedure might be incorrect: max. discrepancy for output #0 is 0.00055 (0.021%)\n",
      "  warnings.warn(warn_string, category=RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend:\n",
      "    \u001b[32mGreen\u001b[0m — conversion successful\n",
      "    \u001b[33mYellow\u001b[0m — conversion imprecise\n",
      "    \u001b[31mRed\u001b[0m — conversion failed\n",
      "    \u001b[31m\u001b[7mRed\u001b[0m — no converter found\n",
      "    \u001b[0m\u001b[1mBold\u001b[0m — conversion applied directly\n",
      "    * — subgraph reused\n",
      "    \u001b[7mTensor\u001b[0m — this output is not dependent on any of subgraph's input tensors\n",
      "    \u001b[4mTensor\u001b[0m — this input is a parameter / constant\n",
      "    \u001b[90mTensor\u001b[0m — this tensor is useless\n",
      "\n",
      "\u001b[32mNeuralNetwork[__main__]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_361<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_347<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m\u001b[7m (!) Max diff 0.00055 (0.021%) \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"C:\\Users\\louis\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py\", line 217\u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"C:/Users/louis/AppData/Roaming/Python/Python311/site-packages/torch/nn/modules/container.py\", line 43 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33mSequential[torch.nn.modules.container]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_2<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_0<1,3,224,224>\u001b[0m, float32_1<16,3,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_2<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_2<1,16,112,112>\u001b[0m) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_2<1,16,112,112>\u001b[0m, float32_3<16>\u001b[0m, float32_3<16>\u001b[0m, float32_4<16>\u001b[0m, float32_3<16>\u001b[0m, False, 0.01, 0.001) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_2<1,16,112,112>\u001b[0m, float32_4<16>\u001b[0m, float32_3<16>\u001b[0m, float32_3<16>\u001b[0m, float32_3<16>\u001b[0m, False, 0.01, 0.001, True) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_5<1,16,112,112>\u001b[0m, True) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_7<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_5<1,16,112,112>\u001b[0m, float32_6<16,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 16) -> float32_7<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_7<1,16,112,112>\u001b[0m) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_7<1,16,112,112>\u001b[0m, float32_8<16>\u001b[0m, float32_9<16>\u001b[0m, float32_10<16>\u001b[0m, float32_11<16>\u001b[0m, False, 0.01, 0.001) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_7<1,16,112,112>\u001b[0m, float32_10<16>\u001b[0m, float32_11<16>\u001b[0m, float32_8<16>\u001b[0m, float32_9<16>\u001b[0m, False, 0.01, 0.001, True) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_12<1,16,112,112>\u001b[0m) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_12<1,16,112,112>\u001b[0m, inplace=True) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_12<1,16,112,112>\u001b[0m) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_12<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_12<1,16,112,112>\u001b[0m) -> float32_14<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_12<1,16,112,112>\u001b[0m, float32_13<16,16,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_14<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_14<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_14<1,16,112,112>\u001b[0m, float32_15<16>\u001b[0m, float32_16<16>\u001b[0m, float32_16<16>\u001b[0m, float32_17<16>\u001b[0m, False, 0.01, 0.001) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_14<1,16,112,112>\u001b[0m, float32_16<16>\u001b[0m, float32_17<16>\u001b[0m, float32_15<16>\u001b[0m, float32_16<16>\u001b[0m, False, 0.01, 0.001, True) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_18<1,16,112,112>\u001b[0m, float32_5<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_18<1,16,112,112>\u001b[0m, float32_5<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_18<1,16,112,112>\u001b[0m) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_18<1,16,112,112>\u001b[0m) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_18<1,16,112,112>\u001b[0m) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_18<1,16,112,112>\u001b[0m) -> float32_20<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_18<1,16,112,112>\u001b[0m, float32_19<64,16,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_20<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_20<1,64,112,112>\u001b[0m) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_20<1,64,112,112>\u001b[0m, float32_21<64>\u001b[0m, float32_22<64>\u001b[0m, float32_22<64>\u001b[0m, float32_22<64>\u001b[0m, False, 0.01, 0.001) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_20<1,64,112,112>\u001b[0m, float32_22<64>\u001b[0m, float32_22<64>\u001b[0m, float32_21<64>\u001b[0m, float32_22<64>\u001b[0m, False, 0.01, 0.001, True) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_23<1,64,112,112>\u001b[0m) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_23<1,64,112,112>\u001b[0m, inplace=True) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_23<1,64,112,112>\u001b[0m) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_23<1,64,112,112>\u001b[0m) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_23<1,64,112,112>\u001b[0m) -> float32_25<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_23<1,64,112,112>\u001b[0m, float32_24<64,1,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 64) -> float32_25<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_25<1,64,56,56>\u001b[0m) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_25<1,64,56,56>\u001b[0m, float32_26<64>\u001b[0m, float32_27<64>\u001b[0m, float32_28<64>\u001b[0m, float32_29<64>\u001b[0m, False, 0.01, 0.001) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_25<1,64,56,56>\u001b[0m, float32_28<64>\u001b[0m, float32_29<64>\u001b[0m, float32_26<64>\u001b[0m, float32_27<64>\u001b[0m, False, 0.01, 0.001, True) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_30<1,64,56,56>\u001b[0m) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_30<1,64,56,56>\u001b[0m, inplace=True) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_30<1,64,56,56>\u001b[0m) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_30<1,64,56,56>\u001b[0m) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_30<1,64,56,56>\u001b[0m) -> float32_32<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_30<1,64,56,56>\u001b[0m, float32_31<24,64,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_32<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_32<1,24,56,56>\u001b[0m) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_32<1,24,56,56>\u001b[0m, float32_33<24>\u001b[0m, float32_33<24>\u001b[0m, float32_34<24>\u001b[0m, float32_33<24>\u001b[0m, False, 0.01, 0.001) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_32<1,24,56,56>\u001b[0m, float32_34<24>\u001b[0m, float32_33<24>\u001b[0m, float32_33<24>\u001b[0m, float32_33<24>\u001b[0m, False, 0.01, 0.001, True) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_35<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_35<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_35<1,24,56,56>\u001b[0m) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_35<1,24,56,56>\u001b[0m) -> float32_37<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_35<1,24,56,56>\u001b[0m, float32_36<72,24,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_37<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_37<1,72,56,56>\u001b[0m) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_37<1,72,56,56>\u001b[0m, float32_38<72>\u001b[0m, float32_39<72>\u001b[0m, float32_40<72>\u001b[0m, float32_41<72>\u001b[0m, False, 0.01, 0.001) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_37<1,72,56,56>\u001b[0m, float32_40<72>\u001b[0m, float32_41<72>\u001b[0m, float32_38<72>\u001b[0m, float32_39<72>\u001b[0m, False, 0.01, 0.001, True) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_42<1,72,56,56>\u001b[0m) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_42<1,72,56,56>\u001b[0m, inplace=True) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_42<1,72,56,56>\u001b[0m) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_42<1,72,56,56>\u001b[0m) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_42<1,72,56,56>\u001b[0m) -> float32_44<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_42<1,72,56,56>\u001b[0m, float32_43<72,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 72) -> float32_44<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_44<1,72,56,56>\u001b[0m) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_44<1,72,56,56>\u001b[0m, float32_45<72>\u001b[0m, float32_46<72>\u001b[0m, float32_47<72>\u001b[0m, float32_47<72>\u001b[0m, False, 0.01, 0.001) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_44<1,72,56,56>\u001b[0m, float32_47<72>\u001b[0m, float32_47<72>\u001b[0m, float32_45<72>\u001b[0m, float32_46<72>\u001b[0m, False, 0.01, 0.001, True) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_48<1,72,56,56>\u001b[0m) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_48<1,72,56,56>\u001b[0m, inplace=True) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_48<1,72,56,56>\u001b[0m) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_48<1,72,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_48<1,72,56,56>\u001b[0m) -> float32_50<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_48<1,72,56,56>\u001b[0m, float32_49<24,72,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_50<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_50<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_50<1,24,56,56>\u001b[0m, float32_51<24>\u001b[0m, float32_52<24>\u001b[0m, float32_53<24>\u001b[0m, float32_52<24>\u001b[0m, False, 0.01, 0.001) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_50<1,24,56,56>\u001b[0m, float32_53<24>\u001b[0m, float32_52<24>\u001b[0m, float32_51<24>\u001b[0m, float32_52<24>\u001b[0m, False, 0.01, 0.001, True) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_54<1,24,56,56>\u001b[0m, float32_35<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_54<1,24,56,56>\u001b[0m, float32_35<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_54<1,24,56,56>\u001b[0m) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_54<1,24,56,56>\u001b[0m) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_54<1,24,56,56>\u001b[0m) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_54<1,24,56,56>\u001b[0m) -> float32_56<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_54<1,24,56,56>\u001b[0m, float32_55<72,24,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_56<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_56<1,72,56,56>\u001b[0m) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_56<1,72,56,56>\u001b[0m, float32_57<72>\u001b[0m, float32_57<72>\u001b[0m, float32_58<72>\u001b[0m, float32_59<72>\u001b[0m, False, 0.01, 0.001) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_56<1,72,56,56>\u001b[0m, float32_58<72>\u001b[0m, float32_59<72>\u001b[0m, float32_57<72>\u001b[0m, float32_57<72>\u001b[0m, False, 0.01, 0.001, True) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_60<1,72,56,56>\u001b[0m) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_60<1,72,56,56>\u001b[0m, inplace=True) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_60<1,72,56,56>\u001b[0m) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_60<1,72,56,56>\u001b[0m) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_60<1,72,56,56>\u001b[0m) -> float32_62<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_60<1,72,56,56>\u001b[0m, float32_61<72,1,5,5>\u001b[0m, None, (2, 2), (2, 2), (1, 1), 72) -> float32_62<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_62<1,72,28,28>\u001b[0m) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_62<1,72,28,28>\u001b[0m, float32_63<72>\u001b[0m, float32_64<72>\u001b[0m, float32_65<72>\u001b[0m, float32_66<72>\u001b[0m, False, 0.01, 0.001) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_62<1,72,28,28>\u001b[0m, float32_65<72>\u001b[0m, float32_66<72>\u001b[0m, float32_63<72>\u001b[0m, float32_64<72>\u001b[0m, False, 0.01, 0.001, True) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_67<1,72,28,28>\u001b[0m) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_67<1,72,28,28>\u001b[0m, inplace=True) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_67<1,72,28,28>\u001b[0m) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_67<1,72,28,28>\u001b[0m) -> float32_77<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_67<1,72,28,28>\u001b[0m) -> float32_68<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_67<1,72,28,28>\u001b[0m, 1) -> float32_68<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_68<1,72,1,1>\u001b[0m) -> float32_71<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_68<1,72,1,1>\u001b[0m, float32_69<24,72,1,1>\u001b[0m, float32_70<24>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_71<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_71<1,24,1,1>\u001b[0m) -> float32_72<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_71<1,24,1,1>\u001b[0m, inplace=False) -> float32_72<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_71<1,24,1,1>\u001b[0m) -> float32_72<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_72<1,24,1,1>\u001b[0m) -> float32_75<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_72<1,24,1,1>\u001b[0m, float32_73<72,24,1,1>\u001b[0m, float32_74<72>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_75<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_75<1,72,1,1>\u001b[0m) -> float32_76<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_75<1,72,1,1>\u001b[0m, False) -> float32_76<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_76<1,72,1,1>\u001b[0m, float32_67<1,72,28,28>\u001b[0m) -> float32_77<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_76<1,72,1,1>\u001b[0m, float32_67<1,72,28,28>\u001b[0m) -> float32_77<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_77<1,72,28,28>\u001b[0m) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_77<1,72,28,28>\u001b[0m) -> float32_79<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_77<1,72,28,28>\u001b[0m, float32_78<40,72,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_79<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_79<1,40,28,28>\u001b[0m) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_79<1,40,28,28>\u001b[0m, float32_80<40>\u001b[0m, float32_81<40>\u001b[0m, float32_80<40>\u001b[0m, float32_82<40>\u001b[0m, False, 0.01, 0.001) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_79<1,40,28,28>\u001b[0m, float32_80<40>\u001b[0m, float32_82<40>\u001b[0m, float32_80<40>\u001b[0m, float32_81<40>\u001b[0m, False, 0.01, 0.001, True) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_83<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_83<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_83<1,40,28,28>\u001b[0m) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_83<1,40,28,28>\u001b[0m) -> float32_85<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_83<1,40,28,28>\u001b[0m, float32_84<120,40,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_85<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_85<1,120,28,28>\u001b[0m) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_85<1,120,28,28>\u001b[0m, float32_86<120>\u001b[0m, float32_87<120>\u001b[0m, float32_88<120>\u001b[0m, float32_86<120>\u001b[0m, False, 0.01, 0.001) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_85<1,120,28,28>\u001b[0m, float32_88<120>\u001b[0m, float32_86<120>\u001b[0m, float32_86<120>\u001b[0m, float32_87<120>\u001b[0m, False, 0.01, 0.001, True) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_89<1,120,28,28>\u001b[0m) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_89<1,120,28,28>\u001b[0m, inplace=True) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_89<1,120,28,28>\u001b[0m) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_89<1,120,28,28>\u001b[0m) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_89<1,120,28,28>\u001b[0m) -> float32_91<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_89<1,120,28,28>\u001b[0m, float32_90<120,1,5,5>\u001b[0m, None, (1, 1), (2, 2), (1, 1), 120) -> float32_91<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_91<1,120,28,28>\u001b[0m) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_91<1,120,28,28>\u001b[0m, float32_92<120>\u001b[0m, float32_93<120>\u001b[0m, float32_92<120>\u001b[0m, float32_94<120>\u001b[0m, False, 0.01, 0.001) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_91<1,120,28,28>\u001b[0m, float32_92<120>\u001b[0m, float32_94<120>\u001b[0m, float32_92<120>\u001b[0m, float32_93<120>\u001b[0m, False, 0.01, 0.001, True) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_95<1,120,28,28>\u001b[0m) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_95<1,120,28,28>\u001b[0m, inplace=True) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_95<1,120,28,28>\u001b[0m) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_95<1,120,28,28>\u001b[0m) -> float32_104<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_95<1,120,28,28>\u001b[0m) -> float32_96<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_95<1,120,28,28>\u001b[0m, 1) -> float32_96<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_96<1,120,1,1>\u001b[0m) -> float32_99<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_96<1,120,1,1>\u001b[0m, float32_97<32,120,1,1>\u001b[0m, float32_98<32>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_99<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_99<1,32,1,1>\u001b[0m) -> float32_100<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_99<1,32,1,1>\u001b[0m, inplace=False) -> float32_100<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_99<1,32,1,1>\u001b[0m) -> float32_100<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_100<1,32,1,1>\u001b[0m) -> float32_102<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_100<1,32,1,1>\u001b[0m, float32_101<120,32,1,1>\u001b[0m, float32_101<120>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_102<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_102<1,120,1,1>\u001b[0m) -> float32_103<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_102<1,120,1,1>\u001b[0m, False) -> float32_103<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_103<1,120,1,1>\u001b[0m, float32_95<1,120,28,28>\u001b[0m) -> float32_104<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_103<1,120,1,1>\u001b[0m, float32_95<1,120,28,28>\u001b[0m) -> float32_104<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_104<1,120,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_104<1,120,28,28>\u001b[0m) -> float32_106<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_104<1,120,28,28>\u001b[0m, float32_105<40,120,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_106<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_106<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_106<1,40,28,28>\u001b[0m, float32_107<40>\u001b[0m, float32_108<40>\u001b[0m, float32_109<40>\u001b[0m, float32_109<40>\u001b[0m, False, 0.01, 0.001) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_106<1,40,28,28>\u001b[0m, float32_109<40>\u001b[0m, float32_109<40>\u001b[0m, float32_107<40>\u001b[0m, float32_108<40>\u001b[0m, False, 0.01, 0.001, True) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_110<1,40,28,28>\u001b[0m, float32_83<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_110<1,40,28,28>\u001b[0m, float32_83<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_110<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_110<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_110<1,40,28,28>\u001b[0m) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_110<1,40,28,28>\u001b[0m) -> float32_112<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_110<1,40,28,28>\u001b[0m, float32_111<120,40,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_112<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_112<1,120,28,28>\u001b[0m) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_112<1,120,28,28>\u001b[0m, float32_113<120>\u001b[0m, float32_114<120>\u001b[0m, float32_115<120>\u001b[0m, float32_113<120>\u001b[0m, False, 0.01, 0.001) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_112<1,120,28,28>\u001b[0m, float32_115<120>\u001b[0m, float32_113<120>\u001b[0m, float32_113<120>\u001b[0m, float32_114<120>\u001b[0m, False, 0.01, 0.001, True) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_116<1,120,28,28>\u001b[0m) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_116<1,120,28,28>\u001b[0m, inplace=True) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_116<1,120,28,28>\u001b[0m) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_116<1,120,28,28>\u001b[0m) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_116<1,120,28,28>\u001b[0m) -> float32_118<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_116<1,120,28,28>\u001b[0m, float32_117<120,1,5,5>\u001b[0m, None, (1, 1), (2, 2), (1, 1), 120) -> float32_118<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_118<1,120,28,28>\u001b[0m) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_118<1,120,28,28>\u001b[0m, float32_119<120>\u001b[0m, float32_120<120>\u001b[0m, float32_121<120>\u001b[0m, float32_120<120>\u001b[0m, False, 0.01, 0.001) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_118<1,120,28,28>\u001b[0m, float32_121<120>\u001b[0m, float32_120<120>\u001b[0m, float32_119<120>\u001b[0m, float32_120<120>\u001b[0m, False, 0.01, 0.001, True) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_122<1,120,28,28>\u001b[0m) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_122<1,120,28,28>\u001b[0m, inplace=True) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_122<1,120,28,28>\u001b[0m) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_122<1,120,28,28>\u001b[0m) -> float32_131<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_122<1,120,28,28>\u001b[0m) -> float32_123<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_122<1,120,28,28>\u001b[0m, 1) -> float32_123<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_123<1,120,1,1>\u001b[0m) -> float32_125<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_123<1,120,1,1>\u001b[0m, float32_124<32,120,1,1>\u001b[0m, float32_124<32>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_125<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_125<1,32,1,1>\u001b[0m) -> float32_126<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_125<1,32,1,1>\u001b[0m, inplace=False) -> float32_126<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_125<1,32,1,1>\u001b[0m) -> float32_126<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_126<1,32,1,1>\u001b[0m) -> float32_129<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_126<1,32,1,1>\u001b[0m, float32_127<120,32,1,1>\u001b[0m, float32_128<120>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_129<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_129<1,120,1,1>\u001b[0m) -> float32_130<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_129<1,120,1,1>\u001b[0m, False) -> float32_130<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_130<1,120,1,1>\u001b[0m, float32_122<1,120,28,28>\u001b[0m) -> float32_131<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_130<1,120,1,1>\u001b[0m, float32_122<1,120,28,28>\u001b[0m) -> float32_131<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_131<1,120,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_131<1,120,28,28>\u001b[0m) -> float32_133<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_131<1,120,28,28>\u001b[0m, float32_132<40,120,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_133<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_133<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_133<1,40,28,28>\u001b[0m, float32_134<40>\u001b[0m, float32_134<40>\u001b[0m, float32_135<40>\u001b[0m, float32_136<40>\u001b[0m, False, 0.01, 0.001) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_133<1,40,28,28>\u001b[0m, float32_135<40>\u001b[0m, float32_136<40>\u001b[0m, float32_134<40>\u001b[0m, float32_134<40>\u001b[0m, False, 0.01, 0.001, True) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_137<1,40,28,28>\u001b[0m, float32_110<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_137<1,40,28,28>\u001b[0m, float32_110<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_137<1,40,28,28>\u001b[0m) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_137<1,40,28,28>\u001b[0m) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_137<1,40,28,28>\u001b[0m) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_137<1,40,28,28>\u001b[0m) -> float32_139<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_137<1,40,28,28>\u001b[0m, float32_138<240,40,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_139<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_139<1,240,28,28>\u001b[0m) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_139<1,240,28,28>\u001b[0m, float32_140<240>\u001b[0m, float32_141<240>\u001b[0m, float32_141<240>\u001b[0m, float32_140<240>\u001b[0m, False, 0.01, 0.001) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_139<1,240,28,28>\u001b[0m, float32_141<240>\u001b[0m, float32_140<240>\u001b[0m, float32_140<240>\u001b[0m, float32_141<240>\u001b[0m, False, 0.01, 0.001, True) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_142<1,240,28,28>\u001b[0m) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_142<1,240,28,28>\u001b[0m, True) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_142<1,240,28,28>\u001b[0m) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_142<1,240,28,28>\u001b[0m) -> float32_144<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_142<1,240,28,28>\u001b[0m, float32_143<240,1,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 240) -> float32_144<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_144<1,240,14,14>\u001b[0m) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_144<1,240,14,14>\u001b[0m, float32_145<240>\u001b[0m, float32_145<240>\u001b[0m, float32_145<240>\u001b[0m, float32_146<240>\u001b[0m, False, 0.01, 0.001) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_144<1,240,14,14>\u001b[0m, float32_145<240>\u001b[0m, float32_146<240>\u001b[0m, float32_145<240>\u001b[0m, float32_145<240>\u001b[0m, False, 0.01, 0.001, True) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_147<1,240,14,14>\u001b[0m) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_147<1,240,14,14>\u001b[0m, True) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_147<1,240,14,14>\u001b[0m) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_147<1,240,14,14>\u001b[0m) -> float32_149<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_147<1,240,14,14>\u001b[0m, float32_148<80,240,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_149<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_149<1,80,14,14>\u001b[0m) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_149<1,80,14,14>\u001b[0m, float32_150<80>\u001b[0m, float32_150<80>\u001b[0m, float32_150<80>\u001b[0m, float32_151<80>\u001b[0m, False, 0.01, 0.001) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_149<1,80,14,14>\u001b[0m, float32_150<80>\u001b[0m, float32_151<80>\u001b[0m, float32_150<80>\u001b[0m, float32_150<80>\u001b[0m, False, 0.01, 0.001, True) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_152<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_152<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_152<1,80,14,14>\u001b[0m) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_152<1,80,14,14>\u001b[0m) -> float32_154<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_152<1,80,14,14>\u001b[0m, float32_153<200,80,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_154<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_154<1,200,14,14>\u001b[0m) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_154<1,200,14,14>\u001b[0m, float32_155<200>\u001b[0m, float32_155<200>\u001b[0m, float32_156<200>\u001b[0m, float32_157<200>\u001b[0m, False, 0.01, 0.001) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_154<1,200,14,14>\u001b[0m, float32_156<200>\u001b[0m, float32_157<200>\u001b[0m, float32_155<200>\u001b[0m, float32_155<200>\u001b[0m, False, 0.01, 0.001, True) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_158<1,200,14,14>\u001b[0m) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_158<1,200,14,14>\u001b[0m, True) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_158<1,200,14,14>\u001b[0m) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_158<1,200,14,14>\u001b[0m) -> float32_160<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_158<1,200,14,14>\u001b[0m, float32_159<200,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 200) -> float32_160<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_160<1,200,14,14>\u001b[0m) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_160<1,200,14,14>\u001b[0m, float32_161<200>\u001b[0m, float32_162<200>\u001b[0m, float32_161<200>\u001b[0m, float32_162<200>\u001b[0m, False, 0.01, 0.001) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_160<1,200,14,14>\u001b[0m, float32_161<200>\u001b[0m, float32_162<200>\u001b[0m, float32_161<200>\u001b[0m, float32_162<200>\u001b[0m, False, 0.01, 0.001, True) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_163<1,200,14,14>\u001b[0m) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_163<1,200,14,14>\u001b[0m, True) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_163<1,200,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_163<1,200,14,14>\u001b[0m) -> float32_165<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_163<1,200,14,14>\u001b[0m, float32_164<80,200,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_165<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_165<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_165<1,80,14,14>\u001b[0m, float32_166<80>\u001b[0m, float32_167<80>\u001b[0m, float32_167<80>\u001b[0m, float32_167<80>\u001b[0m, False, 0.01, 0.001) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_165<1,80,14,14>\u001b[0m, float32_167<80>\u001b[0m, float32_167<80>\u001b[0m, float32_166<80>\u001b[0m, float32_167<80>\u001b[0m, False, 0.01, 0.001, True) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_168<1,80,14,14>\u001b[0m, float32_152<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_168<1,80,14,14>\u001b[0m, float32_152<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_168<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_168<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_168<1,80,14,14>\u001b[0m) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_168<1,80,14,14>\u001b[0m) -> float32_170<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_168<1,80,14,14>\u001b[0m, float32_169<184,80,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_170<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_170<1,184,14,14>\u001b[0m) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_170<1,184,14,14>\u001b[0m, float32_171<184>\u001b[0m, float32_172<184>\u001b[0m, float32_173<184>\u001b[0m, float32_173<184>\u001b[0m, False, 0.01, 0.001) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_170<1,184,14,14>\u001b[0m, float32_173<184>\u001b[0m, float32_173<184>\u001b[0m, float32_171<184>\u001b[0m, float32_172<184>\u001b[0m, False, 0.01, 0.001, True) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_174<1,184,14,14>\u001b[0m) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_174<1,184,14,14>\u001b[0m, True) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_174<1,184,14,14>\u001b[0m) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_174<1,184,14,14>\u001b[0m) -> float32_176<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_174<1,184,14,14>\u001b[0m, float32_175<184,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 184) -> float32_176<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_176<1,184,14,14>\u001b[0m) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_176<1,184,14,14>\u001b[0m, float32_177<184>\u001b[0m, float32_178<184>\u001b[0m, float32_179<184>\u001b[0m, float32_179<184>\u001b[0m, False, 0.01, 0.001) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_176<1,184,14,14>\u001b[0m, float32_179<184>\u001b[0m, float32_179<184>\u001b[0m, float32_177<184>\u001b[0m, float32_178<184>\u001b[0m, False, 0.01, 0.001, True) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_180<1,184,14,14>\u001b[0m) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_180<1,184,14,14>\u001b[0m, True) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_180<1,184,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_180<1,184,14,14>\u001b[0m) -> float32_182<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_180<1,184,14,14>\u001b[0m, float32_181<80,184,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_182<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_182<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_182<1,80,14,14>\u001b[0m, float32_183<80>\u001b[0m, float32_183<80>\u001b[0m, float32_183<80>\u001b[0m, float32_184<80>\u001b[0m, False, 0.01, 0.001) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_182<1,80,14,14>\u001b[0m, float32_183<80>\u001b[0m, float32_184<80>\u001b[0m, float32_183<80>\u001b[0m, float32_183<80>\u001b[0m, False, 0.01, 0.001, True) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_185<1,80,14,14>\u001b[0m, float32_168<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_185<1,80,14,14>\u001b[0m, float32_168<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_185<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_185<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_185<1,80,14,14>\u001b[0m) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_185<1,80,14,14>\u001b[0m) -> float32_187<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_185<1,80,14,14>\u001b[0m, float32_186<184,80,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_187<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_187<1,184,14,14>\u001b[0m) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_187<1,184,14,14>\u001b[0m, float32_188<184>\u001b[0m, float32_189<184>\u001b[0m, float32_189<184>\u001b[0m, float32_189<184>\u001b[0m, False, 0.01, 0.001) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_187<1,184,14,14>\u001b[0m, float32_189<184>\u001b[0m, float32_189<184>\u001b[0m, float32_188<184>\u001b[0m, float32_189<184>\u001b[0m, False, 0.01, 0.001, True) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_190<1,184,14,14>\u001b[0m) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_190<1,184,14,14>\u001b[0m, True) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_190<1,184,14,14>\u001b[0m) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_190<1,184,14,14>\u001b[0m) -> float32_192<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_190<1,184,14,14>\u001b[0m, float32_191<184,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 184) -> float32_192<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_192<1,184,14,14>\u001b[0m) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_192<1,184,14,14>\u001b[0m, float32_193<184>\u001b[0m, float32_194<184>\u001b[0m, float32_194<184>\u001b[0m, float32_194<184>\u001b[0m, False, 0.01, 0.001) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_192<1,184,14,14>\u001b[0m, float32_194<184>\u001b[0m, float32_194<184>\u001b[0m, float32_193<184>\u001b[0m, float32_194<184>\u001b[0m, False, 0.01, 0.001, True) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_195<1,184,14,14>\u001b[0m) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_195<1,184,14,14>\u001b[0m, True) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_195<1,184,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_195<1,184,14,14>\u001b[0m) -> float32_197<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_195<1,184,14,14>\u001b[0m, float32_196<80,184,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_197<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_197<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_197<1,80,14,14>\u001b[0m, float32_198<80>\u001b[0m, float32_198<80>\u001b[0m, float32_199<80>\u001b[0m, float32_198<80>\u001b[0m, False, 0.01, 0.001) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_197<1,80,14,14>\u001b[0m, float32_199<80>\u001b[0m, float32_198<80>\u001b[0m, float32_198<80>\u001b[0m, float32_198<80>\u001b[0m, False, 0.01, 0.001, True) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_200<1,80,14,14>\u001b[0m, float32_185<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_200<1,80,14,14>\u001b[0m, float32_185<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_200<1,80,14,14>\u001b[0m) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_200<1,80,14,14>\u001b[0m) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_200<1,80,14,14>\u001b[0m) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_200<1,80,14,14>\u001b[0m) -> float32_202<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_200<1,80,14,14>\u001b[0m, float32_201<480,80,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_202<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_202<1,480,14,14>\u001b[0m) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_202<1,480,14,14>\u001b[0m, float32_203<480>\u001b[0m, float32_204<480>\u001b[0m, float32_205<480>\u001b[0m, float32_206<480>\u001b[0m, False, 0.01, 0.001) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_202<1,480,14,14>\u001b[0m, float32_205<480>\u001b[0m, float32_206<480>\u001b[0m, float32_203<480>\u001b[0m, float32_204<480>\u001b[0m, False, 0.01, 0.001, True) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_207<1,480,14,14>\u001b[0m) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_207<1,480,14,14>\u001b[0m, True) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_207<1,480,14,14>\u001b[0m) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_207<1,480,14,14>\u001b[0m) -> float32_209<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_207<1,480,14,14>\u001b[0m, float32_208<480,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 480) -> float32_209<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_209<1,480,14,14>\u001b[0m) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_209<1,480,14,14>\u001b[0m, float32_210<480>\u001b[0m, float32_211<480>\u001b[0m, float32_212<480>\u001b[0m, float32_213<480>\u001b[0m, False, 0.01, 0.001) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_209<1,480,14,14>\u001b[0m, float32_212<480>\u001b[0m, float32_213<480>\u001b[0m, float32_210<480>\u001b[0m, float32_211<480>\u001b[0m, False, 0.01, 0.001, True) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_214<1,480,14,14>\u001b[0m) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_214<1,480,14,14>\u001b[0m, True) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_214<1,480,14,14>\u001b[0m) -> float32_224<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_214<1,480,14,14>\u001b[0m) -> float32_215<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_214<1,480,14,14>\u001b[0m, 1) -> float32_215<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_215<1,480,1,1>\u001b[0m) -> float32_218<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_215<1,480,1,1>\u001b[0m, float32_216<120,480,1,1>\u001b[0m, float32_217<120>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_218<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_218<1,120,1,1>\u001b[0m) -> float32_219<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_218<1,120,1,1>\u001b[0m, inplace=False) -> float32_219<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_218<1,120,1,1>\u001b[0m) -> float32_219<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_219<1,120,1,1>\u001b[0m) -> float32_222<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_219<1,120,1,1>\u001b[0m, float32_220<480,120,1,1>\u001b[0m, float32_221<480>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_222<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_222<1,480,1,1>\u001b[0m) -> float32_223<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_222<1,480,1,1>\u001b[0m, False) -> float32_223<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_223<1,480,1,1>\u001b[0m, float32_214<1,480,14,14>\u001b[0m) -> float32_224<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_223<1,480,1,1>\u001b[0m, float32_214<1,480,14,14>\u001b[0m) -> float32_224<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_224<1,480,14,14>\u001b[0m) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_224<1,480,14,14>\u001b[0m) -> float32_226<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_224<1,480,14,14>\u001b[0m, float32_225<112,480,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_226<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_226<1,112,14,14>\u001b[0m) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_226<1,112,14,14>\u001b[0m, float32_227<112>\u001b[0m, float32_228<112>\u001b[0m, float32_228<112>\u001b[0m, float32_229<112>\u001b[0m, False, 0.01, 0.001) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_226<1,112,14,14>\u001b[0m, float32_228<112>\u001b[0m, float32_229<112>\u001b[0m, float32_227<112>\u001b[0m, float32_228<112>\u001b[0m, False, 0.01, 0.001, True) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_230<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_230<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_230<1,112,14,14>\u001b[0m) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_230<1,112,14,14>\u001b[0m) -> float32_232<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_230<1,112,14,14>\u001b[0m, float32_231<672,112,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_232<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_232<1,672,14,14>\u001b[0m) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_232<1,672,14,14>\u001b[0m, float32_233<672>\u001b[0m, float32_234<672>\u001b[0m, float32_235<672>\u001b[0m, float32_234<672>\u001b[0m, False, 0.01, 0.001) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_232<1,672,14,14>\u001b[0m, float32_235<672>\u001b[0m, float32_234<672>\u001b[0m, float32_233<672>\u001b[0m, float32_234<672>\u001b[0m, False, 0.01, 0.001, True) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_236<1,672,14,14>\u001b[0m) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_236<1,672,14,14>\u001b[0m, True) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_236<1,672,14,14>\u001b[0m) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_236<1,672,14,14>\u001b[0m) -> float32_238<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_236<1,672,14,14>\u001b[0m, float32_237<672,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 672) -> float32_238<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_238<1,672,14,14>\u001b[0m) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_238<1,672,14,14>\u001b[0m, float32_239<672>\u001b[0m, float32_240<672>\u001b[0m, float32_241<672>\u001b[0m, float32_242<672>\u001b[0m, False, 0.01, 0.001) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_238<1,672,14,14>\u001b[0m, float32_241<672>\u001b[0m, float32_242<672>\u001b[0m, float32_239<672>\u001b[0m, float32_240<672>\u001b[0m, False, 0.01, 0.001, True) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_243<1,672,14,14>\u001b[0m) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_243<1,672,14,14>\u001b[0m, True) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_243<1,672,14,14>\u001b[0m) -> float32_252<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_243<1,672,14,14>\u001b[0m) -> float32_244<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_243<1,672,14,14>\u001b[0m, 1) -> float32_244<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_244<1,672,1,1>\u001b[0m) -> float32_247<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_244<1,672,1,1>\u001b[0m, float32_245<168,672,1,1>\u001b[0m, float32_246<168>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_247<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_247<1,168,1,1>\u001b[0m) -> float32_248<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_247<1,168,1,1>\u001b[0m, inplace=False) -> float32_248<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_247<1,168,1,1>\u001b[0m) -> float32_248<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_248<1,168,1,1>\u001b[0m) -> float32_250<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_248<1,168,1,1>\u001b[0m, float32_249<672,168,1,1>\u001b[0m, float32_249<672>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_250<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_250<1,672,1,1>\u001b[0m) -> float32_251<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_250<1,672,1,1>\u001b[0m, False) -> float32_251<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_251<1,672,1,1>\u001b[0m, float32_243<1,672,14,14>\u001b[0m) -> float32_252<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_251<1,672,1,1>\u001b[0m, float32_243<1,672,14,14>\u001b[0m) -> float32_252<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_252<1,672,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_252<1,672,14,14>\u001b[0m) -> float32_254<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_252<1,672,14,14>\u001b[0m, float32_253<112,672,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_254<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_254<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_254<1,112,14,14>\u001b[0m, float32_255<112>\u001b[0m, float32_256<112>\u001b[0m, float32_255<112>\u001b[0m, float32_255<112>\u001b[0m, False, 0.01, 0.001) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_254<1,112,14,14>\u001b[0m, float32_255<112>\u001b[0m, float32_255<112>\u001b[0m, float32_255<112>\u001b[0m, float32_256<112>\u001b[0m, False, 0.01, 0.001, True) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_257<1,112,14,14>\u001b[0m, float32_230<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_257<1,112,14,14>\u001b[0m, float32_230<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_257<1,112,14,14>\u001b[0m) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_257<1,112,14,14>\u001b[0m) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_257<1,112,14,14>\u001b[0m) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_257<1,112,14,14>\u001b[0m) -> float32_259<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_257<1,112,14,14>\u001b[0m, float32_258<672,112,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_259<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_259<1,672,14,14>\u001b[0m) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_259<1,672,14,14>\u001b[0m, float32_260<672>\u001b[0m, float32_261<672>\u001b[0m, float32_260<672>\u001b[0m, float32_262<672>\u001b[0m, False, 0.01, 0.001) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_259<1,672,14,14>\u001b[0m, float32_260<672>\u001b[0m, float32_262<672>\u001b[0m, float32_260<672>\u001b[0m, float32_261<672>\u001b[0m, False, 0.01, 0.001, True) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_263<1,672,14,14>\u001b[0m) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_263<1,672,14,14>\u001b[0m, True) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_263<1,672,14,14>\u001b[0m) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_263<1,672,14,14>\u001b[0m) -> float32_265<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_263<1,672,14,14>\u001b[0m, float32_264<672,1,5,5>\u001b[0m, None, (2, 2), (2, 2), (1, 1), 672) -> float32_265<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_265<1,672,7,7>\u001b[0m) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_265<1,672,7,7>\u001b[0m, float32_266<672>\u001b[0m, float32_267<672>\u001b[0m, float32_268<672>\u001b[0m, float32_268<672>\u001b[0m, False, 0.01, 0.001) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_265<1,672,7,7>\u001b[0m, float32_268<672>\u001b[0m, float32_268<672>\u001b[0m, float32_266<672>\u001b[0m, float32_267<672>\u001b[0m, False, 0.01, 0.001, True) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_269<1,672,7,7>\u001b[0m) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_269<1,672,7,7>\u001b[0m, True) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_269<1,672,7,7>\u001b[0m) -> float32_279<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_269<1,672,7,7>\u001b[0m) -> float32_270<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_269<1,672,7,7>\u001b[0m, 1) -> float32_270<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_270<1,672,1,1>\u001b[0m) -> float32_273<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_270<1,672,1,1>\u001b[0m, float32_271<168,672,1,1>\u001b[0m, float32_272<168>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_273<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_273<1,168,1,1>\u001b[0m) -> float32_274<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_273<1,168,1,1>\u001b[0m, inplace=False) -> float32_274<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_273<1,168,1,1>\u001b[0m) -> float32_274<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_274<1,168,1,1>\u001b[0m) -> float32_277<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_274<1,168,1,1>\u001b[0m, float32_275<672,168,1,1>\u001b[0m, float32_276<672>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_277<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_277<1,672,1,1>\u001b[0m) -> float32_278<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_277<1,672,1,1>\u001b[0m, False) -> float32_278<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_278<1,672,1,1>\u001b[0m, float32_269<1,672,7,7>\u001b[0m) -> float32_279<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_278<1,672,1,1>\u001b[0m, float32_269<1,672,7,7>\u001b[0m) -> float32_279<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_279<1,672,7,7>\u001b[0m) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_279<1,672,7,7>\u001b[0m) -> float32_281<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_279<1,672,7,7>\u001b[0m, float32_280<160,672,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_281<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_281<1,160,7,7>\u001b[0m) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_281<1,160,7,7>\u001b[0m, float32_282<160>\u001b[0m, float32_283<160>\u001b[0m, float32_284<160>\u001b[0m, float32_285<160>\u001b[0m, False, 0.01, 0.001) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_281<1,160,7,7>\u001b[0m, float32_284<160>\u001b[0m, float32_285<160>\u001b[0m, float32_282<160>\u001b[0m, float32_283<160>\u001b[0m, False, 0.01, 0.001, True) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_286<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_286<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_286<1,160,7,7>\u001b[0m) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_286<1,160,7,7>\u001b[0m) -> float32_288<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_286<1,160,7,7>\u001b[0m, float32_287<960,160,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_288<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_288<1,960,7,7>\u001b[0m) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_288<1,960,7,7>\u001b[0m, float32_289<960>\u001b[0m, float32_290<960>\u001b[0m, float32_291<960>\u001b[0m, float32_290<960>\u001b[0m, False, 0.01, 0.001) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_288<1,960,7,7>\u001b[0m, float32_291<960>\u001b[0m, float32_290<960>\u001b[0m, float32_289<960>\u001b[0m, float32_290<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_292<1,960,7,7>\u001b[0m) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_292<1,960,7,7>\u001b[0m, True) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_292<1,960,7,7>\u001b[0m) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_292<1,960,7,7>\u001b[0m) -> float32_294<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_292<1,960,7,7>\u001b[0m, float32_293<960,1,5,5>\u001b[0m, None, (1, 1), (2, 2), (1, 1), 960) -> float32_294<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_294<1,960,7,7>\u001b[0m) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_294<1,960,7,7>\u001b[0m, float32_295<960>\u001b[0m, float32_296<960>\u001b[0m, float32_297<960>\u001b[0m, float32_296<960>\u001b[0m, False, 0.01, 0.001) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_294<1,960,7,7>\u001b[0m, float32_297<960>\u001b[0m, float32_296<960>\u001b[0m, float32_295<960>\u001b[0m, float32_296<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_298<1,960,7,7>\u001b[0m) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_298<1,960,7,7>\u001b[0m, True) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_298<1,960,7,7>\u001b[0m) -> float32_308<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_298<1,960,7,7>\u001b[0m) -> float32_299<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_298<1,960,7,7>\u001b[0m, 1) -> float32_299<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_299<1,960,1,1>\u001b[0m) -> float32_302<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_299<1,960,1,1>\u001b[0m, float32_300<240,960,1,1>\u001b[0m, float32_301<240>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_302<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_302<1,240,1,1>\u001b[0m) -> float32_303<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_302<1,240,1,1>\u001b[0m, inplace=False) -> float32_303<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_302<1,240,1,1>\u001b[0m) -> float32_303<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_303<1,240,1,1>\u001b[0m) -> float32_306<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_303<1,240,1,1>\u001b[0m, float32_304<960,240,1,1>\u001b[0m, float32_305<960>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_306<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_306<1,960,1,1>\u001b[0m) -> float32_307<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_306<1,960,1,1>\u001b[0m, False) -> float32_307<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_307<1,960,1,1>\u001b[0m, float32_298<1,960,7,7>\u001b[0m) -> float32_308<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_307<1,960,1,1>\u001b[0m, float32_298<1,960,7,7>\u001b[0m) -> float32_308<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_308<1,960,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_308<1,960,7,7>\u001b[0m) -> float32_310<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_308<1,960,7,7>\u001b[0m, float32_309<160,960,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_310<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_310<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_310<1,160,7,7>\u001b[0m, float32_311<160>\u001b[0m, float32_312<160>\u001b[0m, float32_311<160>\u001b[0m, float32_313<160>\u001b[0m, False, 0.01, 0.001) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_310<1,160,7,7>\u001b[0m, float32_311<160>\u001b[0m, float32_313<160>\u001b[0m, float32_311<160>\u001b[0m, float32_312<160>\u001b[0m, False, 0.01, 0.001, True) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_314<1,160,7,7>\u001b[0m, float32_286<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_314<1,160,7,7>\u001b[0m, float32_286<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m\u001b[7m (!) Max diff 0.00013 (0.000%) \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"C:\\Users\\louis\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py\", line 217\u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"C:/Users/louis/AppData/Roaming/Python/Python311/site-packages/torchvision/models/mobilenetv3.py\", line 52 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_314<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m\u001b[7m (!) Max diff 0.00013 (0.000%) \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"C:\\Users\\louis\\AppData\\Roaming\\Python\\Python311\\site-packages\\torchvision\\models\\mobilenetv3.py\", line 111\u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"C:/Users/louis/AppData/Roaming/Python/Python311/site-packages/torch/nn/modules/container.py\", line 43 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33mSequential[torch.nn.modules.container]\u001b[0m(float32_314<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_314<1,160,7,7>\u001b[0m) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_314<1,160,7,7>\u001b[0m) -> float32_316<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_314<1,160,7,7>\u001b[0m, float32_315<960,160,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_316<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_316<1,960,7,7>\u001b[0m) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_316<1,960,7,7>\u001b[0m, float32_317<960>\u001b[0m, float32_318<960>\u001b[0m, float32_317<960>\u001b[0m, float32_319<960>\u001b[0m, False, 0.01, 0.001) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_316<1,960,7,7>\u001b[0m, float32_317<960>\u001b[0m, float32_319<960>\u001b[0m, float32_317<960>\u001b[0m, float32_318<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_320<1,960,7,7>\u001b[0m) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_320<1,960,7,7>\u001b[0m, True) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_320<1,960,7,7>\u001b[0m) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_320<1,960,7,7>\u001b[0m) -> float32_322<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_320<1,960,7,7>\u001b[0m, float32_321<960,1,5,5>\u001b[0m, None, (1, 1), (2, 2), (1, 1), 960) -> float32_322<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_322<1,960,7,7>\u001b[0m) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_322<1,960,7,7>\u001b[0m, float32_323<960>\u001b[0m, float32_324<960>\u001b[0m, float32_325<960>\u001b[0m, float32_323<960>\u001b[0m, False, 0.01, 0.001) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_322<1,960,7,7>\u001b[0m, float32_325<960>\u001b[0m, float32_323<960>\u001b[0m, float32_323<960>\u001b[0m, float32_324<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_326<1,960,7,7>\u001b[0m) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_326<1,960,7,7>\u001b[0m, True) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_326<1,960,7,7>\u001b[0m) -> float32_336<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_326<1,960,7,7>\u001b[0m) -> float32_327<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_326<1,960,7,7>\u001b[0m, 1) -> float32_327<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_327<1,960,1,1>\u001b[0m) -> float32_330<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_327<1,960,1,1>\u001b[0m, float32_328<240,960,1,1>\u001b[0m, float32_329<240>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_330<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_330<1,240,1,1>\u001b[0m) -> float32_331<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_330<1,240,1,1>\u001b[0m, inplace=False) -> float32_331<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_330<1,240,1,1>\u001b[0m) -> float32_331<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_331<1,240,1,1>\u001b[0m) -> float32_334<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_331<1,240,1,1>\u001b[0m, float32_332<960,240,1,1>\u001b[0m, float32_333<960>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_334<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_334<1,960,1,1>\u001b[0m) -> float32_335<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_334<1,960,1,1>\u001b[0m, False) -> float32_335<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_335<1,960,1,1>\u001b[0m, float32_326<1,960,7,7>\u001b[0m) -> float32_336<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_335<1,960,1,1>\u001b[0m, float32_326<1,960,7,7>\u001b[0m) -> float32_336<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m\u001b[7m (!) Max diff 0.00014 (0.000%) \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"C:\\Users\\louis\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py\", line 217\u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"C:/Users/louis/AppData/Roaming/Python/Python311/site-packages/torchvision/ops/misc.py\", line 125 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m ├·\u001b[0m \u001b[33mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_336<1,960,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_336<1,960,7,7>\u001b[0m) -> float32_338<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_336<1,960,7,7>\u001b[0m, float32_337<160,960,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_338<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_338<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_338<1,160,7,7>\u001b[0m, float32_339<160>\u001b[0m, float32_340<160>\u001b[0m, float32_339<160>\u001b[0m, float32_339<160>\u001b[0m, False, 0.01, 0.001) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m └ \u001b[0m \u001b[33m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_338<1,160,7,7>\u001b[0m, float32_339<160>\u001b[0m, float32_339<160>\u001b[0m, float32_339<160>\u001b[0m, float32_340<160>\u001b[0m, False, 0.01, 0.001, True) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_341<1,160,7,7>\u001b[0m, float32_314<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[33m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_341<1,160,7,7>\u001b[0m, float32_314<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_341<1,160,7,7>\u001b[0m) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_341<1,160,7,7>\u001b[0m) -> float32_343<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_341<1,160,7,7>\u001b[0m, float32_342<960,160,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_343<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_343<1,960,7,7>\u001b[0m) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_343<1,960,7,7>\u001b[0m, float32_344<960>\u001b[0m, float32_344<960>\u001b[0m, float32_345<960>\u001b[0m, float32_345<960>\u001b[0m, False, 0.01, 0.001) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_343<1,960,7,7>\u001b[0m, float32_345<960>\u001b[0m, float32_345<960>\u001b[0m, float32_344<960>\u001b[0m, float32_344<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_346<1,960,7,7>\u001b[0m) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_346<1,960,7,7>\u001b[0m, True) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_346<1,960,7,7>\u001b[0m) -> float32_347<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_346<1,960,7,7>\u001b[0m, 1) -> float32_347<1,960,1,1>\u001b[0m\n",
      "\u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_347<1,960,1,1>\u001b[0m) -> float32_361<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_347<1,960,1,1>\u001b[0m) -> float32_348<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_347<1,960,1,1>\u001b[0m, 1) -> float32_348<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mFlatten[torch.nn.modules.flatten]\u001b[0m(float32_348<1,960,1,1>\u001b[0m) -> float32_349<1,960>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mflatten[torch.Tensor]\u001b[0m(float32_348<1,960,1,1>\u001b[0m, 1, -1) -> float32_349<1,960>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_349<1,960>\u001b[0m) -> float32_352<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_349<1,960>\u001b[0m, float32_350<1024,960>\u001b[0m, float32_351<1024>\u001b[0m) -> float32_352<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_352<1,1024>\u001b[0m) -> float32_353<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_352<1,1024>\u001b[0m, inplace=False) -> float32_353<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_352<1,1024>\u001b[0m) -> float32_353<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_353<1,1024>\u001b[0m) -> float32_356<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_353<1,1024>\u001b[0m, float32_354<512,1024>\u001b[0m, float32_355<512>\u001b[0m) -> float32_356<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_356<1,512>\u001b[0m) -> float32_357<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_356<1,512>\u001b[0m, inplace=False) -> float32_357<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_356<1,512>\u001b[0m) -> float32_357<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_357<1,512>\u001b[0m) -> float32_360<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_357<1,512>\u001b[0m, float32_358<5,512>\u001b[0m, float32_359<5>\u001b[0m) -> float32_360<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSoftmax[torch.nn.modules.activation]\u001b[0m(float32_360<1,5>\u001b[0m) -> float32_361<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_360<1,5>\u001b[0m, 1, _stacklevel=5) -> float32_361<1,5>\u001b[0m\n",
      "\u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_360<1,5>\u001b[0m, 1) -> float32_361<1,5>\u001b[0m\n",
      "\n",
      "Conversion complete. Elapsed time: 6.50 sec.\n"
     ]
    }
   ],
   "source": [
    "keras_model = nobuco.pytorch_to_keras(\n",
    "    saved_model,\n",
    "    args=[input_tensor], kwargs=None,\n",
    "    inputs_channel_order=ChannelOrder.TENSORFLOW,\n",
    "    outputs_channel_order=ChannelOrder.TENSORFLOW\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\louis\\anaconda3\\envs\\nobuco\\Lib\\site-packages\\nobuco\\converters\\validation.py:55: RuntimeWarning: [<class 'torch.nn.modules.container.Sequential'>|NeuralNetwork->Sequential] conversion procedure might be incorrect: max. discrepancy for output #0 is 0.00022 (0.007%)\n",
      "  warnings.warn(warn_string, category=RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Legend:\n",
      "    \u001b[32mGreen\u001b[0m — conversion successful\n",
      "    \u001b[33mYellow\u001b[0m — conversion imprecise\n",
      "    \u001b[31mRed\u001b[0m — conversion failed\n",
      "    \u001b[31m\u001b[7mRed\u001b[0m — no converter found\n",
      "    \u001b[0m\u001b[1mBold\u001b[0m — conversion applied directly\n",
      "    * — subgraph reused\n",
      "    \u001b[7mTensor\u001b[0m — this output is not dependent on any of subgraph's input tensors\n",
      "    \u001b[4mTensor\u001b[0m — this input is a parameter / constant\n",
      "    \u001b[90mTensor\u001b[0m — this tensor is useless\n",
      "\n",
      "\u001b[32mNeuralNetwork[__main__]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_360<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_347<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m\u001b[7m (!) Max diff 0.00022 (0.007%) \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[90m I \u001b[0m\u001b[90m File \"C:\\Users\\louis\\AppData\\Roaming\\Python\\Python311\\site-packages\\torch\\nn\\modules\\container.py\", line 217\u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[90m D \u001b[0m\u001b[90m File \"C:/Users/louis/AppData/Roaming/Python/Python311/site-packages/torch/nn/modules/container.py\", line 43 \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33mSequential[torch.nn.modules.container]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_0<1,3,224,224>\u001b[0m) -> float32_2<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_0<1,3,224,224>\u001b[0m, float32_1<16,3,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 1) -> float32_2<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_2<1,16,112,112>\u001b[0m) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_2<1,16,112,112>\u001b[0m, float32_3<16>\u001b[0m, float32_3<16>\u001b[0m, float32_4<16>\u001b[0m, float32_3<16>\u001b[0m, False, 0.01, 0.001) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_2<1,16,112,112>\u001b[0m, float32_4<16>\u001b[0m, float32_3<16>\u001b[0m, float32_3<16>\u001b[0m, float32_3<16>\u001b[0m, False, 0.01, 0.001, True) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_5<1,16,112,112>\u001b[0m, True) -> float32_5<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_5<1,16,112,112>\u001b[0m) -> float32_7<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_5<1,16,112,112>\u001b[0m, float32_6<16,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 16) -> float32_7<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_7<1,16,112,112>\u001b[0m) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_7<1,16,112,112>\u001b[0m, float32_8<16>\u001b[0m, float32_9<16>\u001b[0m, float32_10<16>\u001b[0m, float32_11<16>\u001b[0m, False, 0.01, 0.001) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_7<1,16,112,112>\u001b[0m, float32_10<16>\u001b[0m, float32_11<16>\u001b[0m, float32_8<16>\u001b[0m, float32_9<16>\u001b[0m, False, 0.01, 0.001, True) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_12<1,16,112,112>\u001b[0m) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_12<1,16,112,112>\u001b[0m, inplace=True) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_12<1,16,112,112>\u001b[0m) -> float32_12<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_12<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_12<1,16,112,112>\u001b[0m) -> float32_14<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_12<1,16,112,112>\u001b[0m, float32_13<16,16,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_14<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_14<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_14<1,16,112,112>\u001b[0m, float32_15<16>\u001b[0m, float32_16<16>\u001b[0m, float32_16<16>\u001b[0m, float32_17<16>\u001b[0m, False, 0.01, 0.001) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_14<1,16,112,112>\u001b[0m, float32_16<16>\u001b[0m, float32_17<16>\u001b[0m, float32_15<16>\u001b[0m, float32_16<16>\u001b[0m, False, 0.01, 0.001, True) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_18<1,16,112,112>\u001b[0m, float32_5<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_18<1,16,112,112>\u001b[0m, float32_5<1,16,112,112>\u001b[0m) -> float32_18<1,16,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_18<1,16,112,112>\u001b[0m) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_18<1,16,112,112>\u001b[0m) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_18<1,16,112,112>\u001b[0m) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_18<1,16,112,112>\u001b[0m) -> float32_20<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_18<1,16,112,112>\u001b[0m, float32_19<64,16,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_20<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_20<1,64,112,112>\u001b[0m) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_20<1,64,112,112>\u001b[0m, float32_21<64>\u001b[0m, float32_22<64>\u001b[0m, float32_22<64>\u001b[0m, float32_22<64>\u001b[0m, False, 0.01, 0.001) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_20<1,64,112,112>\u001b[0m, float32_22<64>\u001b[0m, float32_22<64>\u001b[0m, float32_21<64>\u001b[0m, float32_22<64>\u001b[0m, False, 0.01, 0.001, True) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_23<1,64,112,112>\u001b[0m) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_23<1,64,112,112>\u001b[0m, inplace=True) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_23<1,64,112,112>\u001b[0m) -> float32_23<1,64,112,112>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_23<1,64,112,112>\u001b[0m) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_23<1,64,112,112>\u001b[0m) -> float32_25<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_23<1,64,112,112>\u001b[0m, float32_24<64,1,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 64) -> float32_25<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_25<1,64,56,56>\u001b[0m) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_25<1,64,56,56>\u001b[0m, float32_26<64>\u001b[0m, float32_27<64>\u001b[0m, float32_28<64>\u001b[0m, float32_29<64>\u001b[0m, False, 0.01, 0.001) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_25<1,64,56,56>\u001b[0m, float32_28<64>\u001b[0m, float32_29<64>\u001b[0m, float32_26<64>\u001b[0m, float32_27<64>\u001b[0m, False, 0.01, 0.001, True) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_30<1,64,56,56>\u001b[0m) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_30<1,64,56,56>\u001b[0m, inplace=True) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_30<1,64,56,56>\u001b[0m) -> float32_30<1,64,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_30<1,64,56,56>\u001b[0m) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_30<1,64,56,56>\u001b[0m) -> float32_32<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_30<1,64,56,56>\u001b[0m, float32_31<24,64,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_32<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_32<1,24,56,56>\u001b[0m) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_32<1,24,56,56>\u001b[0m, float32_33<24>\u001b[0m, float32_33<24>\u001b[0m, float32_34<24>\u001b[0m, float32_33<24>\u001b[0m, False, 0.01, 0.001) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_32<1,24,56,56>\u001b[0m, float32_34<24>\u001b[0m, float32_33<24>\u001b[0m, float32_33<24>\u001b[0m, float32_33<24>\u001b[0m, False, 0.01, 0.001, True) -> float32_35<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_35<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_35<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_35<1,24,56,56>\u001b[0m) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_35<1,24,56,56>\u001b[0m) -> float32_37<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_35<1,24,56,56>\u001b[0m, float32_36<72,24,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_37<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_37<1,72,56,56>\u001b[0m) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_37<1,72,56,56>\u001b[0m, float32_38<72>\u001b[0m, float32_39<72>\u001b[0m, float32_40<72>\u001b[0m, float32_41<72>\u001b[0m, False, 0.01, 0.001) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_37<1,72,56,56>\u001b[0m, float32_40<72>\u001b[0m, float32_41<72>\u001b[0m, float32_38<72>\u001b[0m, float32_39<72>\u001b[0m, False, 0.01, 0.001, True) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_42<1,72,56,56>\u001b[0m) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_42<1,72,56,56>\u001b[0m, inplace=True) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_42<1,72,56,56>\u001b[0m) -> float32_42<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_42<1,72,56,56>\u001b[0m) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_42<1,72,56,56>\u001b[0m) -> float32_44<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_42<1,72,56,56>\u001b[0m, float32_43<72,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 72) -> float32_44<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_44<1,72,56,56>\u001b[0m) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_44<1,72,56,56>\u001b[0m, float32_45<72>\u001b[0m, float32_46<72>\u001b[0m, float32_47<72>\u001b[0m, float32_47<72>\u001b[0m, False, 0.01, 0.001) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_44<1,72,56,56>\u001b[0m, float32_47<72>\u001b[0m, float32_47<72>\u001b[0m, float32_45<72>\u001b[0m, float32_46<72>\u001b[0m, False, 0.01, 0.001, True) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_48<1,72,56,56>\u001b[0m) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_48<1,72,56,56>\u001b[0m, inplace=True) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_48<1,72,56,56>\u001b[0m) -> float32_48<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_48<1,72,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_48<1,72,56,56>\u001b[0m) -> float32_50<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_48<1,72,56,56>\u001b[0m, float32_49<24,72,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_50<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_50<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_50<1,24,56,56>\u001b[0m, float32_51<24>\u001b[0m, float32_52<24>\u001b[0m, float32_53<24>\u001b[0m, float32_52<24>\u001b[0m, False, 0.01, 0.001) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_50<1,24,56,56>\u001b[0m, float32_53<24>\u001b[0m, float32_52<24>\u001b[0m, float32_51<24>\u001b[0m, float32_52<24>\u001b[0m, False, 0.01, 0.001, True) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_54<1,24,56,56>\u001b[0m, float32_35<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_54<1,24,56,56>\u001b[0m, float32_35<1,24,56,56>\u001b[0m) -> float32_54<1,24,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_54<1,24,56,56>\u001b[0m) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_54<1,24,56,56>\u001b[0m) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_54<1,24,56,56>\u001b[0m) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_54<1,24,56,56>\u001b[0m) -> float32_56<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_54<1,24,56,56>\u001b[0m, float32_55<72,24,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_56<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_56<1,72,56,56>\u001b[0m) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_56<1,72,56,56>\u001b[0m, float32_57<72>\u001b[0m, float32_57<72>\u001b[0m, float32_58<72>\u001b[0m, float32_59<72>\u001b[0m, False, 0.01, 0.001) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_56<1,72,56,56>\u001b[0m, float32_58<72>\u001b[0m, float32_59<72>\u001b[0m, float32_57<72>\u001b[0m, float32_57<72>\u001b[0m, False, 0.01, 0.001, True) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_60<1,72,56,56>\u001b[0m) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_60<1,72,56,56>\u001b[0m, inplace=True) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_60<1,72,56,56>\u001b[0m) -> float32_60<1,72,56,56>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_60<1,72,56,56>\u001b[0m) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_60<1,72,56,56>\u001b[0m) -> float32_62<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_60<1,72,56,56>\u001b[0m, float32_61<72,1,5,5>\u001b[0m, None, (2, 2), (2, 2), (1, 1), 72) -> float32_62<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_62<1,72,28,28>\u001b[0m) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_62<1,72,28,28>\u001b[0m, float32_63<72>\u001b[0m, float32_64<72>\u001b[0m, float32_65<72>\u001b[0m, float32_66<72>\u001b[0m, False, 0.01, 0.001) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_62<1,72,28,28>\u001b[0m, float32_65<72>\u001b[0m, float32_66<72>\u001b[0m, float32_63<72>\u001b[0m, float32_64<72>\u001b[0m, False, 0.01, 0.001, True) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_67<1,72,28,28>\u001b[0m) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_67<1,72,28,28>\u001b[0m, inplace=True) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_67<1,72,28,28>\u001b[0m) -> float32_67<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_67<1,72,28,28>\u001b[0m) -> float32_77<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_67<1,72,28,28>\u001b[0m) -> float32_68<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_67<1,72,28,28>\u001b[0m, 1) -> float32_68<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_68<1,72,1,1>\u001b[0m) -> float32_71<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_68<1,72,1,1>\u001b[0m, float32_69<24,72,1,1>\u001b[0m, float32_70<24>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_71<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_71<1,24,1,1>\u001b[0m) -> float32_72<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_71<1,24,1,1>\u001b[0m, inplace=False) -> float32_72<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_71<1,24,1,1>\u001b[0m) -> float32_72<1,24,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_72<1,24,1,1>\u001b[0m) -> float32_75<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_72<1,24,1,1>\u001b[0m, float32_73<72,24,1,1>\u001b[0m, float32_74<72>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_75<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_75<1,72,1,1>\u001b[0m) -> float32_76<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_75<1,72,1,1>\u001b[0m, False) -> float32_76<1,72,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_76<1,72,1,1>\u001b[0m, float32_67<1,72,28,28>\u001b[0m) -> float32_77<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_76<1,72,1,1>\u001b[0m, float32_67<1,72,28,28>\u001b[0m) -> float32_77<1,72,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_77<1,72,28,28>\u001b[0m) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_77<1,72,28,28>\u001b[0m) -> float32_79<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_77<1,72,28,28>\u001b[0m, float32_78<40,72,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_79<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_79<1,40,28,28>\u001b[0m) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_79<1,40,28,28>\u001b[0m, float32_80<40>\u001b[0m, float32_81<40>\u001b[0m, float32_80<40>\u001b[0m, float32_82<40>\u001b[0m, False, 0.01, 0.001) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_79<1,40,28,28>\u001b[0m, float32_80<40>\u001b[0m, float32_82<40>\u001b[0m, float32_80<40>\u001b[0m, float32_81<40>\u001b[0m, False, 0.01, 0.001, True) -> float32_83<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_83<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_83<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_83<1,40,28,28>\u001b[0m) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_83<1,40,28,28>\u001b[0m) -> float32_85<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_83<1,40,28,28>\u001b[0m, float32_84<120,40,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_85<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_85<1,120,28,28>\u001b[0m) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_85<1,120,28,28>\u001b[0m, float32_86<120>\u001b[0m, float32_87<120>\u001b[0m, float32_88<120>\u001b[0m, float32_86<120>\u001b[0m, False, 0.01, 0.001) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_85<1,120,28,28>\u001b[0m, float32_88<120>\u001b[0m, float32_86<120>\u001b[0m, float32_86<120>\u001b[0m, float32_87<120>\u001b[0m, False, 0.01, 0.001, True) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_89<1,120,28,28>\u001b[0m) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_89<1,120,28,28>\u001b[0m, inplace=True) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_89<1,120,28,28>\u001b[0m) -> float32_89<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_89<1,120,28,28>\u001b[0m) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_89<1,120,28,28>\u001b[0m) -> float32_91<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_89<1,120,28,28>\u001b[0m, float32_90<120,1,5,5>\u001b[0m, None, (1, 1), (2, 2), (1, 1), 120) -> float32_91<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_91<1,120,28,28>\u001b[0m) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_91<1,120,28,28>\u001b[0m, float32_92<120>\u001b[0m, float32_93<120>\u001b[0m, float32_92<120>\u001b[0m, float32_94<120>\u001b[0m, False, 0.01, 0.001) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_91<1,120,28,28>\u001b[0m, float32_92<120>\u001b[0m, float32_94<120>\u001b[0m, float32_92<120>\u001b[0m, float32_93<120>\u001b[0m, False, 0.01, 0.001, True) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_95<1,120,28,28>\u001b[0m) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_95<1,120,28,28>\u001b[0m, inplace=True) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_95<1,120,28,28>\u001b[0m) -> float32_95<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_95<1,120,28,28>\u001b[0m) -> float32_104<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_95<1,120,28,28>\u001b[0m) -> float32_96<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_95<1,120,28,28>\u001b[0m, 1) -> float32_96<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_96<1,120,1,1>\u001b[0m) -> float32_99<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_96<1,120,1,1>\u001b[0m, float32_97<32,120,1,1>\u001b[0m, float32_98<32>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_99<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_99<1,32,1,1>\u001b[0m) -> float32_100<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_99<1,32,1,1>\u001b[0m, inplace=False) -> float32_100<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_99<1,32,1,1>\u001b[0m) -> float32_100<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_100<1,32,1,1>\u001b[0m) -> float32_102<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_100<1,32,1,1>\u001b[0m, float32_101<120,32,1,1>\u001b[0m, float32_101<120>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_102<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_102<1,120,1,1>\u001b[0m) -> float32_103<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_102<1,120,1,1>\u001b[0m, False) -> float32_103<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_103<1,120,1,1>\u001b[0m, float32_95<1,120,28,28>\u001b[0m) -> float32_104<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_103<1,120,1,1>\u001b[0m, float32_95<1,120,28,28>\u001b[0m) -> float32_104<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_104<1,120,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_104<1,120,28,28>\u001b[0m) -> float32_106<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_104<1,120,28,28>\u001b[0m, float32_105<40,120,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_106<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_106<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_106<1,40,28,28>\u001b[0m, float32_107<40>\u001b[0m, float32_108<40>\u001b[0m, float32_109<40>\u001b[0m, float32_109<40>\u001b[0m, False, 0.01, 0.001) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_106<1,40,28,28>\u001b[0m, float32_109<40>\u001b[0m, float32_109<40>\u001b[0m, float32_107<40>\u001b[0m, float32_108<40>\u001b[0m, False, 0.01, 0.001, True) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_110<1,40,28,28>\u001b[0m, float32_83<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_110<1,40,28,28>\u001b[0m, float32_83<1,40,28,28>\u001b[0m) -> float32_110<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_110<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_110<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_110<1,40,28,28>\u001b[0m) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_110<1,40,28,28>\u001b[0m) -> float32_112<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_110<1,40,28,28>\u001b[0m, float32_111<120,40,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_112<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_112<1,120,28,28>\u001b[0m) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_112<1,120,28,28>\u001b[0m, float32_113<120>\u001b[0m, float32_114<120>\u001b[0m, float32_115<120>\u001b[0m, float32_113<120>\u001b[0m, False, 0.01, 0.001) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_112<1,120,28,28>\u001b[0m, float32_115<120>\u001b[0m, float32_113<120>\u001b[0m, float32_113<120>\u001b[0m, float32_114<120>\u001b[0m, False, 0.01, 0.001, True) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_116<1,120,28,28>\u001b[0m) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_116<1,120,28,28>\u001b[0m, inplace=True) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_116<1,120,28,28>\u001b[0m) -> float32_116<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_116<1,120,28,28>\u001b[0m) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_116<1,120,28,28>\u001b[0m) -> float32_118<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_116<1,120,28,28>\u001b[0m, float32_117<120,1,5,5>\u001b[0m, None, (1, 1), (2, 2), (1, 1), 120) -> float32_118<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_118<1,120,28,28>\u001b[0m) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_118<1,120,28,28>\u001b[0m, float32_119<120>\u001b[0m, float32_120<120>\u001b[0m, float32_121<120>\u001b[0m, float32_120<120>\u001b[0m, False, 0.01, 0.001) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_118<1,120,28,28>\u001b[0m, float32_121<120>\u001b[0m, float32_120<120>\u001b[0m, float32_119<120>\u001b[0m, float32_120<120>\u001b[0m, False, 0.01, 0.001, True) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_122<1,120,28,28>\u001b[0m) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_122<1,120,28,28>\u001b[0m, inplace=True) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu_[torch]\u001b[0m(float32_122<1,120,28,28>\u001b[0m) -> float32_122<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_122<1,120,28,28>\u001b[0m) -> float32_131<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_122<1,120,28,28>\u001b[0m) -> float32_123<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_122<1,120,28,28>\u001b[0m, 1) -> float32_123<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_123<1,120,1,1>\u001b[0m) -> float32_125<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_123<1,120,1,1>\u001b[0m, float32_124<32,120,1,1>\u001b[0m, float32_124<32>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_125<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_125<1,32,1,1>\u001b[0m) -> float32_126<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_125<1,32,1,1>\u001b[0m, inplace=False) -> float32_126<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_125<1,32,1,1>\u001b[0m) -> float32_126<1,32,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_126<1,32,1,1>\u001b[0m) -> float32_129<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_126<1,32,1,1>\u001b[0m, float32_127<120,32,1,1>\u001b[0m, float32_128<120>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_129<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_129<1,120,1,1>\u001b[0m) -> float32_130<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_129<1,120,1,1>\u001b[0m, False) -> float32_130<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_130<1,120,1,1>\u001b[0m, float32_122<1,120,28,28>\u001b[0m) -> float32_131<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_130<1,120,1,1>\u001b[0m, float32_122<1,120,28,28>\u001b[0m) -> float32_131<1,120,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_131<1,120,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_131<1,120,28,28>\u001b[0m) -> float32_133<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_131<1,120,28,28>\u001b[0m, float32_132<40,120,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_133<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_133<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_133<1,40,28,28>\u001b[0m, float32_134<40>\u001b[0m, float32_134<40>\u001b[0m, float32_135<40>\u001b[0m, float32_136<40>\u001b[0m, False, 0.01, 0.001) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_133<1,40,28,28>\u001b[0m, float32_135<40>\u001b[0m, float32_136<40>\u001b[0m, float32_134<40>\u001b[0m, float32_134<40>\u001b[0m, False, 0.01, 0.001, True) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_137<1,40,28,28>\u001b[0m, float32_110<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_137<1,40,28,28>\u001b[0m, float32_110<1,40,28,28>\u001b[0m) -> float32_137<1,40,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_137<1,40,28,28>\u001b[0m) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_137<1,40,28,28>\u001b[0m) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_137<1,40,28,28>\u001b[0m) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_137<1,40,28,28>\u001b[0m) -> float32_139<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_137<1,40,28,28>\u001b[0m, float32_138<240,40,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_139<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_139<1,240,28,28>\u001b[0m) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_139<1,240,28,28>\u001b[0m, float32_140<240>\u001b[0m, float32_141<240>\u001b[0m, float32_141<240>\u001b[0m, float32_140<240>\u001b[0m, False, 0.01, 0.001) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_139<1,240,28,28>\u001b[0m, float32_141<240>\u001b[0m, float32_140<240>\u001b[0m, float32_140<240>\u001b[0m, float32_141<240>\u001b[0m, False, 0.01, 0.001, True) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_142<1,240,28,28>\u001b[0m) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_142<1,240,28,28>\u001b[0m, True) -> float32_142<1,240,28,28>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_142<1,240,28,28>\u001b[0m) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_142<1,240,28,28>\u001b[0m) -> float32_144<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_142<1,240,28,28>\u001b[0m, float32_143<240,1,3,3>\u001b[0m, None, (2, 2), (1, 1), (1, 1), 240) -> float32_144<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_144<1,240,14,14>\u001b[0m) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_144<1,240,14,14>\u001b[0m, float32_145<240>\u001b[0m, float32_145<240>\u001b[0m, float32_145<240>\u001b[0m, float32_146<240>\u001b[0m, False, 0.01, 0.001) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_144<1,240,14,14>\u001b[0m, float32_145<240>\u001b[0m, float32_146<240>\u001b[0m, float32_145<240>\u001b[0m, float32_145<240>\u001b[0m, False, 0.01, 0.001, True) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_147<1,240,14,14>\u001b[0m) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_147<1,240,14,14>\u001b[0m, True) -> float32_147<1,240,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_147<1,240,14,14>\u001b[0m) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_147<1,240,14,14>\u001b[0m) -> float32_149<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_147<1,240,14,14>\u001b[0m, float32_148<80,240,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_149<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_149<1,80,14,14>\u001b[0m) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_149<1,80,14,14>\u001b[0m, float32_150<80>\u001b[0m, float32_150<80>\u001b[0m, float32_150<80>\u001b[0m, float32_151<80>\u001b[0m, False, 0.01, 0.001) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_149<1,80,14,14>\u001b[0m, float32_150<80>\u001b[0m, float32_151<80>\u001b[0m, float32_150<80>\u001b[0m, float32_150<80>\u001b[0m, False, 0.01, 0.001, True) -> float32_152<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_152<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_152<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_152<1,80,14,14>\u001b[0m) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_152<1,80,14,14>\u001b[0m) -> float32_154<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_152<1,80,14,14>\u001b[0m, float32_153<200,80,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_154<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_154<1,200,14,14>\u001b[0m) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_154<1,200,14,14>\u001b[0m, float32_155<200>\u001b[0m, float32_155<200>\u001b[0m, float32_156<200>\u001b[0m, float32_157<200>\u001b[0m, False, 0.01, 0.001) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_154<1,200,14,14>\u001b[0m, float32_156<200>\u001b[0m, float32_157<200>\u001b[0m, float32_155<200>\u001b[0m, float32_155<200>\u001b[0m, False, 0.01, 0.001, True) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_158<1,200,14,14>\u001b[0m) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_158<1,200,14,14>\u001b[0m, True) -> float32_158<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_158<1,200,14,14>\u001b[0m) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_158<1,200,14,14>\u001b[0m) -> float32_160<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_158<1,200,14,14>\u001b[0m, float32_159<200,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 200) -> float32_160<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_160<1,200,14,14>\u001b[0m) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_160<1,200,14,14>\u001b[0m, float32_161<200>\u001b[0m, float32_162<200>\u001b[0m, float32_161<200>\u001b[0m, float32_162<200>\u001b[0m, False, 0.01, 0.001) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_160<1,200,14,14>\u001b[0m, float32_161<200>\u001b[0m, float32_162<200>\u001b[0m, float32_161<200>\u001b[0m, float32_162<200>\u001b[0m, False, 0.01, 0.001, True) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_163<1,200,14,14>\u001b[0m) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_163<1,200,14,14>\u001b[0m, True) -> float32_163<1,200,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_163<1,200,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_163<1,200,14,14>\u001b[0m) -> float32_165<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_163<1,200,14,14>\u001b[0m, float32_164<80,200,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_165<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_165<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_165<1,80,14,14>\u001b[0m, float32_166<80>\u001b[0m, float32_167<80>\u001b[0m, float32_167<80>\u001b[0m, float32_167<80>\u001b[0m, False, 0.01, 0.001) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_165<1,80,14,14>\u001b[0m, float32_167<80>\u001b[0m, float32_167<80>\u001b[0m, float32_166<80>\u001b[0m, float32_167<80>\u001b[0m, False, 0.01, 0.001, True) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_168<1,80,14,14>\u001b[0m, float32_152<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_168<1,80,14,14>\u001b[0m, float32_152<1,80,14,14>\u001b[0m) -> float32_168<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_168<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_168<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_168<1,80,14,14>\u001b[0m) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_168<1,80,14,14>\u001b[0m) -> float32_170<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_168<1,80,14,14>\u001b[0m, float32_169<184,80,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_170<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_170<1,184,14,14>\u001b[0m) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_170<1,184,14,14>\u001b[0m, float32_171<184>\u001b[0m, float32_172<184>\u001b[0m, float32_173<184>\u001b[0m, float32_173<184>\u001b[0m, False, 0.01, 0.001) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_170<1,184,14,14>\u001b[0m, float32_173<184>\u001b[0m, float32_173<184>\u001b[0m, float32_171<184>\u001b[0m, float32_172<184>\u001b[0m, False, 0.01, 0.001, True) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_174<1,184,14,14>\u001b[0m) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_174<1,184,14,14>\u001b[0m, True) -> float32_174<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_174<1,184,14,14>\u001b[0m) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_174<1,184,14,14>\u001b[0m) -> float32_176<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_174<1,184,14,14>\u001b[0m, float32_175<184,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 184) -> float32_176<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_176<1,184,14,14>\u001b[0m) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_176<1,184,14,14>\u001b[0m, float32_177<184>\u001b[0m, float32_178<184>\u001b[0m, float32_179<184>\u001b[0m, float32_179<184>\u001b[0m, False, 0.01, 0.001) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_176<1,184,14,14>\u001b[0m, float32_179<184>\u001b[0m, float32_179<184>\u001b[0m, float32_177<184>\u001b[0m, float32_178<184>\u001b[0m, False, 0.01, 0.001, True) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_180<1,184,14,14>\u001b[0m) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_180<1,184,14,14>\u001b[0m, True) -> float32_180<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_180<1,184,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_180<1,184,14,14>\u001b[0m) -> float32_182<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_180<1,184,14,14>\u001b[0m, float32_181<80,184,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_182<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_182<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_182<1,80,14,14>\u001b[0m, float32_183<80>\u001b[0m, float32_183<80>\u001b[0m, float32_183<80>\u001b[0m, float32_184<80>\u001b[0m, False, 0.01, 0.001) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_182<1,80,14,14>\u001b[0m, float32_183<80>\u001b[0m, float32_184<80>\u001b[0m, float32_183<80>\u001b[0m, float32_183<80>\u001b[0m, False, 0.01, 0.001, True) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_185<1,80,14,14>\u001b[0m, float32_168<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_185<1,80,14,14>\u001b[0m, float32_168<1,80,14,14>\u001b[0m) -> float32_185<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_185<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_185<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_185<1,80,14,14>\u001b[0m) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_185<1,80,14,14>\u001b[0m) -> float32_187<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_185<1,80,14,14>\u001b[0m, float32_186<184,80,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_187<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_187<1,184,14,14>\u001b[0m) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_187<1,184,14,14>\u001b[0m, float32_188<184>\u001b[0m, float32_189<184>\u001b[0m, float32_189<184>\u001b[0m, float32_189<184>\u001b[0m, False, 0.01, 0.001) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_187<1,184,14,14>\u001b[0m, float32_189<184>\u001b[0m, float32_189<184>\u001b[0m, float32_188<184>\u001b[0m, float32_189<184>\u001b[0m, False, 0.01, 0.001, True) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_190<1,184,14,14>\u001b[0m) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_190<1,184,14,14>\u001b[0m, True) -> float32_190<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_190<1,184,14,14>\u001b[0m) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_190<1,184,14,14>\u001b[0m) -> float32_192<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_190<1,184,14,14>\u001b[0m, float32_191<184,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 184) -> float32_192<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_192<1,184,14,14>\u001b[0m) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_192<1,184,14,14>\u001b[0m, float32_193<184>\u001b[0m, float32_194<184>\u001b[0m, float32_194<184>\u001b[0m, float32_194<184>\u001b[0m, False, 0.01, 0.001) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_192<1,184,14,14>\u001b[0m, float32_194<184>\u001b[0m, float32_194<184>\u001b[0m, float32_193<184>\u001b[0m, float32_194<184>\u001b[0m, False, 0.01, 0.001, True) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_195<1,184,14,14>\u001b[0m) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_195<1,184,14,14>\u001b[0m, True) -> float32_195<1,184,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_195<1,184,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_195<1,184,14,14>\u001b[0m) -> float32_197<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_195<1,184,14,14>\u001b[0m, float32_196<80,184,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_197<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_197<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_197<1,80,14,14>\u001b[0m, float32_198<80>\u001b[0m, float32_198<80>\u001b[0m, float32_199<80>\u001b[0m, float32_198<80>\u001b[0m, False, 0.01, 0.001) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_197<1,80,14,14>\u001b[0m, float32_199<80>\u001b[0m, float32_198<80>\u001b[0m, float32_198<80>\u001b[0m, float32_198<80>\u001b[0m, False, 0.01, 0.001, True) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_200<1,80,14,14>\u001b[0m, float32_185<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_200<1,80,14,14>\u001b[0m, float32_185<1,80,14,14>\u001b[0m) -> float32_200<1,80,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_200<1,80,14,14>\u001b[0m) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_200<1,80,14,14>\u001b[0m) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_200<1,80,14,14>\u001b[0m) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_200<1,80,14,14>\u001b[0m) -> float32_202<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_200<1,80,14,14>\u001b[0m, float32_201<480,80,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_202<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_202<1,480,14,14>\u001b[0m) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_202<1,480,14,14>\u001b[0m, float32_203<480>\u001b[0m, float32_204<480>\u001b[0m, float32_205<480>\u001b[0m, float32_206<480>\u001b[0m, False, 0.01, 0.001) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_202<1,480,14,14>\u001b[0m, float32_205<480>\u001b[0m, float32_206<480>\u001b[0m, float32_203<480>\u001b[0m, float32_204<480>\u001b[0m, False, 0.01, 0.001, True) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_207<1,480,14,14>\u001b[0m) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_207<1,480,14,14>\u001b[0m, True) -> float32_207<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_207<1,480,14,14>\u001b[0m) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_207<1,480,14,14>\u001b[0m) -> float32_209<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_207<1,480,14,14>\u001b[0m, float32_208<480,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 480) -> float32_209<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_209<1,480,14,14>\u001b[0m) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_209<1,480,14,14>\u001b[0m, float32_210<480>\u001b[0m, float32_211<480>\u001b[0m, float32_212<480>\u001b[0m, float32_213<480>\u001b[0m, False, 0.01, 0.001) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_209<1,480,14,14>\u001b[0m, float32_212<480>\u001b[0m, float32_213<480>\u001b[0m, float32_210<480>\u001b[0m, float32_211<480>\u001b[0m, False, 0.01, 0.001, True) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_214<1,480,14,14>\u001b[0m) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_214<1,480,14,14>\u001b[0m, True) -> float32_214<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_214<1,480,14,14>\u001b[0m) -> float32_224<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_214<1,480,14,14>\u001b[0m) -> float32_215<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_214<1,480,14,14>\u001b[0m, 1) -> float32_215<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_215<1,480,1,1>\u001b[0m) -> float32_218<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_215<1,480,1,1>\u001b[0m, float32_216<120,480,1,1>\u001b[0m, float32_217<120>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_218<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_218<1,120,1,1>\u001b[0m) -> float32_219<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_218<1,120,1,1>\u001b[0m, inplace=False) -> float32_219<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_218<1,120,1,1>\u001b[0m) -> float32_219<1,120,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_219<1,120,1,1>\u001b[0m) -> float32_222<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_219<1,120,1,1>\u001b[0m, float32_220<480,120,1,1>\u001b[0m, float32_221<480>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_222<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_222<1,480,1,1>\u001b[0m) -> float32_223<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_222<1,480,1,1>\u001b[0m, False) -> float32_223<1,480,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_223<1,480,1,1>\u001b[0m, float32_214<1,480,14,14>\u001b[0m) -> float32_224<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_223<1,480,1,1>\u001b[0m, float32_214<1,480,14,14>\u001b[0m) -> float32_224<1,480,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_224<1,480,14,14>\u001b[0m) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_224<1,480,14,14>\u001b[0m) -> float32_226<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_224<1,480,14,14>\u001b[0m, float32_225<112,480,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_226<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_226<1,112,14,14>\u001b[0m) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_226<1,112,14,14>\u001b[0m, float32_227<112>\u001b[0m, float32_228<112>\u001b[0m, float32_228<112>\u001b[0m, float32_229<112>\u001b[0m, False, 0.01, 0.001) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_226<1,112,14,14>\u001b[0m, float32_228<112>\u001b[0m, float32_229<112>\u001b[0m, float32_227<112>\u001b[0m, float32_228<112>\u001b[0m, False, 0.01, 0.001, True) -> float32_230<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_230<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_230<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_230<1,112,14,14>\u001b[0m) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_230<1,112,14,14>\u001b[0m) -> float32_232<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_230<1,112,14,14>\u001b[0m, float32_231<672,112,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_232<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_232<1,672,14,14>\u001b[0m) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_232<1,672,14,14>\u001b[0m, float32_233<672>\u001b[0m, float32_234<672>\u001b[0m, float32_235<672>\u001b[0m, float32_234<672>\u001b[0m, False, 0.01, 0.001) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_232<1,672,14,14>\u001b[0m, float32_235<672>\u001b[0m, float32_234<672>\u001b[0m, float32_233<672>\u001b[0m, float32_234<672>\u001b[0m, False, 0.01, 0.001, True) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_236<1,672,14,14>\u001b[0m) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_236<1,672,14,14>\u001b[0m, True) -> float32_236<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_236<1,672,14,14>\u001b[0m) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_236<1,672,14,14>\u001b[0m) -> float32_238<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_236<1,672,14,14>\u001b[0m, float32_237<672,1,3,3>\u001b[0m, None, (1, 1), (1, 1), (1, 1), 672) -> float32_238<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_238<1,672,14,14>\u001b[0m) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_238<1,672,14,14>\u001b[0m, float32_239<672>\u001b[0m, float32_240<672>\u001b[0m, float32_241<672>\u001b[0m, float32_242<672>\u001b[0m, False, 0.01, 0.001) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_238<1,672,14,14>\u001b[0m, float32_241<672>\u001b[0m, float32_242<672>\u001b[0m, float32_239<672>\u001b[0m, float32_240<672>\u001b[0m, False, 0.01, 0.001, True) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_243<1,672,14,14>\u001b[0m) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_243<1,672,14,14>\u001b[0m, True) -> float32_243<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_243<1,672,14,14>\u001b[0m) -> float32_252<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_243<1,672,14,14>\u001b[0m) -> float32_244<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_243<1,672,14,14>\u001b[0m, 1) -> float32_244<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_244<1,672,1,1>\u001b[0m) -> float32_247<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_244<1,672,1,1>\u001b[0m, float32_245<168,672,1,1>\u001b[0m, float32_246<168>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_247<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_247<1,168,1,1>\u001b[0m) -> float32_248<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_247<1,168,1,1>\u001b[0m, inplace=False) -> float32_248<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_247<1,168,1,1>\u001b[0m) -> float32_248<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_248<1,168,1,1>\u001b[0m) -> float32_250<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_248<1,168,1,1>\u001b[0m, float32_249<672,168,1,1>\u001b[0m, float32_249<672>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_250<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_250<1,672,1,1>\u001b[0m) -> float32_251<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_250<1,672,1,1>\u001b[0m, False) -> float32_251<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_251<1,672,1,1>\u001b[0m, float32_243<1,672,14,14>\u001b[0m) -> float32_252<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_251<1,672,1,1>\u001b[0m, float32_243<1,672,14,14>\u001b[0m) -> float32_252<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_252<1,672,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_252<1,672,14,14>\u001b[0m) -> float32_254<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_252<1,672,14,14>\u001b[0m, float32_253<112,672,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_254<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_254<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_254<1,112,14,14>\u001b[0m, float32_255<112>\u001b[0m, float32_256<112>\u001b[0m, float32_255<112>\u001b[0m, float32_255<112>\u001b[0m, False, 0.01, 0.001) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_254<1,112,14,14>\u001b[0m, float32_255<112>\u001b[0m, float32_255<112>\u001b[0m, float32_255<112>\u001b[0m, float32_256<112>\u001b[0m, False, 0.01, 0.001, True) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_257<1,112,14,14>\u001b[0m, float32_230<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_257<1,112,14,14>\u001b[0m, float32_230<1,112,14,14>\u001b[0m) -> float32_257<1,112,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_257<1,112,14,14>\u001b[0m) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_257<1,112,14,14>\u001b[0m) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_257<1,112,14,14>\u001b[0m) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_257<1,112,14,14>\u001b[0m) -> float32_259<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_257<1,112,14,14>\u001b[0m, float32_258<672,112,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_259<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_259<1,672,14,14>\u001b[0m) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_259<1,672,14,14>\u001b[0m, float32_260<672>\u001b[0m, float32_261<672>\u001b[0m, float32_260<672>\u001b[0m, float32_262<672>\u001b[0m, False, 0.01, 0.001) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_259<1,672,14,14>\u001b[0m, float32_260<672>\u001b[0m, float32_262<672>\u001b[0m, float32_260<672>\u001b[0m, float32_261<672>\u001b[0m, False, 0.01, 0.001, True) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_263<1,672,14,14>\u001b[0m) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_263<1,672,14,14>\u001b[0m, True) -> float32_263<1,672,14,14>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_263<1,672,14,14>\u001b[0m) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_263<1,672,14,14>\u001b[0m) -> float32_265<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_263<1,672,14,14>\u001b[0m, float32_264<672,1,5,5>\u001b[0m, None, (2, 2), (2, 2), (1, 1), 672) -> float32_265<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_265<1,672,7,7>\u001b[0m) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_265<1,672,7,7>\u001b[0m, float32_266<672>\u001b[0m, float32_267<672>\u001b[0m, float32_268<672>\u001b[0m, float32_268<672>\u001b[0m, False, 0.01, 0.001) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_265<1,672,7,7>\u001b[0m, float32_268<672>\u001b[0m, float32_268<672>\u001b[0m, float32_266<672>\u001b[0m, float32_267<672>\u001b[0m, False, 0.01, 0.001, True) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_269<1,672,7,7>\u001b[0m) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_269<1,672,7,7>\u001b[0m, True) -> float32_269<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_269<1,672,7,7>\u001b[0m) -> float32_279<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_269<1,672,7,7>\u001b[0m) -> float32_270<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_269<1,672,7,7>\u001b[0m, 1) -> float32_270<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_270<1,672,1,1>\u001b[0m) -> float32_273<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_270<1,672,1,1>\u001b[0m, float32_271<168,672,1,1>\u001b[0m, float32_272<168>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_273<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_273<1,168,1,1>\u001b[0m) -> float32_274<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_273<1,168,1,1>\u001b[0m, inplace=False) -> float32_274<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_273<1,168,1,1>\u001b[0m) -> float32_274<1,168,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_274<1,168,1,1>\u001b[0m) -> float32_277<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_274<1,168,1,1>\u001b[0m, float32_275<672,168,1,1>\u001b[0m, float32_276<672>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_277<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_277<1,672,1,1>\u001b[0m) -> float32_278<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_277<1,672,1,1>\u001b[0m, False) -> float32_278<1,672,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_278<1,672,1,1>\u001b[0m, float32_269<1,672,7,7>\u001b[0m) -> float32_279<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_278<1,672,1,1>\u001b[0m, float32_269<1,672,7,7>\u001b[0m) -> float32_279<1,672,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_279<1,672,7,7>\u001b[0m) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_279<1,672,7,7>\u001b[0m) -> float32_281<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_279<1,672,7,7>\u001b[0m, float32_280<160,672,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_281<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_281<1,160,7,7>\u001b[0m) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_281<1,160,7,7>\u001b[0m, float32_282<160>\u001b[0m, float32_283<160>\u001b[0m, float32_284<160>\u001b[0m, float32_285<160>\u001b[0m, False, 0.01, 0.001) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_281<1,160,7,7>\u001b[0m, float32_284<160>\u001b[0m, float32_285<160>\u001b[0m, float32_282<160>\u001b[0m, float32_283<160>\u001b[0m, False, 0.01, 0.001, True) -> float32_286<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_286<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_286<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_286<1,160,7,7>\u001b[0m) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_286<1,160,7,7>\u001b[0m) -> float32_288<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_286<1,160,7,7>\u001b[0m, float32_287<960,160,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_288<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_288<1,960,7,7>\u001b[0m) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_288<1,960,7,7>\u001b[0m, float32_289<960>\u001b[0m, float32_290<960>\u001b[0m, float32_291<960>\u001b[0m, float32_290<960>\u001b[0m, False, 0.01, 0.001) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_288<1,960,7,7>\u001b[0m, float32_291<960>\u001b[0m, float32_290<960>\u001b[0m, float32_289<960>\u001b[0m, float32_290<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_292<1,960,7,7>\u001b[0m) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_292<1,960,7,7>\u001b[0m, True) -> float32_292<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_292<1,960,7,7>\u001b[0m) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_292<1,960,7,7>\u001b[0m) -> float32_294<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_292<1,960,7,7>\u001b[0m, float32_293<960,1,5,5>\u001b[0m, None, (1, 1), (2, 2), (1, 1), 960) -> float32_294<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_294<1,960,7,7>\u001b[0m) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_294<1,960,7,7>\u001b[0m, float32_295<960>\u001b[0m, float32_296<960>\u001b[0m, float32_297<960>\u001b[0m, float32_296<960>\u001b[0m, False, 0.01, 0.001) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_294<1,960,7,7>\u001b[0m, float32_297<960>\u001b[0m, float32_296<960>\u001b[0m, float32_295<960>\u001b[0m, float32_296<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_298<1,960,7,7>\u001b[0m) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_298<1,960,7,7>\u001b[0m, True) -> float32_298<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_298<1,960,7,7>\u001b[0m) -> float32_308<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_298<1,960,7,7>\u001b[0m) -> float32_299<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_298<1,960,7,7>\u001b[0m, 1) -> float32_299<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_299<1,960,1,1>\u001b[0m) -> float32_302<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_299<1,960,1,1>\u001b[0m, float32_300<240,960,1,1>\u001b[0m, float32_301<240>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_302<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_302<1,240,1,1>\u001b[0m) -> float32_303<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_302<1,240,1,1>\u001b[0m, inplace=False) -> float32_303<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_302<1,240,1,1>\u001b[0m) -> float32_303<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_303<1,240,1,1>\u001b[0m) -> float32_306<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_303<1,240,1,1>\u001b[0m, float32_304<960,240,1,1>\u001b[0m, float32_305<960>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_306<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_306<1,960,1,1>\u001b[0m) -> float32_307<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_306<1,960,1,1>\u001b[0m, False) -> float32_307<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_307<1,960,1,1>\u001b[0m, float32_298<1,960,7,7>\u001b[0m) -> float32_308<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_307<1,960,1,1>\u001b[0m, float32_298<1,960,7,7>\u001b[0m) -> float32_308<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_308<1,960,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_308<1,960,7,7>\u001b[0m) -> float32_310<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_308<1,960,7,7>\u001b[0m, float32_309<160,960,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_310<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_310<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_310<1,160,7,7>\u001b[0m, float32_311<160>\u001b[0m, float32_312<160>\u001b[0m, float32_311<160>\u001b[0m, float32_313<160>\u001b[0m, False, 0.01, 0.001) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_310<1,160,7,7>\u001b[0m, float32_311<160>\u001b[0m, float32_313<160>\u001b[0m, float32_311<160>\u001b[0m, float32_312<160>\u001b[0m, False, 0.01, 0.001, True) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_314<1,160,7,7>\u001b[0m, float32_286<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_314<1,160,7,7>\u001b[0m, float32_286<1,160,7,7>\u001b[0m) -> float32_314<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32mInvertedResidual[torchvision.models.mobilenetv3]\u001b[0m(float32_314<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_314<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_314<1,160,7,7>\u001b[0m) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_314<1,160,7,7>\u001b[0m) -> float32_316<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_314<1,160,7,7>\u001b[0m, float32_315<960,160,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_316<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_316<1,960,7,7>\u001b[0m) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_316<1,960,7,7>\u001b[0m, float32_317<960>\u001b[0m, float32_318<960>\u001b[0m, float32_317<960>\u001b[0m, float32_319<960>\u001b[0m, False, 0.01, 0.001) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_316<1,960,7,7>\u001b[0m, float32_317<960>\u001b[0m, float32_319<960>\u001b[0m, float32_317<960>\u001b[0m, float32_318<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_320<1,960,7,7>\u001b[0m) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_320<1,960,7,7>\u001b[0m, True) -> float32_320<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_320<1,960,7,7>\u001b[0m) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_320<1,960,7,7>\u001b[0m) -> float32_322<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_320<1,960,7,7>\u001b[0m, float32_321<960,1,5,5>\u001b[0m, None, (1, 1), (2, 2), (1, 1), 960) -> float32_322<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_322<1,960,7,7>\u001b[0m) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_322<1,960,7,7>\u001b[0m, float32_323<960>\u001b[0m, float32_324<960>\u001b[0m, float32_325<960>\u001b[0m, float32_323<960>\u001b[0m, False, 0.01, 0.001) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_322<1,960,7,7>\u001b[0m, float32_325<960>\u001b[0m, float32_323<960>\u001b[0m, float32_323<960>\u001b[0m, float32_324<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_326<1,960,7,7>\u001b[0m) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_326<1,960,7,7>\u001b[0m, True) -> float32_326<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mSqueezeExcitation[torchvision.ops.misc]\u001b[0m(float32_326<1,960,7,7>\u001b[0m) -> float32_336<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_326<1,960,7,7>\u001b[0m) -> float32_327<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_326<1,960,7,7>\u001b[0m, 1) -> float32_327<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_327<1,960,1,1>\u001b[0m) -> float32_330<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_327<1,960,1,1>\u001b[0m, float32_328<240,960,1,1>\u001b[0m, float32_329<240>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_330<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_330<1,240,1,1>\u001b[0m) -> float32_331<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_330<1,240,1,1>\u001b[0m, inplace=False) -> float32_331<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_330<1,240,1,1>\u001b[0m) -> float32_331<1,240,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_331<1,240,1,1>\u001b[0m) -> float32_334<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_331<1,240,1,1>\u001b[0m, float32_332<960,240,1,1>\u001b[0m, float32_333<960>\u001b[0m, (1, 1), (0, 0), (1, 1), 1) -> float32_334<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mHardsigmoid[torch.nn.modules.activation]\u001b[0m(float32_334<1,960,1,1>\u001b[0m) -> float32_335<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardsigmoid[torch.nn.functional]\u001b[0m(float32_334<1,960,1,1>\u001b[0m, False) -> float32_335<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__mul__[torch.Tensor]\u001b[0m(float32_335<1,960,1,1>\u001b[0m, float32_326<1,960,7,7>\u001b[0m) -> float32_336<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mmul[TensorBase]\u001b[0m(float32_335<1,960,1,1>\u001b[0m, float32_326<1,960,7,7>\u001b[0m) -> float32_336<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_336<1,960,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_336<1,960,7,7>\u001b[0m) -> float32_338<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_336<1,960,7,7>\u001b[0m, float32_337<160,960,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_338<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_338<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_338<1,160,7,7>\u001b[0m, float32_339<160>\u001b[0m, float32_340<160>\u001b[0m, float32_339<160>\u001b[0m, float32_339<160>\u001b[0m, False, 0.01, 0.001) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_338<1,160,7,7>\u001b[0m, float32_339<160>\u001b[0m, float32_339<160>\u001b[0m, float32_339<160>\u001b[0m, float32_340<160>\u001b[0m, False, 0.01, 0.001, True) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1m__iadd__[torch.Tensor]\u001b[0m(float32_341<1,160,7,7>\u001b[0m, float32_314<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0madd_[TensorBase]\u001b[0m(float32_341<1,160,7,7>\u001b[0m, float32_314<1,160,7,7>\u001b[0m) -> float32_341<1,160,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m ├·\u001b[0m \u001b[32mConv2dNormActivation[torchvision.ops.misc]\u001b[0m(float32_341<1,160,7,7>\u001b[0m) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mConv2d[torch.nn.modules.conv]\u001b[0m(float32_341<1,160,7,7>\u001b[0m) -> float32_343<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mconv2d[torch.nn.functional]\u001b[0m(float32_341<1,160,7,7>\u001b[0m, float32_342<960,160,1,1>\u001b[0m, None, (1, 1), (0, 0), (1, 1), 1) -> float32_343<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mBatchNorm2d[torch.nn.modules.batchnorm]\u001b[0m(float32_343<1,960,7,7>\u001b[0m) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mbatch_norm[torch.nn.functional]\u001b[0m(float32_343<1,960,7,7>\u001b[0m, float32_344<960>\u001b[0m, float32_344<960>\u001b[0m, float32_345<960>\u001b[0m, float32_345<960>\u001b[0m, False, 0.01, 0.001) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mbatch_norm[torch]\u001b[0m(float32_343<1,960,7,7>\u001b[0m, float32_345<960>\u001b[0m, float32_345<960>\u001b[0m, float32_344<960>\u001b[0m, float32_344<960>\u001b[0m, False, 0.01, 0.001, True) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mHardswish[torch.nn.modules.activation]\u001b[0m(float32_346<1,960,7,7>\u001b[0m) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[34m\u001b[7m (!) Inplace \u001b[0m \n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[33m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mhardswish[torch.nn.functional]\u001b[0m(float32_346<1,960,7,7>\u001b[0m, True) -> float32_346<1,960,7,7>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_346<1,960,7,7>\u001b[0m) -> float32_347<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_346<1,960,7,7>\u001b[0m, 1) -> float32_347<1,960,1,1>\u001b[0m\n",
      "\u001b[32m ├·\u001b[0m \u001b[32mSequential[torch.nn.modules.container]\u001b[0m(float32_347<1,960,1,1>\u001b[0m) -> float32_360<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mAdaptiveAvgPool2d[torch.nn.modules.pooling]\u001b[0m(float32_347<1,960,1,1>\u001b[0m) -> float32_348<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1madaptive_avg_pool2d[torch.nn.functional]\u001b[0m(float32_347<1,960,1,1>\u001b[0m, 1) -> float32_348<1,960,1,1>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32mFlatten[torch.nn.modules.flatten]\u001b[0m(float32_348<1,960,1,1>\u001b[0m) -> float32_349<1,960>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m └·\u001b[0m \u001b[32m\u001b[1mflatten[torch.Tensor]\u001b[0m(float32_348<1,960,1,1>\u001b[0m, 1, -1) -> float32_349<1,960>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_349<1,960>\u001b[0m) -> float32_352<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_349<1,960>\u001b[0m, float32_350<1024,960>\u001b[0m, float32_351<1024>\u001b[0m) -> float32_352<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_352<1,1024>\u001b[0m) -> float32_353<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_352<1,1024>\u001b[0m, inplace=False) -> float32_353<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_352<1,1024>\u001b[0m) -> float32_353<1,1024>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_353<1,1024>\u001b[0m) -> float32_356<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_353<1,1024>\u001b[0m, float32_354<512,1024>\u001b[0m, float32_355<512>\u001b[0m) -> float32_356<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mReLU[torch.nn.modules.activation]\u001b[0m(float32_356<1,512>\u001b[0m) -> float32_357<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m ├·\u001b[0m \u001b[0mrelu[torch.nn.functional]\u001b[0m(float32_356<1,512>\u001b[0m, inplace=False) -> float32_357<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └ \u001b[0m \u001b[0m └·\u001b[0m \u001b[0mrelu[torch]\u001b[0m(float32_356<1,512>\u001b[0m) -> float32_357<1,512>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1mLinear[torch.nn.modules.linear]\u001b[0m(float32_357<1,512>\u001b[0m) -> float32_357<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0mlinear[torch.nn.functional]\u001b[0m(float32_357<1,512>\u001b[0m, float32_358<5,512>\u001b[0m, float32_359<5>\u001b[0m) -> float32_357<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32mSoftmax[torch.nn.modules.activation]\u001b[0m(float32_357<1,5>\u001b[0m) -> float32_360<1,5>\u001b[0m\n",
      "\u001b[32m │ \u001b[0m \u001b[32m │ \u001b[0m \u001b[32m ├·\u001b[0m \u001b[32m\u001b[1msoftmax[torch.nn.functional]\u001b[0m(float32_357<1,5>\u001b[0m, 1, _stacklevel=5) -> float32_360<1,5>\u001b[0m\n",
      "\u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m └ \u001b[0m \u001b[32m\u001b[1m └·\u001b[0m \u001b[0msoftmax[torch.Tensor]\u001b[0m(float32_357<1,5>\u001b[0m, 1) -> float32_360<1,5>\u001b[0m\n",
      "\n",
      "Conversion complete. Elapsed time: 7.69 sec.\n"
     ]
    }
   ],
   "source": [
    "# Convert pytorch model to keras\n",
    "keras_model = pytorch_to_keras(\n",
    "    saved_model, \n",
    "    args=[input_tensor],\n",
    "    outputs_channel_order=ChannelOrder.PYTORCH, \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(1, 224, 224, 3)]           0         []                            \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPaddin  (1, 226, 226, 3)             0         ['input_1[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (1, 112, 112, 16)            432       ['zero_padding2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (1, 112, 112, 16)            64        ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambd  (1, 112, 112, 16)            0         ['batch_normalization[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (1, 112, 112, 16)            0         ['tf.math.truediv[0][0]']     \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.clip_by_value (TFOpLamb  (1, 112, 112, 16)            0         ['tf.__operators__.add[0][0]']\n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (1, 112, 112, 16)            0         ['batch_normalization[0][0]', \n",
      " da)                                                                 'tf.clip_by_value[0][0]']    \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadd  (1, 114, 114, 16)            0         ['tf.math.multiply[0][0]']    \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d (Depthwis  (1, 112, 112, 16)            144       ['zero_padding2d_1[0][0]']    \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (1, 112, 112, 16)            64        ['depthwise_conv2d[0][0]']    \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                (1, 112, 112, 16)            0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (1, 112, 112, 16)            256       ['re_lu[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (1, 112, 112, 16)            64        ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (1, 112, 112, 16)            0         ['batch_normalization_2[0][0]'\n",
      " OpLambda)                                                          , 'tf.math.multiply[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (1, 112, 112, 64)            1024      ['tf.__operators__.add_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (1, 112, 112, 64)            256       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)              (1, 112, 112, 64)            0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadd  (1, 114, 114, 64)            0         ['re_lu_1[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_1 (Depthw  (1, 56, 56, 64)              576       ['zero_padding2d_2[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (1, 56, 56, 64)              256       ['depthwise_conv2d_1[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)              (1, 56, 56, 64)              0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (1, 56, 56, 24)              1536      ['re_lu_2[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (1, 56, 56, 24)              96        ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (1, 56, 56, 72)              1728      ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (1, 56, 56, 72)              288       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)              (1, 56, 56, 72)              0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " zero_padding2d_3 (ZeroPadd  (1, 58, 58, 72)              0         ['re_lu_3[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_2 (Depthw  (1, 56, 56, 72)              648       ['zero_padding2d_3[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (1, 56, 56, 72)              288       ['depthwise_conv2d_2[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)              (1, 56, 56, 72)              0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (1, 56, 56, 24)              1728      ['re_lu_4[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (1, 56, 56, 24)              96        ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (1, 56, 56, 24)              0         ['batch_normalization_8[0][0]'\n",
      " OpLambda)                                                          , 'batch_normalization_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (1, 56, 56, 72)              1728      ['tf.__operators__.add_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (1, 56, 56, 72)              288       ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)              (1, 56, 56, 72)              0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadd  (1, 60, 60, 72)              0         ['re_lu_5[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_3 (Depthw  (1, 28, 28, 72)              1800      ['zero_padding2d_4[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (1, 28, 28, 72)              288       ['depthwise_conv2d_3[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)              (1, 28, 28, 72)              0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 72)                0         ['re_lu_6[0][0]']             \n",
      " 2 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (1, 1, 1, 24)                1752      ['global_average_pooling2d_72[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)              (1, 1, 1, 24)                0         ['conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (1, 1, 1, 72)                1800      ['re_lu_7[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.truediv_1 (TFOpLam  (1, 1, 1, 72)                0         ['conv2d_8[0][0]']            \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (1, 1, 1, 72)                0         ['tf.math.truediv_1[0][0]']   \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.clip_by_value_1 (TFOpLa  (1, 1, 1, 72)                0         ['tf.__operators__.add_3[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (1, 28, 28, 72)              0         ['tf.clip_by_value_1[0][0]',  \n",
      " mbda)                                                               're_lu_6[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (1, 28, 28, 40)              2880      ['tf.math.multiply_1[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (1, 28, 28, 40)              160       ['conv2d_9[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (1, 28, 28, 120)             4800      ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (1, 28, 28, 120)             480       ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)              (1, 28, 28, 120)             0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadd  (1, 32, 32, 120)             0         ['re_lu_8[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_4 (Depthw  (1, 28, 28, 120)             3000      ['zero_padding2d_5[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (1, 28, 28, 120)             480       ['depthwise_conv2d_4[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)              (1, 28, 28, 120)             0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 120)               0         ['re_lu_9[0][0]']             \n",
      " 3 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (1, 1, 1, 32)                3872      ['global_average_pooling2d_73[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)             (1, 1, 1, 32)                0         ['conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (1, 1, 1, 120)               3960      ['re_lu_10[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.truediv_2 (TFOpLam  (1, 1, 1, 120)               0         ['conv2d_12[0][0]']           \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TF  (1, 1, 1, 120)               0         ['tf.math.truediv_2[0][0]']   \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.clip_by_value_2 (TFOpLa  (1, 1, 1, 120)               0         ['tf.__operators__.add_4[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLa  (1, 28, 28, 120)             0         ['tf.clip_by_value_2[0][0]',  \n",
      " mbda)                                                               're_lu_9[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (1, 28, 28, 40)              4800      ['tf.math.multiply_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (1, 28, 28, 40)              160       ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TF  (1, 28, 28, 40)              0         ['batch_normalization_14[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (1, 28, 28, 120)             4800      ['tf.__operators__.add_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (1, 28, 28, 120)             480       ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)             (1, 28, 28, 120)             0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_6 (ZeroPadd  (1, 32, 32, 120)             0         ['re_lu_11[0][0]']            \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_5 (Depthw  (1, 28, 28, 120)             3000      ['zero_padding2d_6[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (1, 28, 28, 120)             480       ['depthwise_conv2d_5[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)             (1, 28, 28, 120)             0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 120)               0         ['re_lu_12[0][0]']            \n",
      " 4 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (1, 1, 1, 32)                3872      ['global_average_pooling2d_74[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)             (1, 1, 1, 32)                0         ['conv2d_15[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (1, 1, 1, 120)               3960      ['re_lu_13[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.truediv_3 (TFOpLam  (1, 1, 1, 120)               0         ['conv2d_16[0][0]']           \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (1, 1, 1, 120)               0         ['tf.math.truediv_3[0][0]']   \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.clip_by_value_3 (TFOpLa  (1, 1, 1, 120)               0         ['tf.__operators__.add_6[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLa  (1, 28, 28, 120)             0         ['tf.clip_by_value_3[0][0]',  \n",
      " mbda)                                                               're_lu_12[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (1, 28, 28, 40)              4800      ['tf.math.multiply_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (1, 28, 28, 40)              160       ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (1, 28, 28, 40)              0         ['batch_normalization_17[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'tf.__operators__.add_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (1, 28, 28, 240)             9600      ['tf.__operators__.add_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (1, 28, 28, 240)             960       ['conv2d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_4 (TFOpLam  (1, 28, 28, 240)             0         ['batch_normalization_18[0][0]\n",
      " bda)                                                               ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TF  (1, 28, 28, 240)             0         ['tf.math.truediv_4[0][0]']   \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.clip_by_value_4 (TFOpLa  (1, 28, 28, 240)             0         ['tf.__operators__.add_8[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLa  (1, 28, 28, 240)             0         ['batch_normalization_18[0][0]\n",
      " mbda)                                                              ',                            \n",
      "                                                                     'tf.clip_by_value_4[0][0]']  \n",
      "                                                                                                  \n",
      " zero_padding2d_7 (ZeroPadd  (1, 30, 30, 240)             0         ['tf.math.multiply_4[0][0]']  \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_6 (Depthw  (1, 14, 14, 240)             2160      ['zero_padding2d_7[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (1, 14, 14, 240)             960       ['depthwise_conv2d_6[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_5 (TFOpLam  (1, 14, 14, 240)             0         ['batch_normalization_19[0][0]\n",
      " bda)                                                               ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TF  (1, 14, 14, 240)             0         ['tf.math.truediv_5[0][0]']   \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.clip_by_value_5 (TFOpLa  (1, 14, 14, 240)             0         ['tf.__operators__.add_9[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLa  (1, 14, 14, 240)             0         ['batch_normalization_19[0][0]\n",
      " mbda)                                                              ',                            \n",
      "                                                                     'tf.clip_by_value_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (1, 14, 14, 80)              19200     ['tf.math.multiply_5[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (1, 14, 14, 80)              320       ['conv2d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (1, 14, 14, 200)             16000     ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (1, 14, 14, 200)             800       ['conv2d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_6 (TFOpLam  (1, 14, 14, 200)             0         ['batch_normalization_21[0][0]\n",
      " bda)                                                               ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (T  (1, 14, 14, 200)             0         ['tf.math.truediv_6[0][0]']   \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_6 (TFOpLa  (1, 14, 14, 200)             0         ['tf.__operators__.add_10[0][0\n",
      " mbda)                                                              ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLa  (1, 14, 14, 200)             0         ['batch_normalization_21[0][0]\n",
      " mbda)                                                              ',                            \n",
      "                                                                     'tf.clip_by_value_6[0][0]']  \n",
      "                                                                                                  \n",
      " zero_padding2d_8 (ZeroPadd  (1, 16, 16, 200)             0         ['tf.math.multiply_6[0][0]']  \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_7 (Depthw  (1, 14, 14, 200)             1800      ['zero_padding2d_8[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (1, 14, 14, 200)             800       ['depthwise_conv2d_7[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_7 (TFOpLam  (1, 14, 14, 200)             0         ['batch_normalization_22[0][0]\n",
      " bda)                                                               ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (T  (1, 14, 14, 200)             0         ['tf.math.truediv_7[0][0]']   \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_7 (TFOpLa  (1, 14, 14, 200)             0         ['tf.__operators__.add_11[0][0\n",
      " mbda)                                                              ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLa  (1, 14, 14, 200)             0         ['batch_normalization_22[0][0]\n",
      " mbda)                                                              ',                            \n",
      "                                                                     'tf.clip_by_value_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (1, 14, 14, 80)              16000     ['tf.math.multiply_7[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (1, 14, 14, 80)              320       ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (T  (1, 14, 14, 80)              0         ['batch_normalization_23[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (1, 14, 14, 184)             14720     ['tf.__operators__.add_12[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (1, 14, 14, 184)             736       ['conv2d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_8 (TFOpLam  (1, 14, 14, 184)             0         ['batch_normalization_24[0][0]\n",
      " bda)                                                               ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (T  (1, 14, 14, 184)             0         ['tf.math.truediv_8[0][0]']   \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_8 (TFOpLa  (1, 14, 14, 184)             0         ['tf.__operators__.add_13[0][0\n",
      " mbda)                                                              ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLa  (1, 14, 14, 184)             0         ['batch_normalization_24[0][0]\n",
      " mbda)                                                              ',                            \n",
      "                                                                     'tf.clip_by_value_8[0][0]']  \n",
      "                                                                                                  \n",
      " zero_padding2d_9 (ZeroPadd  (1, 16, 16, 184)             0         ['tf.math.multiply_8[0][0]']  \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_8 (Depthw  (1, 14, 14, 184)             1656      ['zero_padding2d_9[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (1, 14, 14, 184)             736       ['depthwise_conv2d_8[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_9 (TFOpLam  (1, 14, 14, 184)             0         ['batch_normalization_25[0][0]\n",
      " bda)                                                               ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (T  (1, 14, 14, 184)             0         ['tf.math.truediv_9[0][0]']   \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_9 (TFOpLa  (1, 14, 14, 184)             0         ['tf.__operators__.add_14[0][0\n",
      " mbda)                                                              ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLa  (1, 14, 14, 184)             0         ['batch_normalization_25[0][0]\n",
      " mbda)                                                              ',                            \n",
      "                                                                     'tf.clip_by_value_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (1, 14, 14, 80)              14720     ['tf.math.multiply_9[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (1, 14, 14, 80)              320       ['conv2d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (T  (1, 14, 14, 80)              0         ['batch_normalization_26[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_12[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (1, 14, 14, 184)             14720     ['tf.__operators__.add_15[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (1, 14, 14, 184)             736       ['conv2d_24[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_10 (TFOpLa  (1, 14, 14, 184)             0         ['batch_normalization_27[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (T  (1, 14, 14, 184)             0         ['tf.math.truediv_10[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_10 (TFOpL  (1, 14, 14, 184)             0         ['tf.__operators__.add_16[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_10 (TFOpL  (1, 14, 14, 184)             0         ['batch_normalization_27[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_10[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_10 (ZeroPad  (1, 16, 16, 184)             0         ['tf.math.multiply_10[0][0]'] \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_9 (Depthw  (1, 14, 14, 184)             1656      ['zero_padding2d_10[0][0]']   \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (1, 14, 14, 184)             736       ['depthwise_conv2d_9[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_11 (TFOpLa  (1, 14, 14, 184)             0         ['batch_normalization_28[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (T  (1, 14, 14, 184)             0         ['tf.math.truediv_11[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_11 (TFOpL  (1, 14, 14, 184)             0         ['tf.__operators__.add_17[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_11 (TFOpL  (1, 14, 14, 184)             0         ['batch_normalization_28[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (1, 14, 14, 80)              14720     ['tf.math.multiply_11[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (1, 14, 14, 80)              320       ['conv2d_25[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (T  (1, 14, 14, 80)              0         ['batch_normalization_29[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_15[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (1, 14, 14, 480)             38400     ['tf.__operators__.add_18[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (1, 14, 14, 480)             1920      ['conv2d_26[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_12 (TFOpLa  (1, 14, 14, 480)             0         ['batch_normalization_30[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (T  (1, 14, 14, 480)             0         ['tf.math.truediv_12[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_12 (TFOpL  (1, 14, 14, 480)             0         ['tf.__operators__.add_19[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_12 (TFOpL  (1, 14, 14, 480)             0         ['batch_normalization_30[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_12[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_11 (ZeroPad  (1, 16, 16, 480)             0         ['tf.math.multiply_12[0][0]'] \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_10 (Depth  (1, 14, 14, 480)             4320      ['zero_padding2d_11[0][0]']   \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (1, 14, 14, 480)             1920      ['depthwise_conv2d_10[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_13 (TFOpLa  (1, 14, 14, 480)             0         ['batch_normalization_31[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (T  (1, 14, 14, 480)             0         ['tf.math.truediv_13[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_13 (TFOpL  (1, 14, 14, 480)             0         ['tf.__operators__.add_20[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_13 (TFOpL  (1, 14, 14, 480)             0         ['batch_normalization_31[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_13[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 480)               0         ['tf.math.multiply_13[0][0]'] \n",
      " 5 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (1, 1, 1, 120)               57720     ['global_average_pooling2d_75[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)             (1, 1, 1, 120)               0         ['conv2d_27[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (1, 1, 1, 480)               58080     ['re_lu_14[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.truediv_14 (TFOpLa  (1, 1, 1, 480)               0         ['conv2d_28[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (T  (1, 1, 1, 480)               0         ['tf.math.truediv_14[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_14 (TFOpL  (1, 1, 1, 480)               0         ['tf.__operators__.add_21[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_14 (TFOpL  (1, 14, 14, 480)             0         ['tf.clip_by_value_14[0][0]', \n",
      " ambda)                                                              'tf.math.multiply_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (1, 14, 14, 112)             53760     ['tf.math.multiply_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (1, 14, 14, 112)             448       ['conv2d_29[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (1, 14, 14, 672)             75264     ['batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (1, 14, 14, 672)             2688      ['conv2d_30[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_15 (TFOpLa  (1, 14, 14, 672)             0         ['batch_normalization_33[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (T  (1, 14, 14, 672)             0         ['tf.math.truediv_15[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_15 (TFOpL  (1, 14, 14, 672)             0         ['tf.__operators__.add_22[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_15 (TFOpL  (1, 14, 14, 672)             0         ['batch_normalization_33[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_15[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_12 (ZeroPad  (1, 16, 16, 672)             0         ['tf.math.multiply_15[0][0]'] \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_11 (Depth  (1, 14, 14, 672)             6048      ['zero_padding2d_12[0][0]']   \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (1, 14, 14, 672)             2688      ['depthwise_conv2d_11[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_16 (TFOpLa  (1, 14, 14, 672)             0         ['batch_normalization_34[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (T  (1, 14, 14, 672)             0         ['tf.math.truediv_16[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_16 (TFOpL  (1, 14, 14, 672)             0         ['tf.__operators__.add_23[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_16 (TFOpL  (1, 14, 14, 672)             0         ['batch_normalization_34[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_16[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 672)               0         ['tf.math.multiply_16[0][0]'] \n",
      " 6 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (1, 1, 1, 168)               113064    ['global_average_pooling2d_76[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)             (1, 1, 1, 168)               0         ['conv2d_31[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (1, 1, 1, 672)               113568    ['re_lu_15[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.truediv_17 (TFOpLa  (1, 1, 1, 672)               0         ['conv2d_32[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (T  (1, 1, 1, 672)               0         ['tf.math.truediv_17[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_17 (TFOpL  (1, 1, 1, 672)               0         ['tf.__operators__.add_24[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_17 (TFOpL  (1, 14, 14, 672)             0         ['tf.clip_by_value_17[0][0]', \n",
      " ambda)                                                              'tf.math.multiply_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (1, 14, 14, 112)             75264     ['tf.math.multiply_17[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_35 (Ba  (1, 14, 14, 112)             448       ['conv2d_33[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (T  (1, 14, 14, 112)             0         ['batch_normalization_35[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (1, 14, 14, 672)             75264     ['tf.__operators__.add_25[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_36 (Ba  (1, 14, 14, 672)             2688      ['conv2d_34[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_18 (TFOpLa  (1, 14, 14, 672)             0         ['batch_normalization_36[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (T  (1, 14, 14, 672)             0         ['tf.math.truediv_18[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_18 (TFOpL  (1, 14, 14, 672)             0         ['tf.__operators__.add_26[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_18 (TFOpL  (1, 14, 14, 672)             0         ['batch_normalization_36[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_18[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_13 (ZeroPad  (1, 18, 18, 672)             0         ['tf.math.multiply_18[0][0]'] \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_12 (Depth  (1, 7, 7, 672)               16800     ['zero_padding2d_13[0][0]']   \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_37 (Ba  (1, 7, 7, 672)               2688      ['depthwise_conv2d_12[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_19 (TFOpLa  (1, 7, 7, 672)               0         ['batch_normalization_37[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (T  (1, 7, 7, 672)               0         ['tf.math.truediv_19[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_19 (TFOpL  (1, 7, 7, 672)               0         ['tf.__operators__.add_27[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_19 (TFOpL  (1, 7, 7, 672)               0         ['batch_normalization_37[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_19[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 672)               0         ['tf.math.multiply_19[0][0]'] \n",
      " 7 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (1, 1, 1, 168)               113064    ['global_average_pooling2d_77[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)             (1, 1, 1, 168)               0         ['conv2d_35[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (1, 1, 1, 672)               113568    ['re_lu_16[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.truediv_20 (TFOpLa  (1, 1, 1, 672)               0         ['conv2d_36[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (T  (1, 1, 1, 672)               0         ['tf.math.truediv_20[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_20 (TFOpL  (1, 1, 1, 672)               0         ['tf.__operators__.add_28[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_20 (TFOpL  (1, 7, 7, 672)               0         ['tf.clip_by_value_20[0][0]', \n",
      " ambda)                                                              'tf.math.multiply_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (1, 7, 7, 160)               107520    ['tf.math.multiply_20[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_38 (Ba  (1, 7, 7, 160)               640       ['conv2d_37[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)          (1, 7, 7, 960)               153600    ['batch_normalization_38[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_39 (Ba  (1, 7, 7, 960)               3840      ['conv2d_38[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_21 (TFOpLa  (1, 7, 7, 960)               0         ['batch_normalization_39[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (T  (1, 7, 7, 960)               0         ['tf.math.truediv_21[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_21 (TFOpL  (1, 7, 7, 960)               0         ['tf.__operators__.add_29[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_21 (TFOpL  (1, 7, 7, 960)               0         ['batch_normalization_39[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_21[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_14 (ZeroPad  (1, 11, 11, 960)             0         ['tf.math.multiply_21[0][0]'] \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_13 (Depth  (1, 7, 7, 960)               24000     ['zero_padding2d_14[0][0]']   \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_40 (Ba  (1, 7, 7, 960)               3840      ['depthwise_conv2d_13[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_22 (TFOpLa  (1, 7, 7, 960)               0         ['batch_normalization_40[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (T  (1, 7, 7, 960)               0         ['tf.math.truediv_22[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_22 (TFOpL  (1, 7, 7, 960)               0         ['tf.__operators__.add_30[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_22 (TFOpL  (1, 7, 7, 960)               0         ['batch_normalization_40[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_22[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 960)               0         ['tf.math.multiply_22[0][0]'] \n",
      " 8 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)          (1, 1, 1, 240)               230640    ['global_average_pooling2d_78[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)             (1, 1, 1, 240)               0         ['conv2d_39[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)          (1, 1, 1, 960)               231360    ['re_lu_17[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.truediv_23 (TFOpLa  (1, 1, 1, 960)               0         ['conv2d_40[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (T  (1, 1, 1, 960)               0         ['tf.math.truediv_23[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_23 (TFOpL  (1, 1, 1, 960)               0         ['tf.__operators__.add_31[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_23 (TFOpL  (1, 7, 7, 960)               0         ['tf.clip_by_value_23[0][0]', \n",
      " ambda)                                                              'tf.math.multiply_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)          (1, 7, 7, 160)               153600    ['tf.math.multiply_23[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_41 (Ba  (1, 7, 7, 160)               640       ['conv2d_41[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_32 (T  (1, 7, 7, 160)               0         ['batch_normalization_41[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'batch_normalization_38[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)          (1, 7, 7, 960)               153600    ['tf.__operators__.add_32[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_42 (Ba  (1, 7, 7, 960)               3840      ['conv2d_42[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_24 (TFOpLa  (1, 7, 7, 960)               0         ['batch_normalization_42[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_33 (T  (1, 7, 7, 960)               0         ['tf.math.truediv_24[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_24 (TFOpL  (1, 7, 7, 960)               0         ['tf.__operators__.add_33[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_24 (TFOpL  (1, 7, 7, 960)               0         ['batch_normalization_42[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_24[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_15 (ZeroPad  (1, 11, 11, 960)             0         ['tf.math.multiply_24[0][0]'] \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_14 (Depth  (1, 7, 7, 960)               24000     ['zero_padding2d_15[0][0]']   \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_43 (Ba  (1, 7, 7, 960)               3840      ['depthwise_conv2d_14[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_25 (TFOpLa  (1, 7, 7, 960)               0         ['batch_normalization_43[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_34 (T  (1, 7, 7, 960)               0         ['tf.math.truediv_25[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_25 (TFOpL  (1, 7, 7, 960)               0         ['tf.__operators__.add_34[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_25 (TFOpL  (1, 7, 7, 960)               0         ['batch_normalization_43[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_25[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 960)               0         ['tf.math.multiply_25[0][0]'] \n",
      " 9 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)          (1, 1, 1, 240)               230640    ['global_average_pooling2d_79[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)             (1, 1, 1, 240)               0         ['conv2d_43[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)          (1, 1, 1, 960)               231360    ['re_lu_18[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.truediv_26 (TFOpLa  (1, 1, 1, 960)               0         ['conv2d_44[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_35 (T  (1, 1, 1, 960)               0         ['tf.math.truediv_26[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_26 (TFOpL  (1, 1, 1, 960)               0         ['tf.__operators__.add_35[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_26 (TFOpL  (1, 7, 7, 960)               0         ['tf.clip_by_value_26[0][0]', \n",
      " ambda)                                                              'tf.math.multiply_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)          (1, 7, 7, 160)               153600    ['tf.math.multiply_26[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_44 (Ba  (1, 7, 7, 160)               640       ['conv2d_45[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_36 (T  (1, 7, 7, 160)               0         ['batch_normalization_44[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_32[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)          (1, 7, 7, 960)               153600    ['tf.__operators__.add_36[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_45 (Ba  (1, 7, 7, 960)               3840      ['conv2d_46[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_27 (TFOpLa  (1, 7, 7, 960)               0         ['batch_normalization_45[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_37 (T  (1, 7, 7, 960)               0         ['tf.math.truediv_27[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_27 (TFOpL  (1, 7, 7, 960)               0         ['tf.__operators__.add_37[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_27 (TFOpL  (1, 7, 7, 960)               0         ['batch_normalization_45[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_27[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8  (1, 1, 1, 960)               0         ['tf.math.multiply_27[0][0]'] \n",
      " 0 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8  (1, 1, 1, 960)               0         ['global_average_pooling2d_80[\n",
      " 1 (GlobalAveragePooling2D)                                         0][0]']                       \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TF  (1, 960, 1, 1)               0         ['global_average_pooling2d_81[\n",
      " OpLambda)                                                          0][0]']                       \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.compat.v1.transpose[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (1,)                         0         ['tf.compat.v1.shape[0][0]']  \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.__operators__.getitem[0][\n",
      "  (SlicingOpLambda)                                                 0]']                          \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)     (1, 960)                     0         ['tf.compat.v1.transpose[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense (Dense)               (1, 1024)                    984064    ['tf.reshape[0][0]']          \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)             (1, 1024)                    0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (1, 512)                     524800    ['re_lu_19[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)             (1, 512)                     0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (1, 5)                       2565      ['re_lu_20[0][0]']            \n",
      "                                                                                                  \n",
      " tf.nn.softmax (TFOpLambda)  (1, 5)                       0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " tf.identity (TFOpLambda)    (1, 5)                       0         ['tf.nn.softmax[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4507781 (17.20 MB)\n",
      "Trainable params: 4483381 (17.10 MB)\n",
      "Non-trainable params: 24400 (95.31 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\louis\\anaconda3\\envs\\nobuco\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n",
      "WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "\"\"\" keras_model.save(\"keras_model.h5\") \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I got ``WARNING:tensorflow:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.`` so I compile to model and save it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "keras_model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\louis\\anaconda3\\envs\\nobuco\\Lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    }
   ],
   "source": [
    "keras_model.save(\"keras_model.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "keras_model = tf.keras.saving.load_model(\"best-keras_model.h5\", custom_objects=None, compile=True, safe_mode=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model\"\n",
      "__________________________________________________________________________________________________\n",
      " Layer (type)                Output Shape                 Param #   Connected to                  \n",
      "==================================================================================================\n",
      " input_1 (InputLayer)        [(1, 224, 224, 3)]           0         []                            \n",
      "                                                                                                  \n",
      " zero_padding2d (ZeroPaddin  (1, 226, 226, 3)             0         ['input_1[0][0]']             \n",
      " g2D)                                                                                             \n",
      "                                                                                                  \n",
      " conv2d (Conv2D)             (1, 112, 112, 16)            432       ['zero_padding2d[0][0]']      \n",
      "                                                                                                  \n",
      " batch_normalization (Batch  (1, 112, 112, 16)            64        ['conv2d[0][0]']              \n",
      " Normalization)                                                                                   \n",
      "                                                                                                  \n",
      " tf.math.truediv (TFOpLambd  (1, 112, 112, 16)            0         ['batch_normalization[0][0]'] \n",
      " a)                                                                                               \n",
      "                                                                                                  \n",
      " tf.__operators__.add (TFOp  (1, 112, 112, 16)            0         ['tf.math.truediv[0][0]']     \n",
      " Lambda)                                                                                          \n",
      "                                                                                                  \n",
      " tf.clip_by_value (TFOpLamb  (1, 112, 112, 16)            0         ['tf.__operators__.add[0][0]']\n",
      " da)                                                                                              \n",
      "                                                                                                  \n",
      " tf.math.multiply (TFOpLamb  (1, 112, 112, 16)            0         ['batch_normalization[0][0]', \n",
      " da)                                                                 'tf.clip_by_value[0][0]']    \n",
      "                                                                                                  \n",
      " zero_padding2d_1 (ZeroPadd  (1, 114, 114, 16)            0         ['tf.math.multiply[0][0]']    \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d (Depthwis  (1, 112, 112, 16)            144       ['zero_padding2d_1[0][0]']    \n",
      " eConv2D)                                                                                         \n",
      "                                                                                                  \n",
      " batch_normalization_1 (Bat  (1, 112, 112, 16)            64        ['depthwise_conv2d[0][0]']    \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu (ReLU)                (1, 112, 112, 16)            0         ['batch_normalization_1[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_1 (Conv2D)           (1, 112, 112, 16)            256       ['re_lu[0][0]']               \n",
      "                                                                                                  \n",
      " batch_normalization_2 (Bat  (1, 112, 112, 16)            64        ['conv2d_1[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_1 (TF  (1, 112, 112, 16)            0         ['batch_normalization_2[0][0]'\n",
      " OpLambda)                                                          , 'tf.math.multiply[0][0]']   \n",
      "                                                                                                  \n",
      " conv2d_2 (Conv2D)           (1, 112, 112, 64)            1024      ['tf.__operators__.add_1[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_3 (Bat  (1, 112, 112, 64)            256       ['conv2d_2[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_1 (ReLU)              (1, 112, 112, 64)            0         ['batch_normalization_3[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " zero_padding2d_2 (ZeroPadd  (1, 114, 114, 64)            0         ['re_lu_1[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_1 (Depthw  (1, 56, 56, 64)              576       ['zero_padding2d_2[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_4 (Bat  (1, 56, 56, 64)              256       ['depthwise_conv2d_1[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_2 (ReLU)              (1, 56, 56, 64)              0         ['batch_normalization_4[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_3 (Conv2D)           (1, 56, 56, 24)              1536      ['re_lu_2[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_5 (Bat  (1, 56, 56, 24)              96        ['conv2d_3[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " conv2d_4 (Conv2D)           (1, 56, 56, 72)              1728      ['batch_normalization_5[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " batch_normalization_6 (Bat  (1, 56, 56, 72)              288       ['conv2d_4[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_3 (ReLU)              (1, 56, 56, 72)              0         ['batch_normalization_6[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " zero_padding2d_3 (ZeroPadd  (1, 58, 58, 72)              0         ['re_lu_3[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_2 (Depthw  (1, 56, 56, 72)              648       ['zero_padding2d_3[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_7 (Bat  (1, 56, 56, 72)              288       ['depthwise_conv2d_2[0][0]']  \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_4 (ReLU)              (1, 56, 56, 72)              0         ['batch_normalization_7[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " conv2d_5 (Conv2D)           (1, 56, 56, 24)              1728      ['re_lu_4[0][0]']             \n",
      "                                                                                                  \n",
      " batch_normalization_8 (Bat  (1, 56, 56, 24)              96        ['conv2d_5[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.add_2 (TF  (1, 56, 56, 24)              0         ['batch_normalization_8[0][0]'\n",
      " OpLambda)                                                          , 'batch_normalization_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_6 (Conv2D)           (1, 56, 56, 72)              1728      ['tf.__operators__.add_2[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_9 (Bat  (1, 56, 56, 72)              288       ['conv2d_6[0][0]']            \n",
      " chNormalization)                                                                                 \n",
      "                                                                                                  \n",
      " re_lu_5 (ReLU)              (1, 56, 56, 72)              0         ['batch_normalization_9[0][0]'\n",
      "                                                                    ]                             \n",
      "                                                                                                  \n",
      " zero_padding2d_4 (ZeroPadd  (1, 60, 60, 72)              0         ['re_lu_5[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_3 (Depthw  (1, 28, 28, 72)              1800      ['zero_padding2d_4[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_10 (Ba  (1, 28, 28, 72)              288       ['depthwise_conv2d_3[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_6 (ReLU)              (1, 28, 28, 72)              0         ['batch_normalization_10[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 72)                0         ['re_lu_6[0][0]']             \n",
      " 2 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_7 (Conv2D)           (1, 1, 1, 24)                1752      ['global_average_pooling2d_72[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_7 (ReLU)              (1, 1, 1, 24)                0         ['conv2d_7[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_8 (Conv2D)           (1, 1, 1, 72)                1800      ['re_lu_7[0][0]']             \n",
      "                                                                                                  \n",
      " tf.math.truediv_1 (TFOpLam  (1, 1, 1, 72)                0         ['conv2d_8[0][0]']            \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_3 (TF  (1, 1, 1, 72)                0         ['tf.math.truediv_1[0][0]']   \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.clip_by_value_1 (TFOpLa  (1, 1, 1, 72)                0         ['tf.__operators__.add_3[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_1 (TFOpLa  (1, 28, 28, 72)              0         ['tf.clip_by_value_1[0][0]',  \n",
      " mbda)                                                               're_lu_6[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_9 (Conv2D)           (1, 28, 28, 40)              2880      ['tf.math.multiply_1[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_11 (Ba  (1, 28, 28, 40)              160       ['conv2d_9[0][0]']            \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_10 (Conv2D)          (1, 28, 28, 120)             4800      ['batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_12 (Ba  (1, 28, 28, 120)             480       ['conv2d_10[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_8 (ReLU)              (1, 28, 28, 120)             0         ['batch_normalization_12[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_5 (ZeroPadd  (1, 32, 32, 120)             0         ['re_lu_8[0][0]']             \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_4 (Depthw  (1, 28, 28, 120)             3000      ['zero_padding2d_5[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_13 (Ba  (1, 28, 28, 120)             480       ['depthwise_conv2d_4[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_9 (ReLU)              (1, 28, 28, 120)             0         ['batch_normalization_13[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 120)               0         ['re_lu_9[0][0]']             \n",
      " 3 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_11 (Conv2D)          (1, 1, 1, 32)                3872      ['global_average_pooling2d_73[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_10 (ReLU)             (1, 1, 1, 32)                0         ['conv2d_11[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_12 (Conv2D)          (1, 1, 1, 120)               3960      ['re_lu_10[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.truediv_2 (TFOpLam  (1, 1, 1, 120)               0         ['conv2d_12[0][0]']           \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_4 (TF  (1, 1, 1, 120)               0         ['tf.math.truediv_2[0][0]']   \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.clip_by_value_2 (TFOpLa  (1, 1, 1, 120)               0         ['tf.__operators__.add_4[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_2 (TFOpLa  (1, 28, 28, 120)             0         ['tf.clip_by_value_2[0][0]',  \n",
      " mbda)                                                               're_lu_9[0][0]']             \n",
      "                                                                                                  \n",
      " conv2d_13 (Conv2D)          (1, 28, 28, 40)              4800      ['tf.math.multiply_2[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_14 (Ba  (1, 28, 28, 40)              160       ['conv2d_13[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_5 (TF  (1, 28, 28, 40)              0         ['batch_normalization_14[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'batch_normalization_11[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_14 (Conv2D)          (1, 28, 28, 120)             4800      ['tf.__operators__.add_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_15 (Ba  (1, 28, 28, 120)             480       ['conv2d_14[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_11 (ReLU)             (1, 28, 28, 120)             0         ['batch_normalization_15[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " zero_padding2d_6 (ZeroPadd  (1, 32, 32, 120)             0         ['re_lu_11[0][0]']            \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_5 (Depthw  (1, 28, 28, 120)             3000      ['zero_padding2d_6[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_16 (Ba  (1, 28, 28, 120)             480       ['depthwise_conv2d_5[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " re_lu_12 (ReLU)             (1, 28, 28, 120)             0         ['batch_normalization_16[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 120)               0         ['re_lu_12[0][0]']            \n",
      " 4 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_15 (Conv2D)          (1, 1, 1, 32)                3872      ['global_average_pooling2d_74[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_13 (ReLU)             (1, 1, 1, 32)                0         ['conv2d_15[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_16 (Conv2D)          (1, 1, 1, 120)               3960      ['re_lu_13[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.truediv_3 (TFOpLam  (1, 1, 1, 120)               0         ['conv2d_16[0][0]']           \n",
      " bda)                                                                                             \n",
      "                                                                                                  \n",
      " tf.__operators__.add_6 (TF  (1, 1, 1, 120)               0         ['tf.math.truediv_3[0][0]']   \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.clip_by_value_3 (TFOpLa  (1, 1, 1, 120)               0         ['tf.__operators__.add_6[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_3 (TFOpLa  (1, 28, 28, 120)             0         ['tf.clip_by_value_3[0][0]',  \n",
      " mbda)                                                               're_lu_12[0][0]']            \n",
      "                                                                                                  \n",
      " conv2d_17 (Conv2D)          (1, 28, 28, 40)              4800      ['tf.math.multiply_3[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_17 (Ba  (1, 28, 28, 40)              160       ['conv2d_17[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_7 (TF  (1, 28, 28, 40)              0         ['batch_normalization_17[0][0]\n",
      " OpLambda)                                                          ',                            \n",
      "                                                                     'tf.__operators__.add_5[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_18 (Conv2D)          (1, 28, 28, 240)             9600      ['tf.__operators__.add_7[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_18 (Ba  (1, 28, 28, 240)             960       ['conv2d_18[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_4 (TFOpLam  (1, 28, 28, 240)             0         ['batch_normalization_18[0][0]\n",
      " bda)                                                               ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_8 (TF  (1, 28, 28, 240)             0         ['tf.math.truediv_4[0][0]']   \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.clip_by_value_4 (TFOpLa  (1, 28, 28, 240)             0         ['tf.__operators__.add_8[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_4 (TFOpLa  (1, 28, 28, 240)             0         ['batch_normalization_18[0][0]\n",
      " mbda)                                                              ',                            \n",
      "                                                                     'tf.clip_by_value_4[0][0]']  \n",
      "                                                                                                  \n",
      " zero_padding2d_7 (ZeroPadd  (1, 30, 30, 240)             0         ['tf.math.multiply_4[0][0]']  \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_6 (Depthw  (1, 14, 14, 240)             2160      ['zero_padding2d_7[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_19 (Ba  (1, 14, 14, 240)             960       ['depthwise_conv2d_6[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_5 (TFOpLam  (1, 14, 14, 240)             0         ['batch_normalization_19[0][0]\n",
      " bda)                                                               ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_9 (TF  (1, 14, 14, 240)             0         ['tf.math.truediv_5[0][0]']   \n",
      " OpLambda)                                                                                        \n",
      "                                                                                                  \n",
      " tf.clip_by_value_5 (TFOpLa  (1, 14, 14, 240)             0         ['tf.__operators__.add_9[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.math.multiply_5 (TFOpLa  (1, 14, 14, 240)             0         ['batch_normalization_19[0][0]\n",
      " mbda)                                                              ',                            \n",
      "                                                                     'tf.clip_by_value_5[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_19 (Conv2D)          (1, 14, 14, 80)              19200     ['tf.math.multiply_5[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_20 (Ba  (1, 14, 14, 80)              320       ['conv2d_19[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_20 (Conv2D)          (1, 14, 14, 200)             16000     ['batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_21 (Ba  (1, 14, 14, 200)             800       ['conv2d_20[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_6 (TFOpLam  (1, 14, 14, 200)             0         ['batch_normalization_21[0][0]\n",
      " bda)                                                               ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_10 (T  (1, 14, 14, 200)             0         ['tf.math.truediv_6[0][0]']   \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_6 (TFOpLa  (1, 14, 14, 200)             0         ['tf.__operators__.add_10[0][0\n",
      " mbda)                                                              ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_6 (TFOpLa  (1, 14, 14, 200)             0         ['batch_normalization_21[0][0]\n",
      " mbda)                                                              ',                            \n",
      "                                                                     'tf.clip_by_value_6[0][0]']  \n",
      "                                                                                                  \n",
      " zero_padding2d_8 (ZeroPadd  (1, 16, 16, 200)             0         ['tf.math.multiply_6[0][0]']  \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_7 (Depthw  (1, 14, 14, 200)             1800      ['zero_padding2d_8[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_22 (Ba  (1, 14, 14, 200)             800       ['depthwise_conv2d_7[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_7 (TFOpLam  (1, 14, 14, 200)             0         ['batch_normalization_22[0][0]\n",
      " bda)                                                               ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_11 (T  (1, 14, 14, 200)             0         ['tf.math.truediv_7[0][0]']   \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_7 (TFOpLa  (1, 14, 14, 200)             0         ['tf.__operators__.add_11[0][0\n",
      " mbda)                                                              ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_7 (TFOpLa  (1, 14, 14, 200)             0         ['batch_normalization_22[0][0]\n",
      " mbda)                                                              ',                            \n",
      "                                                                     'tf.clip_by_value_7[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_21 (Conv2D)          (1, 14, 14, 80)              16000     ['tf.math.multiply_7[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_23 (Ba  (1, 14, 14, 80)              320       ['conv2d_21[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_12 (T  (1, 14, 14, 80)              0         ['batch_normalization_23[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'batch_normalization_20[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_22 (Conv2D)          (1, 14, 14, 184)             14720     ['tf.__operators__.add_12[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_24 (Ba  (1, 14, 14, 184)             736       ['conv2d_22[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_8 (TFOpLam  (1, 14, 14, 184)             0         ['batch_normalization_24[0][0]\n",
      " bda)                                                               ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_13 (T  (1, 14, 14, 184)             0         ['tf.math.truediv_8[0][0]']   \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_8 (TFOpLa  (1, 14, 14, 184)             0         ['tf.__operators__.add_13[0][0\n",
      " mbda)                                                              ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_8 (TFOpLa  (1, 14, 14, 184)             0         ['batch_normalization_24[0][0]\n",
      " mbda)                                                              ',                            \n",
      "                                                                     'tf.clip_by_value_8[0][0]']  \n",
      "                                                                                                  \n",
      " zero_padding2d_9 (ZeroPadd  (1, 16, 16, 184)             0         ['tf.math.multiply_8[0][0]']  \n",
      " ing2D)                                                                                           \n",
      "                                                                                                  \n",
      " depthwise_conv2d_8 (Depthw  (1, 14, 14, 184)             1656      ['zero_padding2d_9[0][0]']    \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_25 (Ba  (1, 14, 14, 184)             736       ['depthwise_conv2d_8[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_9 (TFOpLam  (1, 14, 14, 184)             0         ['batch_normalization_25[0][0]\n",
      " bda)                                                               ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_14 (T  (1, 14, 14, 184)             0         ['tf.math.truediv_9[0][0]']   \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_9 (TFOpLa  (1, 14, 14, 184)             0         ['tf.__operators__.add_14[0][0\n",
      " mbda)                                                              ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_9 (TFOpLa  (1, 14, 14, 184)             0         ['batch_normalization_25[0][0]\n",
      " mbda)                                                              ',                            \n",
      "                                                                     'tf.clip_by_value_9[0][0]']  \n",
      "                                                                                                  \n",
      " conv2d_23 (Conv2D)          (1, 14, 14, 80)              14720     ['tf.math.multiply_9[0][0]']  \n",
      "                                                                                                  \n",
      " batch_normalization_26 (Ba  (1, 14, 14, 80)              320       ['conv2d_23[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_15 (T  (1, 14, 14, 80)              0         ['batch_normalization_26[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_12[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_24 (Conv2D)          (1, 14, 14, 184)             14720     ['tf.__operators__.add_15[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_27 (Ba  (1, 14, 14, 184)             736       ['conv2d_24[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_10 (TFOpLa  (1, 14, 14, 184)             0         ['batch_normalization_27[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_16 (T  (1, 14, 14, 184)             0         ['tf.math.truediv_10[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_10 (TFOpL  (1, 14, 14, 184)             0         ['tf.__operators__.add_16[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_10 (TFOpL  (1, 14, 14, 184)             0         ['batch_normalization_27[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_10[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_10 (ZeroPad  (1, 16, 16, 184)             0         ['tf.math.multiply_10[0][0]'] \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_9 (Depthw  (1, 14, 14, 184)             1656      ['zero_padding2d_10[0][0]']   \n",
      " iseConv2D)                                                                                       \n",
      "                                                                                                  \n",
      " batch_normalization_28 (Ba  (1, 14, 14, 184)             736       ['depthwise_conv2d_9[0][0]']  \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_11 (TFOpLa  (1, 14, 14, 184)             0         ['batch_normalization_28[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_17 (T  (1, 14, 14, 184)             0         ['tf.math.truediv_11[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_11 (TFOpL  (1, 14, 14, 184)             0         ['tf.__operators__.add_17[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_11 (TFOpL  (1, 14, 14, 184)             0         ['batch_normalization_28[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_11[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_25 (Conv2D)          (1, 14, 14, 80)              14720     ['tf.math.multiply_11[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_29 (Ba  (1, 14, 14, 80)              320       ['conv2d_25[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_18 (T  (1, 14, 14, 80)              0         ['batch_normalization_29[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_15[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_26 (Conv2D)          (1, 14, 14, 480)             38400     ['tf.__operators__.add_18[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_30 (Ba  (1, 14, 14, 480)             1920      ['conv2d_26[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_12 (TFOpLa  (1, 14, 14, 480)             0         ['batch_normalization_30[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_19 (T  (1, 14, 14, 480)             0         ['tf.math.truediv_12[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_12 (TFOpL  (1, 14, 14, 480)             0         ['tf.__operators__.add_19[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_12 (TFOpL  (1, 14, 14, 480)             0         ['batch_normalization_30[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_12[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_11 (ZeroPad  (1, 16, 16, 480)             0         ['tf.math.multiply_12[0][0]'] \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_10 (Depth  (1, 14, 14, 480)             4320      ['zero_padding2d_11[0][0]']   \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_31 (Ba  (1, 14, 14, 480)             1920      ['depthwise_conv2d_10[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_13 (TFOpLa  (1, 14, 14, 480)             0         ['batch_normalization_31[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_20 (T  (1, 14, 14, 480)             0         ['tf.math.truediv_13[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_13 (TFOpL  (1, 14, 14, 480)             0         ['tf.__operators__.add_20[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_13 (TFOpL  (1, 14, 14, 480)             0         ['batch_normalization_31[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_13[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 480)               0         ['tf.math.multiply_13[0][0]'] \n",
      " 5 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_27 (Conv2D)          (1, 1, 1, 120)               57720     ['global_average_pooling2d_75[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_14 (ReLU)             (1, 1, 1, 120)               0         ['conv2d_27[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_28 (Conv2D)          (1, 1, 1, 480)               58080     ['re_lu_14[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.truediv_14 (TFOpLa  (1, 1, 1, 480)               0         ['conv2d_28[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_21 (T  (1, 1, 1, 480)               0         ['tf.math.truediv_14[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_14 (TFOpL  (1, 1, 1, 480)               0         ['tf.__operators__.add_21[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_14 (TFOpL  (1, 14, 14, 480)             0         ['tf.clip_by_value_14[0][0]', \n",
      " ambda)                                                              'tf.math.multiply_13[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_29 (Conv2D)          (1, 14, 14, 112)             53760     ['tf.math.multiply_14[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_32 (Ba  (1, 14, 14, 112)             448       ['conv2d_29[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_30 (Conv2D)          (1, 14, 14, 672)             75264     ['batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_33 (Ba  (1, 14, 14, 672)             2688      ['conv2d_30[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_15 (TFOpLa  (1, 14, 14, 672)             0         ['batch_normalization_33[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_22 (T  (1, 14, 14, 672)             0         ['tf.math.truediv_15[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_15 (TFOpL  (1, 14, 14, 672)             0         ['tf.__operators__.add_22[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_15 (TFOpL  (1, 14, 14, 672)             0         ['batch_normalization_33[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_15[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_12 (ZeroPad  (1, 16, 16, 672)             0         ['tf.math.multiply_15[0][0]'] \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_11 (Depth  (1, 14, 14, 672)             6048      ['zero_padding2d_12[0][0]']   \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_34 (Ba  (1, 14, 14, 672)             2688      ['depthwise_conv2d_11[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_16 (TFOpLa  (1, 14, 14, 672)             0         ['batch_normalization_34[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_23 (T  (1, 14, 14, 672)             0         ['tf.math.truediv_16[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_16 (TFOpL  (1, 14, 14, 672)             0         ['tf.__operators__.add_23[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_16 (TFOpL  (1, 14, 14, 672)             0         ['batch_normalization_34[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_16[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 672)               0         ['tf.math.multiply_16[0][0]'] \n",
      " 6 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_31 (Conv2D)          (1, 1, 1, 168)               113064    ['global_average_pooling2d_76[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_15 (ReLU)             (1, 1, 1, 168)               0         ['conv2d_31[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_32 (Conv2D)          (1, 1, 1, 672)               113568    ['re_lu_15[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.truediv_17 (TFOpLa  (1, 1, 1, 672)               0         ['conv2d_32[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_24 (T  (1, 1, 1, 672)               0         ['tf.math.truediv_17[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_17 (TFOpL  (1, 1, 1, 672)               0         ['tf.__operators__.add_24[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_17 (TFOpL  (1, 14, 14, 672)             0         ['tf.clip_by_value_17[0][0]', \n",
      " ambda)                                                              'tf.math.multiply_16[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_33 (Conv2D)          (1, 14, 14, 112)             75264     ['tf.math.multiply_17[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_35 (Ba  (1, 14, 14, 112)             448       ['conv2d_33[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_25 (T  (1, 14, 14, 112)             0         ['batch_normalization_35[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'batch_normalization_32[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_34 (Conv2D)          (1, 14, 14, 672)             75264     ['tf.__operators__.add_25[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_36 (Ba  (1, 14, 14, 672)             2688      ['conv2d_34[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_18 (TFOpLa  (1, 14, 14, 672)             0         ['batch_normalization_36[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_26 (T  (1, 14, 14, 672)             0         ['tf.math.truediv_18[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_18 (TFOpL  (1, 14, 14, 672)             0         ['tf.__operators__.add_26[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_18 (TFOpL  (1, 14, 14, 672)             0         ['batch_normalization_36[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_18[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_13 (ZeroPad  (1, 18, 18, 672)             0         ['tf.math.multiply_18[0][0]'] \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_12 (Depth  (1, 7, 7, 672)               16800     ['zero_padding2d_13[0][0]']   \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_37 (Ba  (1, 7, 7, 672)               2688      ['depthwise_conv2d_12[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_19 (TFOpLa  (1, 7, 7, 672)               0         ['batch_normalization_37[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_27 (T  (1, 7, 7, 672)               0         ['tf.math.truediv_19[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_19 (TFOpL  (1, 7, 7, 672)               0         ['tf.__operators__.add_27[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_19 (TFOpL  (1, 7, 7, 672)               0         ['batch_normalization_37[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_19[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 672)               0         ['tf.math.multiply_19[0][0]'] \n",
      " 7 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_35 (Conv2D)          (1, 1, 1, 168)               113064    ['global_average_pooling2d_77[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_16 (ReLU)             (1, 1, 1, 168)               0         ['conv2d_35[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_36 (Conv2D)          (1, 1, 1, 672)               113568    ['re_lu_16[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.truediv_20 (TFOpLa  (1, 1, 1, 672)               0         ['conv2d_36[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_28 (T  (1, 1, 1, 672)               0         ['tf.math.truediv_20[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_20 (TFOpL  (1, 1, 1, 672)               0         ['tf.__operators__.add_28[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_20 (TFOpL  (1, 7, 7, 672)               0         ['tf.clip_by_value_20[0][0]', \n",
      " ambda)                                                              'tf.math.multiply_19[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_37 (Conv2D)          (1, 7, 7, 160)               107520    ['tf.math.multiply_20[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_38 (Ba  (1, 7, 7, 160)               640       ['conv2d_37[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " conv2d_38 (Conv2D)          (1, 7, 7, 960)               153600    ['batch_normalization_38[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " batch_normalization_39 (Ba  (1, 7, 7, 960)               3840      ['conv2d_38[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_21 (TFOpLa  (1, 7, 7, 960)               0         ['batch_normalization_39[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_29 (T  (1, 7, 7, 960)               0         ['tf.math.truediv_21[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_21 (TFOpL  (1, 7, 7, 960)               0         ['tf.__operators__.add_29[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_21 (TFOpL  (1, 7, 7, 960)               0         ['batch_normalization_39[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_21[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_14 (ZeroPad  (1, 11, 11, 960)             0         ['tf.math.multiply_21[0][0]'] \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_13 (Depth  (1, 7, 7, 960)               24000     ['zero_padding2d_14[0][0]']   \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_40 (Ba  (1, 7, 7, 960)               3840      ['depthwise_conv2d_13[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_22 (TFOpLa  (1, 7, 7, 960)               0         ['batch_normalization_40[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_30 (T  (1, 7, 7, 960)               0         ['tf.math.truediv_22[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_22 (TFOpL  (1, 7, 7, 960)               0         ['tf.__operators__.add_30[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_22 (TFOpL  (1, 7, 7, 960)               0         ['batch_normalization_40[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_22[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 960)               0         ['tf.math.multiply_22[0][0]'] \n",
      " 8 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_39 (Conv2D)          (1, 1, 1, 240)               230640    ['global_average_pooling2d_78[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_17 (ReLU)             (1, 1, 1, 240)               0         ['conv2d_39[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_40 (Conv2D)          (1, 1, 1, 960)               231360    ['re_lu_17[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.truediv_23 (TFOpLa  (1, 1, 1, 960)               0         ['conv2d_40[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_31 (T  (1, 1, 1, 960)               0         ['tf.math.truediv_23[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_23 (TFOpL  (1, 1, 1, 960)               0         ['tf.__operators__.add_31[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_23 (TFOpL  (1, 7, 7, 960)               0         ['tf.clip_by_value_23[0][0]', \n",
      " ambda)                                                              'tf.math.multiply_22[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_41 (Conv2D)          (1, 7, 7, 160)               153600    ['tf.math.multiply_23[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_41 (Ba  (1, 7, 7, 160)               640       ['conv2d_41[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_32 (T  (1, 7, 7, 160)               0         ['batch_normalization_41[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'batch_normalization_38[0][0]\n",
      "                                                                    ']                            \n",
      "                                                                                                  \n",
      " conv2d_42 (Conv2D)          (1, 7, 7, 960)               153600    ['tf.__operators__.add_32[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_42 (Ba  (1, 7, 7, 960)               3840      ['conv2d_42[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_24 (TFOpLa  (1, 7, 7, 960)               0         ['batch_normalization_42[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_33 (T  (1, 7, 7, 960)               0         ['tf.math.truediv_24[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_24 (TFOpL  (1, 7, 7, 960)               0         ['tf.__operators__.add_33[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_24 (TFOpL  (1, 7, 7, 960)               0         ['batch_normalization_42[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_24[0][0]'] \n",
      "                                                                                                  \n",
      " zero_padding2d_15 (ZeroPad  (1, 11, 11, 960)             0         ['tf.math.multiply_24[0][0]'] \n",
      " ding2D)                                                                                          \n",
      "                                                                                                  \n",
      " depthwise_conv2d_14 (Depth  (1, 7, 7, 960)               24000     ['zero_padding2d_15[0][0]']   \n",
      " wiseConv2D)                                                                                      \n",
      "                                                                                                  \n",
      " batch_normalization_43 (Ba  (1, 7, 7, 960)               3840      ['depthwise_conv2d_14[0][0]'] \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_25 (TFOpLa  (1, 7, 7, 960)               0         ['batch_normalization_43[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_34 (T  (1, 7, 7, 960)               0         ['tf.math.truediv_25[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_25 (TFOpL  (1, 7, 7, 960)               0         ['tf.__operators__.add_34[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_25 (TFOpL  (1, 7, 7, 960)               0         ['batch_normalization_43[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_25[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_7  (1, 1, 1, 960)               0         ['tf.math.multiply_25[0][0]'] \n",
      " 9 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " conv2d_43 (Conv2D)          (1, 1, 1, 240)               230640    ['global_average_pooling2d_79[\n",
      "                                                                    0][0]']                       \n",
      "                                                                                                  \n",
      " re_lu_18 (ReLU)             (1, 1, 1, 240)               0         ['conv2d_43[0][0]']           \n",
      "                                                                                                  \n",
      " conv2d_44 (Conv2D)          (1, 1, 1, 960)               231360    ['re_lu_18[0][0]']            \n",
      "                                                                                                  \n",
      " tf.math.truediv_26 (TFOpLa  (1, 1, 1, 960)               0         ['conv2d_44[0][0]']           \n",
      " mbda)                                                                                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_35 (T  (1, 1, 1, 960)               0         ['tf.math.truediv_26[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_26 (TFOpL  (1, 1, 1, 960)               0         ['tf.__operators__.add_35[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_26 (TFOpL  (1, 7, 7, 960)               0         ['tf.clip_by_value_26[0][0]', \n",
      " ambda)                                                              'tf.math.multiply_25[0][0]'] \n",
      "                                                                                                  \n",
      " conv2d_45 (Conv2D)          (1, 7, 7, 160)               153600    ['tf.math.multiply_26[0][0]'] \n",
      "                                                                                                  \n",
      " batch_normalization_44 (Ba  (1, 7, 7, 160)               640       ['conv2d_45[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.__operators__.add_36 (T  (1, 7, 7, 160)               0         ['batch_normalization_44[0][0]\n",
      " FOpLambda)                                                         ',                            \n",
      "                                                                     'tf.__operators__.add_32[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " conv2d_46 (Conv2D)          (1, 7, 7, 960)               153600    ['tf.__operators__.add_36[0][0\n",
      "                                                                    ]']                           \n",
      "                                                                                                  \n",
      " batch_normalization_45 (Ba  (1, 7, 7, 960)               3840      ['conv2d_46[0][0]']           \n",
      " tchNormalization)                                                                                \n",
      "                                                                                                  \n",
      " tf.math.truediv_27 (TFOpLa  (1, 7, 7, 960)               0         ['batch_normalization_45[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.add_37 (T  (1, 7, 7, 960)               0         ['tf.math.truediv_27[0][0]']  \n",
      " FOpLambda)                                                                                       \n",
      "                                                                                                  \n",
      " tf.clip_by_value_27 (TFOpL  (1, 7, 7, 960)               0         ['tf.__operators__.add_37[0][0\n",
      " ambda)                                                             ]']                           \n",
      "                                                                                                  \n",
      " tf.math.multiply_27 (TFOpL  (1, 7, 7, 960)               0         ['batch_normalization_45[0][0]\n",
      " ambda)                                                             ',                            \n",
      "                                                                     'tf.clip_by_value_27[0][0]'] \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8  (1, 1, 1, 960)               0         ['tf.math.multiply_27[0][0]'] \n",
      " 0 (GlobalAveragePooling2D)                                                                       \n",
      "                                                                                                  \n",
      " global_average_pooling2d_8  (1, 1, 1, 960)               0         ['global_average_pooling2d_80[\n",
      " 1 (GlobalAveragePooling2D)                                         0][0]']                       \n",
      "                                                                                                  \n",
      " tf.compat.v1.transpose (TF  (1, 960, 1, 1)               0         ['global_average_pooling2d_81[\n",
      " OpLambda)                                                          0][0]']                       \n",
      "                                                                                                  \n",
      " tf.compat.v1.shape (TFOpLa  (4,)                         0         ['tf.compat.v1.transpose[0][0]\n",
      " mbda)                                                              ']                            \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem (  (1,)                         0         ['tf.compat.v1.shape[0][0]']  \n",
      " SlicingOpLambda)                                                                                 \n",
      "                                                                                                  \n",
      " tf.__operators__.getitem_2  ()                           0         ['tf.__operators__.getitem[0][\n",
      "  (SlicingOpLambda)                                                 0]']                          \n",
      "                                                                                                  \n",
      " tf.reshape (TFOpLambda)     (1, 960)                     0         ['tf.compat.v1.transpose[0][0]\n",
      "                                                                    ',                            \n",
      "                                                                     'tf.__operators__.getitem_2[0\n",
      "                                                                    ][0]']                        \n",
      "                                                                                                  \n",
      " dense (Dense)               (1, 1024)                    984064    ['tf.reshape[0][0]']          \n",
      "                                                                                                  \n",
      " re_lu_19 (ReLU)             (1, 1024)                    0         ['dense[0][0]']               \n",
      "                                                                                                  \n",
      " dense_1 (Dense)             (1, 512)                     524800    ['re_lu_19[0][0]']            \n",
      "                                                                                                  \n",
      " re_lu_20 (ReLU)             (1, 512)                     0         ['dense_1[0][0]']             \n",
      "                                                                                                  \n",
      " dense_2 (Dense)             (1, 5)                       2565      ['re_lu_20[0][0]']            \n",
      "                                                                                                  \n",
      " tf.nn.softmax (TFOpLambda)  (1, 5)                       0         ['dense_2[0][0]']             \n",
      "                                                                                                  \n",
      " tf.identity (TFOpLambda)    (1, 5)                       0         ['tf.nn.softmax[0][0]']       \n",
      "                                                                                                  \n",
      "==================================================================================================\n",
      "Total params: 4507781 (17.20 MB)\n",
      "Trainable params: 4483381 (17.10 MB)\n",
      "Non-trainable params: 24400 (95.31 KB)\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "keras_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Check keras model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5 images belonging to 5 classes.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# Validation and test set\n",
    "datagen = ImageDataGenerator(\n",
    "                            rescale=1./255,  # Rescale pixel values from [0, 255] to [0, 1]\n",
    "                            #featurewise_center=True,  # Apply ImageNet mean subtraction (per channel)\n",
    "                            #featurewise_std_normalization=True  # Apply ImageNet standard deviation scaling (per channel)\n",
    "                        )\n",
    "test = datagen.flow_from_directory(\n",
    "                                    os.path.join(\"dataset\", \"row-data-test\"),\n",
    "                                    shuffle=False,\n",
    "                                    target_size=(224, 224),\n",
    "                                    batch_size=1,\n",
    "                                    class_mode=\"sparse\",\n",
    "                                    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 66ms/step\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pred = keras_model.predict(test)\n",
    "\n",
    "np.argmax(test_pred, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 2, 3, 4])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 1000x400 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "test_pred_labels = np.argmax(test_pred, axis=1)\n",
    "\n",
    "true_test_pred_labels = test.labels\n",
    "\n",
    "# Plot Confusion Matrix\n",
    "fig, (ax0, ax1) = plt.subplots(1, 2, figsize=(10, 4))\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(true_test_pred_labels, test_pred_labels, ax=ax0)\n",
    "ax0.set_title(\"Confusion Matrix values\")\n",
    "\n",
    "ConfusionMatrixDisplay.from_predictions(true_test_pred_labels, test_pred_labels, normalize=\"true\", ax=ax1)\n",
    "ax1.set_title(\"Confusion Matrix percentage\")\n",
    " \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lel's save the model to json using tensorflowjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the model to json using tensorflowjs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ">use tfjs env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ``cd C:\\Users\\louis\\OneDrive\\Bureau\\Project-MedAI``\n",
    "2. cmd command: ``tensorflowjs_converter --input_format=keras  model.h5 tfjs_model_pytorch``"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. ``cd C:\\Users\\louis\\OneDrive\\Bureau\\Project-MedAI``\n",
    "2. cmd command: ``tensorflowjs_converter --input_format=keras  model.h5 tfjs_model_pytorchv2``"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "onnx",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
